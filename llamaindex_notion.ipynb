{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ターミナルに  \n",
    "export HEADQUARTER_DATABASE_ID  \n",
    "と  \n",
    "export BOOKMARK_DATABASE_ID  \n",
    "と  \n",
    "NOTION_INTEGRATION_TOKEN  \n",
    "をしてから実行してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = os.environ.get('OPENAI_API_KEY')\n",
    "os.environ['NOTION_INTEGRATION_TOKEN'] = os.environ.get('NOTION_INTEGRATION_TOKEN')\n",
    "os.environ[\"GEMINI_API_KEY\"] = os.environ.get(\"GEMINI_API_KEY\")\n",
    "# os.environ['HEADQUARTER_DATABASE_ID'] = os.environ.get('HEADQUARTER_DATABASE_ID')\n",
    "# os.environ['BOOKMARK_DATABASE_ID'] = os.environ.get('BOOKMARK_DATABASE_ID')\n",
    "# headquarter_database_id = os.environ.get(\"HEADQUARTER_DATABASE_ID\")\n",
    "# BOOKMARK_DATABASE_ID = os.environ.get(\"BOOKMARK_DATABASE_ID\")\n",
    "# integration_token = os.environ.get(\"NOTION_INTEGRATION_TOKEN\")\n",
    "# print(integration_token)\n",
    "# print(headquarter_database_id)\n",
    "# print(BOOKMARK_DATABASE_ID)\n",
    "integration_token = 'secret_NqX3JTPq6E3Zj5cnYanrfZfQ6GVqmNxGyjsVFe3feGM'\n",
    "HEADQUARTER_DATABASE_ID = '7d6f473167454ca3936fece11a0b692a'\n",
    "BOOKMARK_DATABASE_ID = 'd979925d021f499d90a5ab9cfede7487'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NotionをGraphRAGで扱うための準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "from llama_index.core import SummaryIndex\n",
    "from IPython.display import Markdown, display\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from llama_index.readers.notion import NotionPageReader\n",
    "import urllib3\n",
    "# ログレベルの設定\n",
    "# logging.basicConfig(stream=sys.stdout, level=logging.DEBUG, force=True)\n",
    "urllib3.disable_warnings()\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings, VectorStoreIndex\n",
    "from llama_index.llms.openai import OpenAI\n",
    "# from llama_index.llms.gemini import Gemini # ColabじゃないとGCPの設定が必要？\n",
    "# from llama_index.embeddings.gemini import GeminiEmbedding # ColabじゃないとGCPの設定が必要？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notion_test.py\n",
    "def get_database_pages(databese_id):\n",
    "    url = f\"https://api.notion.com/v1/databases/{databese_id}/query\"\n",
    "    headers = {\n",
    "        \"Notion-Version\": \"2022-06-28\",\n",
    "        'Authorization': 'Bearer ' + integration_token,\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "    response = requests.post(url, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "def extract_page_titles(database_data):\n",
    "    page_titles = []\n",
    "    for page in database_data.get('results', []):\n",
    "        properties = page.get('properties', {})\n",
    "        for prop in properties.values():\n",
    "            if prop['type'] == 'title':\n",
    "                title = prop['title'][0]['plain_text'] if prop['title'] else ''\n",
    "                page_titles.append(title)\n",
    "                break\n",
    "    return page_titles\n",
    "\n",
    "\n",
    "# # 使用例\n",
    "# database_data = get_database_pages(HEADQUARTER_DATABASE_ID)\n",
    "# page_titles = extract_page_titles(database_data)\n",
    "# print(page_titles)\n",
    "\n",
    "def get_page_title(page_id):\n",
    "    url = f\"https://api.notion.com/v1/pages/{page_id}\"\n",
    "    headers = {\n",
    "        \"Notion-Version\": \"2022-06-28\",\n",
    "        'Authorization': 'Bearer ' + NOTION_API_KEY,\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    page_data = response.json()\n",
    "    \n",
    "    # ページのプロパティからタイトルを抽出\n",
    "    properties = page_data.get('properties', {})\n",
    "    for prop in properties.values():\n",
    "        if prop['type'] == 'title':\n",
    "            return prop['title'][0]['plain_text'] if prop['title'] else ''\n",
    "    \n",
    "    # タイトルが見つからない場合は空文字列を返す\n",
    "    return ''\n",
    "\n",
    "# 使用例\n",
    "# page_id = \"page_id here\"\n",
    "# title = get_page_title(page_id)\n",
    "# print(f\"Page Title: {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:28<00:00,  1.40it/s]\n",
      "100%|██████████| 39/39 [00:00<00:00, 2183.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize NotionPageReader\n",
    "reader = NotionPageReader(integration_token=integration_token)\n",
    "\n",
    "# Load data from Notion\n",
    "# 指定したデータベースが持つページのデータを読み込む\n",
    "headquarter_documents = reader.load_data(page_ids=reader.query_database(HEADQUARTER_DATABASE_ID))  # List of page IDs to load\n",
    "bookmark_documents = reader.load_data(page_ids=reader.query_database(BOOKMARK_DATABASE_ID))  # List of page IDs to load\n",
    "\n",
    "# 辞書型に整形\n",
    "# ページタイトルをキー、ページ内容をバリューとする辞書を作成\n",
    "docs = {}\n",
    "for doc in tqdm(bookmark_documents):\n",
    "    page_title, page_contents = get_page_title(doc.id_), doc.text\n",
    "    docs[page_title] = page_contents\n",
    "\n",
    "# 辞書をtxtに書き出す。キーをファイル名、値をコンテンツとして書き出す\n",
    "for key, value in tqdm(docs.items()):\n",
    "    file_name = key.replace('.', '_').replace('/', '-')\n",
    "    with open(f\"ragtarget/input/{file_name}.txt\", \"w\") as f:\n",
    "        f.write(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAGtest\n",
    "bookmark_documentsについて質問"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: The National Payments Corporation of India, the...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: \n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: \n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: a. 10時間コース\n",
      "10時間コースでは，深層学習の背景にある数学や理論を飛ばし，短時間でプロ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: (TensorFlow)\n",
      "Deep Learning実践開発講座（DL4US）\n",
      " \n",
      "\n",
      "\tKer...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: (\n",
      "TensorFlow\n",
      ")のコースを中心に紹介しましたが，200時間コースでは\n",
      "PyTorc...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 数学の勉強（学習想定時間：40時間）\n",
      "機械学習や深層学習の理解に必要な「線形代数」「微分積分」...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: プログラミングの勉強（学習想定時間：40時間）\n",
      "機械学習や深層学習を理解し実装するために，プロ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: PythonやNumPyを用いたデータ分析の方法を学ぶ（学習想定時間：30時間）\n",
      "3. プログ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Introduction to Deep Learning\n",
      "（英語のみ） \n",
      "\n",
      "\tマサチューセッ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 岡谷貴之先生による深層学習の定番本です．深層学習について基礎からしっかり学ぶことができます．改...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: ProbSpace\n",
      ", \n",
      "Nishika\n",
      "などもあります）．こちらでモデルの性能を向上させる工...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 社会人向け\n",
      "社会人向けでは，深層学習技術を使ってビジネス展開やその産業応用をすることを念頭にロ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: プログラミングの勉強（学習想定時間：40時間）\n",
      "多忙な社会人の方は長い期間をかけて数学の勉強を...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Learning Lecture Series 2020\n",
      "（英語のみ） \n",
      "\n",
      "\tDeepMind...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: \n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: \n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: \n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 勉強について\n",
      "エンジニアの皆さん。エンジニア以外の皆さん。\n",
      "\n",
      " ・勉強しようと思っているけど、...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: SEGA\n",
      "SEGAはゲーム会社なので、数学についての資料を展開していますね。\n",
      "クォータニオンと...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: \n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 昨年、\n",
      "株式会社松尾研究所\n",
      "（東京大学松尾研とビジョンを共有）に転職しました。\n",
      "現在は技術顧問...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: ai」をメインにしています。\n",
      "1.2 最新の技術情報\n",
      "技術系の情報については、はてなブックマー...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: URLべた書きを再掲いたします。\n",
      "https://papers.labml.ai/papers...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: （上記3つのメルマガの雰囲気）\n",
      "以上、毎朝チェックする情報の紹介でした。\n",
      "続いては、週単位でチ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 今回は、今話題の ChatGPT と Notion の連携についてのご紹介です。 AI機能は ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Notion の新規ページにテーブルを作成する\n",
      "](https://notion-lab.jp...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Chrome拡張機能『 ChatGPT to Notion 』 をインストール\n",
      "Chrome ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: チャットデータ保存方法\n",
      "ChatGPT の解答のアイコンボタンにあるピンのマークをクリックする...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 全ての会話を保存する方法\n",
      "全ての会話を保存したい場合は、Chrome の拡張機能ボタンをクリッ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: \n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: TAG: Dynalyst\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TAG: Dynalyst\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: English | \n",
      "日本語\n",
      "astro-notion-blog\n",
      "\n",
      "\n",
      "\n",
      "astro-notio...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: \n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: この記事は、一度使われて終わるような、ChatGPT にちょっとした機能を追加しただけの GP...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 以下デモ動画のように「空いている時間に予定入れといて」のような雑な命令でも適切に判断して追加し...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 日本から素晴らしい GPTs がどんどんと作られていき、\n",
      "\n",
      "\n",
      "世界で使われるGPTが出てきて欲...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: こんにちは！新しいGPTを作るのを手伝います。例えば、\"新商品のビジュアル制作を手伝ってくれる...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: **URLにアクセスしても自分のアカウントだけしかアクセスできないため、自分専用の特化型GPT...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: \n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: \n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: DeepFoids: Simulation Of Fish School Behavior U...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 今までで最もインパクトのあるGPTsが完成しました。\n",
      "その名も、「\n",
      "GAS Interpret...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: ぜひ、GAS Interpreter を導入する方は、さまざまな活用事例を探ってみてほしいです...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 適当な指示でスライドのデザインをかっこよくする：\n",
      "\n",
      "画像のように、適当な命令でも使えます。この...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: ただし、\n",
      "リスクは低いもののゼロではないため、自己責任で導入\n",
      "してください。正直言って、大企業...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: はじめに\n",
      "今回は有名企業の公開されているエンジニア新人研修資料をまとめました。\n",
      "昨今、新人向け...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: こちらも資料も豊富でかなり勉強になると思うのでぜひ利用してみてください。\n",
      "\n",
      "サイボウズ\n",
      "\n",
      "次に...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: こちらの研修資料ではGitHubのリポジトリーが公開されており、天気予報アプリを開発しながら学...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 公開日：1日前 最終更新日：1日前\n",
      "\n",
      "AIエセ師\n",
      "AIエセ師です。\n",
      "さて今回も無料プレゼントで...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 引用リポストいただければ私からリポストします。\n",
      "\n",
      "\n",
      "そうする事でインプ数も稼ぎフォロワーさんが...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: またマンツーマン面談もあるので安心して画像が生成できますよ。\n",
      "\n",
      "\n",
      "それもなんと！！マガジン形式...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: \n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: \n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: \n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Transcript\n",
      "\n",
      " \n",
      "\n",
      "\tMasanobu Naruse\n",
      "\tSQL Tutorial\n",
      "\t...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: net\n",
      "\t26\n",
      "\tView Slide\n",
      "\n",
      " \n",
      "\n",
      "\thttps://sqlzoo.net\n",
      "\t27...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 090,000 人より\n",
      "\t多い国\n",
      "\t61\n",
      "\tView Slide\n",
      "\n",
      " \n",
      "\n",
      "\tFROM worl...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: area,\n",
      "\tpopulation DESC\n",
      "\tソートするカラムは複数指定できる\n",
      "\t80\n",
      "\tV...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 本記事では、私が2022年に読んでよかったO'Reillyの技術書とその要点を簡潔に解説する。...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 本書では、「レガシーコード」を修正する上で重要なポイントを9つにわけてまとめられている。その中...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: マイクロサービスは\n",
      "LINE\n",
      "や\n",
      "Cookpad\n",
      "で採用されている。マイクロサービスの仕組み、...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: API設計・開発で生計を立てるプログラマーは全員読んでおくべき。APIに関する書籍は数多く存在...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Dockerのコンテナ作成のプロセスと比較しながら、Kubernetesのワークフローを学べる...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 始めに はじめまして、2022年4月に新卒として入社した Customer Analytics...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: ARISE Tech Blog  2021.12.10\n",
      " \n",
      "\n",
      "\n",
      "PySparkで線形回帰モデル...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: ARISE Tech Blog  \n",
      "   \n",
      "\n",
      "\n",
      "皆さまこんにちは。 Marketing Sol...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: はじめに こんにちは、Customer-Analytics-Divisionの徳山と申します。...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 導入 レコメンドエンジン連載の第2回目です。 前回の「レコメンドって何？」はこちらを御覧くださ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: ARISE Tech Blog  2020.09.25\n",
      " \n",
      "\n",
      "\n",
      "ARISE analytics...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 画像生成AI（midjourney）の基礎プロンプト集をつくりました。\n",
      "100以上のおすすめ基...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: https://docs.google.com/spreadsheets/d/1cm6239g...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: アイデアの力を解き放つ\n",
      "EdrawMind（エドラマインド）は、マインドマップが書きやすい。\n",
      "...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: ９つのスペシャルポイント\n",
      "\n",
      "企業認証レベルの安全性\n",
      "転送されるすべての情報は、最高レベルの S...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: この記事は、一度使われて終わるような、ChatGPT にちょっとした機能を追加しただけの GP...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: この記事は、これらのGPTの制作経験をもとにして書いています。\n",
      "公開しているGPTが、他のユー...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: とにかく一個作ってみるには良い一歩です。\n",
      "わかる方は、この章は飛ばしてOKです。\n",
      "Step 1...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: **URLにアクセスしても自分のアカウントだけしかアクセスできないため、自分専用の特化型GPT...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: \n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: \n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: updated at 2022-02-05\n",
      ",\n",
      "こんにちは、高校 2 年生の E869120 ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: その悩みも、実力帯ごとに異なり、\n",
      "最初に何をやれば良いのか悩んでいる競プロ未経験者もいる\n",
      "競プ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: それらのトピックをまとめた書籍を出版しましたので、ぜひ読んでみてください。\n",
      "Amazon｜「ア...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: このように、競技プログラミングは\n",
      "コーディングの正確性\n",
      "が問われるコンテストです。\n",
      "どんな問題...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 一部修正しました)\n",
      "#include <iostream>\n",
      "#include <cstdio>...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 数学的考察力が向上する！\n",
      "一般に、AtCoder の問題をたくさん解いていくと、数学的考察力・...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 早速競プロを始めてみよう\n",
      "競プロの楽しさ、面白さはわかりましたでしょうか？\n",
      "皆さんも、早速今日...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: We recruit annotators to search for relevant in...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: \n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: DL SEMINARS\n",
      "\n",
      "\n",
      "\n",
      "Deep Learning技術は、他の分野では例を見ないスピード...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: はじめに\n",
      "早速ですが、皆さんは投資をしているでしょうか。しているとすれば、どのような投資をして...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 本記事の目的\n",
      "本記事では兎にも角にも、初級者の方が持つ投資観に対して全く新しい気付きを与えるこ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: このときのスタートアップ資金は5000万円でした。2016年に現在主力となっている運用システム...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: さて、この投資手法で利益は出るのでしょうか。\n",
      "結論として、利益が出る場合もあれば出ない場合もあ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: これは中身の分からないガチャをひたすら回しているのと同じことです。あなたは年に数回ほど上記の排...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 期待値がプラスで且つバラツキが小さい、すなわち「シャープレシオ」の高い台です。このようなガチャ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 引けば引くだけあなたの財布からお金は消えていきます。これはトレードでも同じことです。トレードで...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: このようなトレーディングスタイルは、包括的に「システムトレーディング」とも呼ばれています。\n",
      "実...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 0             0\n",
      "1999-05-10  2253.27  2279.16  2...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 43446e+12   2.4572e+12  2.39986e+12  1.99437e+1...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 102642e+12  4.479344e+12  4.399669e+12  3.97993...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 552805e+12\n",
      "Long Term Debt                    1....\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 610950e+12\n",
      "Dividends Paid                      ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 0  6948.0  6870.0  6945.0   3047000          0 ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 180       NaN       NaN\n",
      "1996-11-01  113.500    ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: Amazonシアトル本社でプロダクトマネージャーをしていましたが、2021年8月にスタートアッ...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: 2021年11月13日\n",
      "2022年2月14日\n",
      "【GAFA米国本社】プロダクトマネージャーとエン...\n",
      "DEBUG:llama_index.core.node_parser.node_utils:> Adding chunk: それ、実はかなり損しています。この記事では、内定獲得後に必ず給与交渉をした方が良い理由と、その...\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': \"You are an expert Q&A system that is trusted around the world.\\nAlways answer the query using the provided context information, and not prior knowledge.\\nSome rules to follow:\\n1. Never directly reference the given context in your answer.\\n2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\"}, {'role': 'user', 'content': 'Context information is below.\\n---------------------\\npage_id: 0e61e779-12cb-4bbb-b7c8-bfdc59fdffb8\\n\\nThe National Payments Corporation of India, the firm that built the eponymous UPI rail in the country, approved Paytm’s application to participate in the payments ecosystem as a third-party a...\\nInstagram is working on a “Spins” feature for Reels, its short-form video TikTok clone, the company confirmed to TechCrunch. The feature, which was first spotted by reverse engineer Ale...\\nThe European Commission has sent a series of formal requests for information (RFI) to Google, Meta, Microsoft, Snap, TikTok and X about how they’re handling risks related to the use of genera...\\nSatellite sensors collect an incredible amount of raw data, but on-orbit compute limitations mean that operators have little way to process this data in space. Aethero, a startup founded 13 months ...\\nEven though NFT sales volume is still down 88% from 2022 all time-highs (and down 38% year-to-date), Pallet Exchange is building a new type of NFT marketplace focused on user retention. And it’s do...\\nThere is perhaps no bigger jump for a startup to make than from the incubatory seed stage to its Series A round. Given how large a step-up landing a Series A can be, there are many guidelines out t...\\nThe European Union has opened its third formal investigation of a very large platform under the Digital Services Act (DSA), with China’s AliExpress earning itself the dubious honor of being t...\\nProton Mail, the end-to-end encrypted (E2EE) email service from Swiss company Proton, is now officially available via a dedicated desktop app some three months after debuting in beta. However, desp...\\n[\\nBook By March 15 & Save $1000\\nSuper Early Bird Sale Ends Sooncarat-rightBuy Now\\n](https://techcrunch.com/events/tc-disrupt-2024/)\\nA startup out of Paris that began life building marketing tools has raised $22 million after making a successful pivot into billing — a space it discovered was even more broken among potentia...\\nWhere we’ll be next\\narrow-left\\nMay 21London, United Kingdom\\nJun 11Washington, D.C., United States of America\\narrow-right\\nYouverify, a Nigerian provider of identity verification and anti-money laundering (AML) solutions for banks and startups, secured a $2.5 million investment from Elm, which specializes in offering r...\\nAmazon launched generative AI-powered features last year to help sellers quickly create listings by entering just a few words about the product. The company is now making it easier for sellers to c...\\nElaia’s third deep tech seed fund, DTS3, is double the size of the two previous funds, and signals the momentum that is forming around an emerging concept: European dynamism.\\nThe Irish government fixed a vulnerability two years ago in its national COVID-19 vaccination portal that exposed the vaccination records of around a million residents. But details of the vulnerabi...\\nOne undeniable trend from this year’s Modex conference: suddenly everyone is into truck unloading. The past couple of years have gone from a few select companies to seemingly everyone in and around...\\nOpenAI’s legal battle with The New York Times over data to train its AI models might still be brewing. But OpenAI’s forging ahead on deals with other publishers, including some of Franc...\\nSpaceX will attempt to send the massive Starship rocket to orbit for the third time early Thursday morning after U.S. regulators gave the green light for launch. The company is aiming to complete t...\\nDoing inventory sucks. I feel the need to reiterate this any time I discuss the topic here. Having performed a bit of it during my years of retail work, I can personally attest to the fact that it’...\\nMukesh Ambani’s Reliance is buying Paramount Global’s 13% stake in Viacom18 for $517 million as Asia’s richest man broadens his entertainment business just weeks after striking a ...\\n\\npage_id: bffa752d-d046-490a-bdc8-c641a1de7234\\n\\npage_id: 77f15eb9-196c-42ab-a8a2-06b8b529ad05\\n\\npage_id: c86e4d11-41fe-4f26-bcaf-44a735f63669\\n\\na. 10時間コース\\n10時間コースでは，深層学習の背景にある数学や理論を飛ばし，短時間でプログラミングに慣れて自分で機械学習モデルや深層学習モデルを構築するまでを目指します．ここで実物のモデルを動かすことを経験してから，200時間コースへ進んで理論や実装をより深く学ぶのも良いでしょう．\\nPythonプログラミングの経験がある方も，\\n1.プログラミングの勉強\\nは見て知識に穴がないかを確認すると良いでしょう．\\n対象者\\nPythonプログラミングの経験がない，または数学に自信がないが，短時間で深層学習モデルをとりあえず動かしてみたい方\\n1. プログラミングの勉強（学習想定時間：4時間）\\n機械学習や深層学習を理解し実装するために，まずはプログラミングについて簡単に学びましょう．プログラミング言語にはPythonを選ぶといいでしょう．以下の教材などを利用して，基本的なPythonの実装の仕方を確認しましょう．\\nPythonプログラミング入門\\n \\n\\n\\t10時間コースでは，全てを網羅せずに\\n\\tGoogle Colaboratory\\n\\tの使い方やPythonの使い方についてざっくりと理解するといいでしょう．\\nプログラミングの勉強は，他人のコードを読んだり自分で書いたりしながら，わからないところを逐一調べて覚えていくのが最も効率的です．そういった意味では，何度も基礎を反復するよりは\\n2. 深層学習の実装\\nに進んでしまった方が結果的に早いかもしれません．\\n2. 深層学習の実装（学習想定時間：6時間）\\nPythonプログラミングについてある程度理解できたら，実際に深層学習モデルを動かしてみましょう．200時間コースでは数学や機械学習理論についても学びますが，10時間コースでは手を動かしながら実践的に理解することを目指します．10時間コースでの深層学習のライブラリとしては，\\nKeras\\nなど高レベルAPIのものがおすすめです．以下の教材などを利用するといいでしょう．\\nKeras (TensorFlow)\\nDeep Learning実践開発講座（DL4US）\\n \\n\\n\\tKerasを用いて深層学習について手を動かしながら学べるコンテンツです．一通り進めることで，深層学習の概要を理解し実装できるようになります．\\nIntroduction to Deep Learning & Neural Networks with Keras\\n（英語のみ）\\n\\npage_id: c86e4d11-41fe-4f26-bcaf-44a735f63669\\n\\n(TensorFlow)\\nDeep Learning実践開発講座（DL4US）\\n \\n\\n\\tKerasを用いて深層学習について手を動かしながら学べるコンテンツです．一通り進めることで，深層学習の概要を理解し実装できるようになります．\\nIntroduction to Deep Learning & Neural Networks with Keras\\n（英語のみ） \\n\\n\\tCourseraで公開されているKerasで深層学習を学ぶ講座です．修了まで約8時間かかるので，本ロードマップの時間をややオーバーしてしまいますが，Jupyter Notebook形式で配布される演習を中心的に進めるといいでしょう．\\nIntroduction to TensorFlow using Keras\\n（英語のみ） \\n\\n\\tMicrosoft Learnで公開されている講座です．深層学習を学ぶには不十分ですが，Kerasを動かしてニューラルネットワークを学習・予測する方法について最短で学ぶことができます．\\nPyTorch\\nPyTorch official quickstart tutorial\\n（英語） \\n\\n\\tGoogle Colabですぐに動かすことができ，PyTorchで最も簡単なデータセットでモデルを学習する一通りを経験することができます．これをやったあとは個別のより細かいチュートリアルに進んだり，\\n\\tPyTorch Hub\\n\\tから学習済みの大規模モデルなどをダウンロードしてより難しいタスクに使ってみたりするのが良いでしょう．\\n200時間コースほど詳しく学ぶことはできませんが，本コースを終えることで，深層学習モデルを自分で実装し動かせるようになります．次のステップとして，自分で課題を設定しデータセットを準備して深層学習モデルを学習させてみましょう．\\nKaggle\\nなどのデータサイエンスコンペに参加すれば自分でデータを用意する必要もなく，実践的にノウハウを学ぶことができます．\\nなお，ここでは最も手っ取り早く使える\\nKeras\\n (\\nTensorFlow\\n)のコースを中心に紹介しましたが，200時間コースでは\\nPyTorch\\nによるものを中心に紹介しています．PyTorchとTensorFlowの普及率は同程度なので，両方とも触ってみてどちらが好みに合うかを選ぶのも良いでしょう．まだ日本語のドキュメントは少ないですが，新しく動作が速い\\nJAX\\nをはじめから選ぶのも手です．\\nb.\\n\\npage_id: c86e4d11-41fe-4f26-bcaf-44a735f63669\\n\\n(\\nTensorFlow\\n)のコースを中心に紹介しましたが，200時間コースでは\\nPyTorch\\nによるものを中心に紹介しています．PyTorchとTensorFlowの普及率は同程度なので，両方とも触ってみてどちらが好みに合うかを選ぶのも良いでしょう．まだ日本語のドキュメントは少ないですが，新しく動作が速い\\nJAX\\nをはじめから選ぶのも手です．\\nb. 200時間コース\\n200時間コースでは，まず人工知能の概要について掴んだ後に，数学やプログラミングの勉強へと進み，機械学習・深層学習について勉強や実装をします．最終的に自分で深層学習に関わるプロジェクトに取り組むところまでを目指します．\\n対象者\\nPythonプログラミングの経験がない，または数学に自信はないが，機械学習・深層学習の背景にある理論まで理解して動かせるようになりたい方\\nこのコースを完了することで，最新論文を読んだり，解決したい問題があったときに自分で機械学習モデルを実装したりすることができるようになります．また，最も重要なこととして，わからないことや忘れたことがあったときにどう検索したら良いのか，何を見たら良いのかといったことがわかるようになります．\\nここで学んだことを活かしてインターンシップなどを始めるのも良いでしょう．\\n5. 機械学習・深層学習の勉強・実装\\nで紹介するコースの多くは修了証をもらえるものなので，実力を示すという意味でも助けとなるはずです．\\n1. 人工知能の概要についての勉強（学習想定時間：20時間）\\nまずは人工知能の概要や歴史的背景について学びます．以下の本などがおすすめです．\\n人工知能は人間を超えるか\\n \\n\\n\\t人工知能とは何かを知りたい場合は，まず読むといいでしょう．\\n深層学習教科書 ディープラーニング G検定（ジェネラリスト） 公式テキスト\\n \\n\\n\\tディープラーニング協会の\\n\\tG検定\\n\\tの公式テキストです．より網羅的で実用的な内容なので，先に読むと他の本が読みやすくなるでしょう．\\n人工知能のアーキテクトたち\\n \\n\\n\\t著名な人工知能研究者へのインタビュー集です．網羅的な内容ですが，興味のある研究者から先にピックアップして読んでいくこともできます．\\n2.\\n\\npage_id: c86e4d11-41fe-4f26-bcaf-44a735f63669\\n\\n数学の勉強（学習想定時間：40時間）\\n機械学習や深層学習の理解に必要な「線形代数」「微分積分」「統計学」などについて最低限の内容を学びます．基本的には，それぞれの単元に関する教科書や参考書で勉強すれば良いですが，以下のような人工知能や機械学習に特化した数学の本で勉強するといいでしょう．\\n人工知能プログラミングのための数学がわかる本\\n \\n\\n\\t機械学習に関連したプログラミングに必要な数学を，初歩から体系的に学べます．\\n最短コースでわかる ディープラーニングの数学\\n \\n\\n\\t高校1年生レベルから深層学習に必要な最小限の数学について説明しています．\\n機械学習のエッセンス\\n \\n\\n\\t機械学習のための数学の基本（ベクトル，線形代数，微積分）を始め，Pythonのプログラミング （\\n\\tNumPy\\n\\t，\\n\\tSciPy\\n\\t，\\n\\tJupyter Notebook\\n\\t）や機械学習アルゴリズムの実装を含んでいます．\\n最初に数学の勉強をするのが大変だったり，なかなかモチベーションが続かない場合は，先に\\n3.プログラミングの勉強\\nに進んでも構いません．その際に，以下のようなプログラミングを動かしながら数学を学ぶ本も利用してみるといいでしょう．\\nプログラマのためのディープラーニングのしくみがわかる数学入門\\n \\n\\n\\t数式をコーディングから学ぶ形式になっています．\\npythonで動かして学ぶ！あたらしい数学の教科書―機械学習・深層学習に必要な基礎知識\\n \\n\\n\\tコードを書きながら数学を学ぶような形式になっています．対象読者に文系・非エンジニアも含まれています．\\nまた，\\n3Blue1Brown\\nのように数学の理解を大きく助けてくれるYouTube動画などもあります．このページでは紹介しませんが，機械学習を学ぶ上でネット上の記事や動画を活用するのは必須のスキルと言えるでしょう．\\n3.\\n\\npage_id: c86e4d11-41fe-4f26-bcaf-44a735f63669\\n\\nプログラミングの勉強（学習想定時間：40時間）\\n機械学習や深層学習を理解し実装するために，プログラミングについて学びましょう．ここでは，プログラミング言語としてPythonを学びます．中でもPythonの数値計算ライブラリである\\nNumPy\\nの使用は，Pythonで機械学習をするにあたりほぼ必須となります．\\n以下の教材などを利用して，基本的なPythonの実装の仕方を学びましょう．Pythonプログラミングを勉強する際は，環境構築が不要でブラウザから実行できる\\nGoogle Colaboratory\\nを利用することをおすすめします．他にも類似の無料で利用できるサービスとして，\\nKaggle Notebook\\nやAmazon \\nSageMaker Studio Lab\\nなどがあります．\\nゼロからのPython入門講座\\n \\n\\n\\tWeb上で公開されているPython公式の入門講座です．初めてプログラミングを触る人を想定して作られていて，\\n\\tGoogle Colaboratory\\n\\tの使い方についても説明されているので，最初に取り組むと良いでしょう．\\nPythonプログラミング入門\\n \\n\\n\\t東京大学 数理・情報教育研究センターが公開しているPythonを学ぶための教材です．全てを網羅する必要はありませんが，NumPyの使い方はしっかり身につけましょう．\\n独習Python\\n \\n\\n\\tPythonの基礎的な構文からオブジェクト指向，一部標準ライブラリの利用方法まで網羅的にまとめられている本です．\\nNumPyのメソッドは無数にあり，一度で覚え切れるようなものではありません．NumPyの\\nAPI reference\\nは，今後何度も訪れるページになるでしょう（Pandasやscikit-learn，PyTorchなどについても同様）．\\n4. PythonやNumPyを用いたデータ分析の方法を学ぶ（学習想定時間：30時間）\\n3.\\n\\npage_id: c86e4d11-41fe-4f26-bcaf-44a735f63669\\n\\nPythonやNumPyを用いたデータ分析の方法を学ぶ（学習想定時間：30時間）\\n3. プログラミングの勉強\\nで学んだPythonやNumPyを使って，データが与えられた時に，どのように読み込みや分析を行えばいいかについて学びましょう．以下の教材がおすすめです．\\n東京大学グローバル消費インテリジェンス寄附講座\\n \\n\\n\\tデータ分析の流れを手を動かしながら学ぶことができます．公開講座は学生ならば誰でも受講することができます．自習のための\\n\\t演習コンテンツ\\n\\tも公開されています．\\n東京大学のデータサイエンティスト育成講座\\n \\n\\n\\t上記の講座の書籍版です．\\nKaggleの入門用コンペティションである\\nTitanic – Machine Learning from Disaster\\nに参加してみるのもおすすめです．Codeタブから他の参加者のコード，特に評価の高いコードとその説明を読めるため，データの扱い方について手っ取り早く学ぶことができます．また，\\nscikit-learn\\nなどを用いたシンプルな機械学習モデルで十分解けるタスクなので，\\n5.機械学習・深層学習の勉強・実装\\nの予習にもなります．\\n5. 機械学習・深層学習の勉強・実装（学習想定時間：70時間）\\nいよいよ機械学習や深層学習についての勉強に入っていきます．ここまでの流れで基本的な知識や実装能力は身についているはずなので，以下のような演習付きの講義などを受講してみるといいでしょう．\\nDeep Learning基礎講座\\n \\n\\n\\t松尾研究室が2015年から毎年4月〜開講している講義で，深層学習の基礎から最新トピックまで扱っています．各講義回でプログラミング演習があるので，手を動かしながら深層学習について学ぶことができます．学生ならば誰でも受講することができます．\\nMIT Introduction to Deep Learning\\n（英語のみ） \\n\\n\\tマサチューセッツ工科大（MIT）によって公開されている講義で，深層学習の基礎から自動運転・音声合成などの応用的な内容まで網羅的に学ぶことができます．こちらも講義ビデオとスライドの両方が公開されており，演習も用意されています．\\nCS230 Deep Learning\\n（英語のみ）\\n\\npage_id: c86e4d11-41fe-4f26-bcaf-44a735f63669\\n\\nIntroduction to Deep Learning\\n（英語のみ） \\n\\n\\tマサチューセッツ工科大（MIT）によって公開されている講義で，深層学習の基礎から自動運転・音声合成などの応用的な内容まで網羅的に学ぶことができます．こちらも講義ビデオとスライドの両方が公開されており，演習も用意されています．\\nCS230 Deep Learning\\n（英語のみ） \\n\\n\\tスタンフォード大学による講義です．シラバスから講義スライドを閲覧することができます．画像系の内容が中心になりますが，\\n\\tCS231 Deep Learning for Computer Vision\\n\\tもおすすめです．\\nNeuromatch Academy: Deep Learning\\n（英語のみ） \\n\\n\\tNeuromatch Academyによって毎年開催されている講義です．コンテンツがすべてJupyter Notebook上で完結していて説明動画も埋め込まれているので，Google Colab上で実装を進めながら学ぶことができます．\\n上記のような講義と合わせて，以下のような深層学習の定番本も活用するといいでしょう．\\nゼロから作るDeep Learning\\n \\n\\n\\t本書では深層学習の基本的な構成要素のすべてをほぼNumPyのみを使って実装するため，PyTorchやTensorFlowといった深層学習用ライブラリを利用し始める前に経験しておくととても良い内容になっています．\\n深層学習（岡谷貴之著）\\n \\n\\n\\t岡谷貴之先生による深層学習の定番本です．深層学習について基礎からしっかり学ぶことができます．改訂版では最近の話題を含み大幅にボリュームアップしています．\\n詳解ディープラーニング\\n \\n\\n\\t深層学習について数学の基礎から扱っています．実装例も充実しています．\\n深層学習（Ian Goodfellow著）\\n \\n\\n\\tIan Goodfellow先生やYoshua\\n\\npage_id: c86e4d11-41fe-4f26-bcaf-44a735f63669\\n\\n岡谷貴之先生による深層学習の定番本です．深層学習について基礎からしっかり学ぶことができます．改訂版では最近の話題を含み大幅にボリュームアップしています．\\n詳解ディープラーニング\\n \\n\\n\\t深層学習について数学の基礎から扱っています．実装例も充実しています．\\n深層学習（Ian Goodfellow著）\\n \\n\\n\\tIan Goodfellow先生やYoshua Bengio先生らによる深層学習についての名著です．ボリュームがあり最初に学ぶ本としては難しいかもしれませんが，複数の本や講義で深層学習を勉強した後に読むと，様々な発見があるはずです．\\nここまで学べば，深層学習について理解し，自分で実装できるようになっているはずです．学んだ内容に基づいて，是非自分でプロジェクトを立ち上げて取り組んでみてください．さらに高度な内容を身につけたい場合は，松尾研究室が主催している\\nサマースクール\\nなどに参加することをおすすめします．\\nエンジニアを目指す人は，自分で課題を設定し，データセットを用意して取り組んでみましょう．問題設定に迷っている方は，前述の\\nKaggle\\nなどに参加してみましょう．Kaggleでは，さまざまな問題設定に対してデータセットが用意されており，チュートリアルに取り組んだりコンペティションに参加することができます（日本語のものから始めるのであれば\\nSIGNATE\\n, \\nProbSpace\\n,\\n\\npage_id: c86e4d11-41fe-4f26-bcaf-44a735f63669\\n\\nProbSpace\\n, \\nNishika\\nなどもあります）．こちらでモデルの性能を向上させる工夫について試行錯誤しながら学びましょう．\\n研究者を目指す人は，是非論文や解説記事を読んで再現実装や実験をしてみてください．興味のある論文を選ぶといいですが，Twitterなどで話題となっている内容や\\nDeep Learning Monitor\\nでトレンド上位の論文を選んでみてもいいでしょう．話題の論文を理論含めて要約している\\nAI-SCHOLAR\\nもおすすめです．また，最近の論文はソースコードもGithubなどで公開していることが多いので\\nPapers with Code\\nなどを利用して，論文の実装を探してみて，自分で動かしてみましょう．また最新の内容をキャッチアップするためには，松尾研究室主催の\\nDeep Learning輪読会\\nをはじめとした輪読会に参加することをお勧めします．この輪読会は，松尾研主催講義を受講した人ならば，誰でも参加可能です．また，人工知能系の国際会議に参加することで，最新の内容をキャッチアップすることができます．\\n2. 社会人向け\\n社会人向けでは，深層学習技術を使ってビジネス展開やその産業応用をすることを念頭にロードマップを作成しています．数学の勉強は比較的少なめにして，人工知能による社会への影響や産業応用の理解や実装に重点をおきます．\\na.\\n\\npage_id: c86e4d11-41fe-4f26-bcaf-44a735f63669\\n\\n社会人向け\\n社会人向けでは，深層学習技術を使ってビジネス展開やその産業応用をすることを念頭にロードマップを作成しています．数学の勉強は比較的少なめにして，人工知能による社会への影響や産業応用の理解や実装に重点をおきます．\\na. 10時間コース\\n対象者\\n時間がないが，とにかく早めに習得して問題解決に人工知能を役立てたいという方\\n経営をしていて，人工知能の概要や活用方法について学びたいという方\\nある程度実装などに時間を取れる方は，学生向けの\\n10時間コース\\nを進めるといいでしょう．\\n経営者の方で，人工知能の概要や活用方法を簡単に学びたいという方は，以下の本から読み進めると良いと思います．ただし，経営者の方もDL4USなどの教材を使って，実装から学習までの流れを体験していただいた方が，今後のAI Transformationの戦略を考える上で間違いなく役立つでしょう．\\n東大生も学ぶ「AI経営」の教科書 \\n\\n\\t東京大学 AI経営寄付講座\\u200b\\u200b\\n\\tの内容を学ぶことができます．\\n世界のトップ企業 50 は AI をどのように活用しているか？\\n \\n\\n\\t世界のトップ企業のAIの活用法を簡潔にまとまっています．\\nビジネスパーソンのための人工知能入門\\n \\n\\n\\tビジネスパーソンを対象に人工知能や深層学習についてわかりやすく解説しています．\\nb. 200時間コース\\n対象者\\nPythonプログラミングの経験がない，または数学に自信はないが，機械学習・深層学習の背景にある理論まで理解して動かせるようになりたい方\\n学生のようにまとまった時間を取るのが難しい方\\n1. 人工知能についての勉強（学習想定時間：40時間）\\n学生向けコースと同様，最初に人工知能に関する本を読んで概要の理解を深めましょう．この段階を学び終わったタイミングで，ディープラーニング協会の\\nG検定\\nを受験してみると，勉強したことの確認になり良いでしょう．\\n学生向けロードマップでご紹介した入門書の他に，10時間コースで紹介した産業応用やAI経営などに関連した本もお勧めです．\\n2.\\n\\npage_id: c86e4d11-41fe-4f26-bcaf-44a735f63669\\n\\nプログラミングの勉強（学習想定時間：40時間）\\n多忙な社会人の方は長い期間をかけて数学の勉強をするのはモチベーションの点からも難しいかもしれません．そのため，まずは（作業した結果がわかりやすい）プログラミングから始めてみましょう．プログラミングの勉強方法については，\\n学生向けコース\\nと同様です．プログラミングに慣れていない方にとっては大変だと思いますが，頑張りましょう．\\n3. PythonやNumPyを用いたデータ分析の方法を学ぶ（学習想定時間：30時間）\\nこちらも\\n学生向けコース\\nと同様です．5で説明する\\nE資格\\nの認定プログラムを受講する方は，こちらを飛ばしても構いません．\\n4. 数学の勉強（学習想定時間：20時間）\\n社会人向けのコースでも，深層学習の理解や実装のためには最低限の数学の勉強は必要です．学生と比べるとまとまった勉強時間を取りづらいかもしれませんが，学生向けの200時間コースで\\n紹介した本\\nなどを参考に，「線形代数」「微分積分」「統計学」について集中的に学びましょう．1~3と並行して進めてもいいですし，ここで完全に理解できなくても，以降の勉強の中でわからない箇所があれば，その都度戻って復習するといいでしょう．\\n5. 機械学習・深層学習の勉強・実装（学習想定時間：70時間）\\n社会人の方は決まったスケジュールのあるコースやサマースクールなどに参加することは難しいと想定し，以下のコースをお勧めします．また，学生向けコースで紹介した\\n定番本\\nを参考に勉強しましょう．\\nNYU Deep Learning\\n \\n\\n\\tニューヨーク大学（NYU）のYann LeCun先生による深層学習の講義です．スライドやコード，講義ビデオは全て公開されており自習することができます．レクチャーノートは複数の言語で翻訳されていて，2020年度の講義内容は複数のボランティアによって\\n\\t日本語に翻訳されています\\n\\t．\\nDeep Learning Lecture Series 2020\\n（英語のみ） \\n\\n\\tDeepMindとユニヴァーシティ・カレッジ・ロンドン（UCL）による講義です．こちらも講義ビデオとスライドの両方を閲覧することができます．\\n11-785 Introduction to Deep Learning\\n（英語のみ）\\n\\npage_id: c86e4d11-41fe-4f26-bcaf-44a735f63669\\n\\nLearning Lecture Series 2020\\n（英語のみ） \\n\\n\\tDeepMindとユニヴァーシティ・カレッジ・ロンドン（UCL）による講義です．こちらも講義ビデオとスライドの両方を閲覧することができます．\\n11-785 Introduction to Deep Learning\\n（英語のみ） \\n\\n\\tカーネギーメロン大学（CMU）の講義です．各回の宿題も公開されているので，自習する場合でもしっかり学ぶことができます．\\nUvA Deep Learning Tutorials\\n（英語のみ） \\n\\n\\tアムステルダム大学の講義で使われている演習コンテンツです．上記と同様コンテンツが全てJupyter Notebookでまとめられています．PyTorch以外にもJAX（Google発の深層学習実装フレームワーク）による実装に基づいたコンテンツも公開されています．\\n社会人の方にはディープラーニング協会の\\nE資格\\nを受験してみることもお勧めします．E資格を受講するためには所定の\\n認定プログラム\\nを受講して修了する必要があります．受講には費用がかかってしまいますが，実装も含めてしっかり学ぶことができます．\\nここまで進めれば，人工知能や深層学習の基本的な理解だけでなく，それらの活用方法や実装方法についても身につけていると思います．\\n次に，自社などで現在抱えている問題に対して実際にどのように人工知能を用いることができるのかを検討してみましょう．エンジニアの方は，実際に問題解決のためのモデルを設計・実装し，データを集めて学習させてみましょう．それをベースラインとして，どのように性能を改善できるかを考えてみましょう．経営者の方は，自社内にAIチームを作り（メンバーにはこのロードマップに従って勉強してもらうといいでしょう），自社のどの部分をAI化できるかについて戦略を考えましょう．\\n\\npage_id: d8054dab-e267-4a5d-91c8-647cbd8c308e\\n\\npage_id: 0aef7453-8445-4680-92f6-62caf7958e63\\n\\npage_id: 64430a7b-2ba4-40f5-8486-b289cff63ea9\\n\\npage_id: 1a4acc6e-0466-40ca-b968-69c8ed63248e\\n\\npage_id: 15daad6b-4cc8-4037-a899-ed6a40917a45\\n\\n勉強について\\nエンジニアの皆さん。エンジニア以外の皆さん。\\n\\n ・勉強しようと思っているけど、何を勉強したらいいかわからない\\n\\n ・ネットを漁っても良質な教材が出てこない\\n\\n ・他人がどんなことをしているか気になる\\n\\n こんなお悩みありませんか？\\n\\n 今回は、有名企業の研修資料をまとめましたので、勉強のネタにしてみてはいかがでしょうか？\\n\\n 新人、ベテラン関係ありません！\\n\\n GWに暇を持て余したら、こちらをご覧くださいね\\nサイボウズ\\nサイボウズです。\\n\\n 22年度の内容が公開されていました。\\n2022年のエンジニア新人研修の講義資料を公開しました - Cybozu Inside Out | サイボウズエンジニアのブログhttps://blog.cybozu.io\\n■モバイルアプリ開発\\n\\n ■サイボウズのアジャイル・クオリティ\\n\\n ■MySQL - テストデータが偏るということ\\n\\n ■モブに早く慣れたい人のためのガイド\\n\\n ■テクニカルライティングの基本\\n\\n ■ソフトウェアテスト\\n\\n ■セキュリティ\\n\\n ■ソフトウェアライセンス\\n\\n 講義資料と講義動画まで公開されています。\\n\\n 資料が苦手な人でも学習が捗りますね。\\nラクス\\nこちらは、研修がかなり長く2ヶ月半もの研修期間をとっているようで\\n\\n 研修の集大成となる「技術研修発表会」の模様が記されています。\\n【2022年】新卒エンジニアの技術研修発表会を行いました！ - RAKUS Developers Blog | ラクス エンジニアブログhttps://tech-blog.rakus.co.jp\\n■サーバーサイド\\nJava\\nSpring boot\\nThymeleaf\\n ■フロントエンド\\nHTML\\nCSS\\nJavaScript\\njQuery\\nAjax\\n 主に、web周りの技術に関して研修が行われたようです。\\n チームごとにアプリケーション作成し、それぞれのチームの意見が\\n あって面白いです。\\nMIXI\\nあのスマホアプリで人気のあるmixiです。\\nミクシィの21新卒技術研修の資料と動画を公開します！https://mixi-developers.mixi.co.jp\\n■git研修\\n\\n ■データベース研修\\n\\n ■設計・テスト研修\\n\\n ■iOSアプリ開発研修\\n\\n ■Androidアプリ開発研修\\n\\n ■フロントエンド研修\\n\\n ■ゲーム開発（Unity）研修\\n\\n スライド資料と動画も付属していますし、\\n\\n native appsにも対応した研修内容となっています。\\nSEGA\\nSEGAはゲーム会社なので、数学についての資料を展開していますね。\\nクォータニオンとは何ぞや？：基礎線形代数講座 - SEGA TECH Bloghttps://techblog.sega.\\n\\npage_id: 15daad6b-4cc8-4037-a899-ed6a40917a45\\n\\nSEGA\\nSEGAはゲーム会社なので、数学についての資料を展開していますね。\\nクォータニオンとは何ぞや？：基礎線形代数講座 - SEGA TECH Bloghttps://techblog.sega.jp\\n基礎線形代数講座について記述されています。\\n第１講 イントロダクション\\n\\n 第２講 初等関数\\n\\n 第３講 ベクトル\\n\\n 第４講 行列 I：連立一次方程式\\n\\n 第５講 行列 II：線形変換\\n\\n 第６講 行列 III：固有値・対角化\\n\\n 第７講 回転の表現 I\\n\\n 第８講 回転の表現 II\\nゲーム会社なので、数学に重きを置いた内容になっています。\\nAI Shift\\nSQL研修の内容は、基本的には大学のデータベース講義で取り上げられるような基礎的なものです。まずは「データベースとは」という問いから始まり、簡単なRDBMSの歴史を振り返りました。\\n\\n とのこと。\\nSQL講習ですが、歴史まで遡って取り上げている研修資料は珍しいのではないでしょうか？\\n\\n データベースの設計についても触れています。\\nGMOペパボ\\n幅広い開発研修を行なっていて、\\n\\n セキュリティや機械学習に関しての資料もたっぷり。\\n\\n いやはや、本当に質の高い資料になってます。\\nApplibot\\nこれはすごい！\\n\\n 全11回の講義が無料で見放題！\\n\\n 講義&ハンズオン形式で、現場社員からゲーム開発に必要な技術について学んでもらい\\n\\n 全11回の実施で、22年度の内容は以下のようになっております。\\n第1回 モバイルゲーム開発概観\\n\\n 第2回 ゲームエンジン\\n\\n 第3回 データ設計\\n\\n 第4回 システム設計\\n\\n 第5回 テスト\\n\\n 第6回 チームビルディング\\n\\n 第7回 アルゴリズム\\n\\n 第8回 データ構造\\n\\n 第9回 通信\\n\\n 第10回 パフォーマンスチューニング\\n\\n 第11回 UNIXコマンド講座\\nその他\\n研修資料ではないですがAmazonが出している資料です。\\n\\n サイバーセキュリティに関して学べるので、エンジニア以外の方もぜひ！\\n\\n UIもサイバーぽくかっこいい！\\n最後に\\n色々な企業が資料を公開してくれています。\\n\\n 初級者中級者問わず、GWやお休みの日に一度目を通してみてはいかがでしょうか？\\nhttps://twitter.com/obg_ocr\\n\\n 「弊社でも様々な研修をスキルに応じて行っております。\\n\\n 是非TwitterのフォローやDM、マシュマロでの問い合わせもお待ちしております！」\\n\\npage_id: eff2bb61-73e6-4c22-b6d4-1b38c0ad5a09\\n\\npage_id: f091e3e9-380a-4097-9691-9fcdfbba533e\\n\\n昨年、\\n株式会社松尾研究所\\n（東京大学松尾研とビジョンを共有）に転職しました。\\n現在は技術顧問の松尾先生のもと、AI系のビジネス活用に向けた基礎研究寄りの業務に従事しています（リサーチャー職）。\\n本記事では社内の有志向けに実施した、私が普段実施している情報収集元の紹介です。\\n私は現在、「企業での基礎研究者」的立場ですが、AI系は基礎研究から開発、ビジネスの距離が近いため、ビジネス関連の情報も幅広く見るように心がけています。\\n以下、\\n毎朝チェックしている情報\\n週単位でチェックしている情報\\n月単位でチェックしている情報\\nの順番に紹介いたします。\\n1. 毎朝チェック\\n1.1 最新の研究情報\\n最新のAI系研究論文の調べ方ですが、私は \\n「labml.ai」\\n の \\n「Find latest and trending machine learning papers」\\n を使用しています。\\nこちらのサイトでは、Twitterのいいねやリツイートの多さで論文をピックアップしており、毎日単位、週単位など任意の期間、また任意のキーワードで最新論文を検索・表示できます。\\nそしてその論文のAbstを読んだり、Summaryを見たり、論文PDFを開いたりできます。\\nlabml.aihttps://labml.ai\\n[1] まず、daily単位でこの24時間で話題になっている論文をざっとチェックします\\nhttps://papers.labml.ai/papers/daily/\\n[2] 次に、自身の研究に関連のあるキーワードで検索して、この24時間で話題になっている論文をチェックします\\n例えば「GPT」というキーワードでこの24時間に話題の論文であれば、以下のURLになります\\nhttps://papers.labml.ai/papers/daily/GPT\\n（labml.aiでの論文チェックの様子）\\n\\n情報収集を目的にTwitterのタイムラインを追うのは大変なので、私はこの「labml.ai」をメインにしています。\\n1.2 最新の技術情報\\n技術系の情報については、はてなブックマークの「テクノロジー」、「AI・機械学習」をざっと見て、気になる記事がないかを調べます。\\nはてなブックマーク - 人気エントリー - テクノロジーhttps://b.hatena.ne.jp\\nはてなブックマーク - 新着エントリー - テクノロジー - AI・機械学習https://b.hatena.ne.jp\\n1.\\n\\npage_id: f091e3e9-380a-4097-9691-9fcdfbba533e\\n\\nai」をメインにしています。\\n1.2 最新の技術情報\\n技術系の情報については、はてなブックマークの「テクノロジー」、「AI・機械学習」をざっと見て、気になる記事がないかを調べます。\\nはてなブックマーク - 人気エントリー - テクノロジーhttps://b.hatena.ne.jp\\nはてなブックマーク - 新着エントリー - テクノロジー - AI・機械学習https://b.hatena.ne.jp\\n1.3 最新のAIビジネス寄りの情報\\nAI系の技術系情報とビジネス系情報を厳密に切り分けるのは難しいですが、ビジネス寄りの情報については、\\nITmedia\\nの「社会とIT」、「AI+」の最新記事をざっとチェックします\\n社会とIT - ITmedia NEWShttps://www.itmedia.co.jp\\nAI+ by ITmedia NEWShttps://www.itmedia.co.jp\\n（上記サイトの雰囲気）\\n\\n1.4 もう少しビジネス寄りの情報系収集\\nもう少し、AIに限らず、テックビジネス系の最新情報のチェックとして、\\n「Business Insider」\\n をチェックしています。\\n「ビジネス」、「テクノロジー」、「サイエンス」のニュースをチェックします。\\nhttps://www.businessinsider.jp/business/\\nhttps://www.businessinsider.jp/sai/\\nhttps://www.businessinsider.jp/science/\\n（上記サイトの雰囲気）\\n\\n他には、\\nダイヤモンド・シグナル\\nも、先端技術を活用したビジネス寄りの情報収集先としてチェックしています。\\n※ダイヤモンド社のオンライン・ビジネスメディア\\n\\tDIAMOND SIGNALでは、テクノロジーを武器に新たな事業を生み出すスタートアップ起業家や業界関係者、組織をデジタル化し変革するビジネスリーダーのために、明日からの行動のヒントとなる深掘りニュースや連載コンテンツを提供していきます。\\nDIAMOND SIGNAL（ダイヤモンド・シグナル）https://signal.diamond.jp\\n以上が毎朝チェックするサイトです。\\nなお、ブラウザを立ち上げたときに、ここまでに紹介した全ページが自動で開くように、\\nブラウザの「起動時の設定」にて、「これらのページを開く」的な部分に、起動時に開くURLとして設定しています\\n。\\nURLべた書きを再掲いたします。\\nhttps://papers.labml.ai/papers/daily/\\nhttps://b.hatena.ne.jp/hotentry/it\\nhttps://b.hatena.ne.jp/entrylist/it/AI%E3%83%BB%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\nhttps://www.itmedia.co.jp/news/subtop/society/\\nhttps://www.itmedia.co.jp/news/subtop/aiplus/\\nhttps://www.businessinsider.jp/business/\\nhttps://www.businessinsider.jp/sai/\\nhttps://www.businessinsider.jp/science/\\nhttps://www.businessinsider.jp/tag/start-up/\\nhttps://signal.diamond.jp/\\n\\n1.\\n\\npage_id: f091e3e9-380a-4097-9691-9fcdfbba533e\\n\\nURLべた書きを再掲いたします。\\nhttps://papers.labml.ai/papers/daily/\\nhttps://b.hatena.ne.jp/hotentry/it\\nhttps://b.hatena.ne.jp/entrylist/it/AI%E3%83%BB%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\nhttps://www.itmedia.co.jp/news/subtop/society/\\nhttps://www.itmedia.co.jp/news/subtop/aiplus/\\nhttps://www.businessinsider.jp/business/\\nhttps://www.businessinsider.jp/sai/\\nhttps://www.businessinsider.jp/science/\\nhttps://www.businessinsider.jp/tag/start-up/\\nhttps://signal.diamond.jp/\\n\\n1.5 毎朝のメルマガでチェックする情報\\nサイトではなく、毎日単位で来るように設定しているメルマガとしては、\\n[1] Mediumの「Medium daily digest」\\nMedium – Where good ideas find you.https://medium.com\\n[2] 各種「Inside」の情報\\n日本における「日経」の存在は非常にありがたく、ビジネスからコンピュータ・IT情報から各種を整理して発信してくれます。\\n世界における「日経」的な存在の企業は存在しないと思っているのですが、それに近い情報源として、私は\\nInside.com\\nを使用しています\\n他には、\\nThe Verge\\n、\\nArs Technica\\n、も良い情報源ですが、Insideのコンセプトである、「メールで読みやすいように届けてくれる」が使いやすいので、Insideを使用しています。\\nInside\\n\\tThe latest in business, tech, and venture capital delivered daily to your inbox. Subscribe for free at Inside.com.\\nInside.com: The Best Business Community For Any Topichttps://inside.com\\nInsideのNewsletterのうち、「AI」、「Business」、「NoCode」、「Dev」、「Tech」のメールマガジンをサブスクライブしています（無料です）。\\n[3] TLDR\\nTLDRは以下の解説の通り、技術、IT、スタートアップ系のその日の重要ニュースを簡潔にまとめて届けてくれます（23年4月から変更があり、カテゴリーごとにメルマガが分割されるようです）。\\n\\tTLDR is the free daily newsletter with links and TLDRs of the most interesting stories in startups 🚀, tech 📱, and programming 💻!\\n（上記3つのメルマガの雰囲気）\\n以上、毎朝チェックする情報の紹介でした。\\n続いては、週単位でチェックする・届く情報を紹介します。\\n2.\\n\\npage_id: f091e3e9-380a-4097-9691-9fcdfbba533e\\n\\n（上記3つのメルマガの雰囲気）\\n以上、毎朝チェックする情報の紹介でした。\\n続いては、週単位でチェックする・届く情報を紹介します。\\n2. 週単位でのチェック\\n2.1 最新の研究情報（YouTube）\\n研究論文に関する動画解説は多々ありますが、私は \\n「Two Minute Papers」\\n の動画解説をチェックしています。\\n2.2 最新の研究情報（メルマガ系）\\n週単位で届く、最新研究の紹介メルマガで活用しているのは、以下の3つになります。\\n[1] Deep Learning Weekly\\n[2] Import AI\\n[3] arXiv roundup\\n（上記3つのメルマガの雰囲気）\\n2.3 最新の開発者向け情報（メルマガ系）\\n週単位で届く最新の「データサイエンス系」や「開発系」のメルマガで活用しているのは以下の4つになります。\\n[4] Weekly Kaggle News\\n「毎週金曜日に日本語でKaggleに関する話題をお届けするニューズレター」\\n[5] Data Science Weekly\\n[6] Python Weekly\\n[7] The Machine Learning\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: SQLを勉強するのに良い資料は？\\nAnswer: '}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.1}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.connection:close.started\n",
      "DEBUG:httpcore.connection:close.complete\n",
      "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=60.0 socket_options=None\n",
      "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1673bea10>\n",
      "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x166a63da0> server_hostname='api.openai.com' timeout=60.0\n",
      "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x167bc5090>\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 01 Aug 2024 16:35:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-01p8otbt5gis2mt84rnzemio'), (b'openai-processing-ms', b'3652'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'188591'), (b'x-ratelimit-reset-requests', b'8.64s'), (b'x-ratelimit-reset-tokens', b'3.422s'), (b'x-request-id', b'req_d80b1936a55815ab872a10e98b5ca9eb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=0l2iS2jFqc9w3rR6NV2.4GC0hEbUs4JhDnKAvF2JzRc-1722530112-1.0.1.1-2D_npRPEPxMzKAdNuFQvLKkkaqYpMKL9fqeYK0q97xfOi7b2gybO..HSvRKikCYAoqa2iozyUBd..06aBiZRSw; path=/; expires=Thu, 01-Aug-24 17:05:12 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ac73d5d6a7d688c-NRT'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Thu, 01 Aug 2024 16:35:12 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-01p8otbt5gis2mt84rnzemio', 'openai-processing-ms': '3652', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9999', 'x-ratelimit-remaining-tokens': '188591', 'x-ratelimit-reset-requests': '8.64s', 'x-ratelimit-reset-tokens': '3.422s', 'x-request-id': 'req_d80b1936a55815ab872a10e98b5ca9eb', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=0l2iS2jFqc9w3rR6NV2.4GC0hEbUs4JhDnKAvF2JzRc-1722530112-1.0.1.1-2D_npRPEPxMzKAdNuFQvLKkkaqYpMKL9fqeYK0q97xfOi7b2gybO..HSvRKikCYAoqa2iozyUBd..06aBiZRSw; path=/; expires=Thu, 01-Aug-24 17:05:12 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ac73d5d6a7d688c-NRT', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_d80b1936a55815ab872a10e98b5ca9eb\n",
      "DEBUG:llama_index.core.response_synthesizers.refine:> Refine context: SIGNALでは、テクノロジーを武器に新たな事業を生み出すスタートアップ起業家や業界関係者、組...\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are an expert Q&A system that strictly operates in two modes when refining existing answers:\\n1. **Rewrite** an original answer using the new context.\\n2. **Repeat** the original answer if the new context isn\\'t useful.\\nNever reference the original answer or context directly in your answer.\\nWhen in doubt, just repeat the original answer.\\nNew Context: SIGNALでは、テクノロジーを武器に新たな事業を生み出すスタートアップ起業家や業界関係者、組織をデジタル化し変革するビジネスリーダーのために、明日からの行動のヒントとなる深掘りニュースや連載コンテンツを提供していきます。\\nDIAMOND SIGNAL（ダイヤモンド・シグナル）https://signal.diamond.jp\\n以上が毎朝チェックするサイトです。\\nなお、ブラウザを立ち上げたときに、ここまでに紹介した全ページが自動で開くように、\\nブラウザの「起動時の設定」にて、「これらのページを開く」的な部分に、起動時に開くURLとして設定しています\\n。\\nURLべた書きを再掲いたします。\\nhttps://papers.labml.ai/papers/daily/\\nhttps://b.hatena.ne.jp/hotentry/it\\nhttps://b.hatena.ne.jp/entrylist/it/AI%E3%83%BB%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\nhttps://www.itmedia.co.jp/news/subtop/society/\\nhttps://www.itmedia.co.jp/news/subtop/aiplus/\\nhttps://www.businessinsider.jp/business/\\nhttps://www.businessinsider.jp/sai/\\nhttps://www.businessinsider.jp/science/\\nhttps://www.businessinsider.jp/tag/start-up/\\nhttps://signal.diamond.jp/\\n\\n1.\\n\\npage_id: f091e3e9-380a-4097-9691-9fcdfbba533e\\n\\nURLべた書きを再掲いたします。\\nhttps://papers.labml.ai/papers/daily/\\nhttps://b.hatena.ne.jp/hotentry/it\\nhttps://b.hatena.ne.jp/entrylist/it/AI%E3%83%BB%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92\\nhttps://www.itmedia.co.jp/news/subtop/society/\\nhttps://www.itmedia.co.jp/news/subtop/aiplus/\\nhttps://www.businessinsider.jp/business/\\nhttps://www.businessinsider.jp/sai/\\nhttps://www.businessinsider.jp/science/\\nhttps://www.businessinsider.jp/tag/start-up/\\nhttps://signal.diamond.jp/\\n\\n1.5 毎朝のメルマガでチェックする情報\\nサイトではなく、毎日単位で来るように設定しているメルマガとしては、\\n[1] Mediumの「Medium daily digest」\\nMedium – Where good ideas find you.https://medium.com\\n[2] 各種「Inside」の情報\\n日本における「日経」の存在は非常にありがたく、ビジネスからコンピュータ・IT情報から各種を整理して発信してくれます。\\n世界における「日経」的な存在の企業は存在しないと思っているのですが、それに近い情報源として、私は\\nInside.com\\nを使用しています\\n他には、\\nThe Verge\\n、\\nArs Technica\\n、も良い情報源ですが、Insideのコンセプトである、「メールで読みやすいように届けてくれる」が使いやすいので、Insideを使用しています。\\nInside\\n\\tThe latest in business, tech, and venture capital delivered daily to your inbox. Subscribe for free at Inside.com.\\nInside.com: The Best Business Community For Any Topichttps://inside.com\\nInsideのNewsletterのうち、「AI」、「Business」、「NoCode」、「Dev」、「Tech」のメールマガジンをサブスクライブしています（無料です）。\\n[3] TLDR\\nTLDRは以下の解説の通り、技術、IT、スタートアップ系のその日の重要ニュースを簡潔にまとめて届けてくれます（23年4月から変更があり、カテゴリーごとにメルマガが分割されるようです）。\\n\\tTLDR is the free daily newsletter with links and TLDRs of the most interesting stories in startups 🚀, tech 📱, and programming 💻!\\n（上記3つのメルマガの雰囲気）\\n以上、毎朝チェックする情報の紹介でした。\\n続いては、週単位でチェックする・届く情報を紹介します。\\n2.\\n\\npage_id: f091e3e9-380a-4097-9691-9fcdfbba533e\\n\\n（上記3つのメルマガの雰囲気）\\n以上、毎朝チェックする情報の紹介でした。\\n続いては、週単位でチェックする・届く情報を紹介します。\\n2. 週単位でのチェック\\n2.1 最新の研究情報（YouTube）\\n研究論文に関する動画解説は多々ありますが、私は \\n「Two Minute Papers」\\n の動画解説をチェックしています。\\n2.2 最新の研究情報（メルマガ系）\\n週単位で届く、最新研究の紹介メルマガで活用しているのは、以下の3つになります。\\n[1] Deep Learning Weekly\\n[2] Import AI\\n[3] arXiv roundup\\n（上記3つのメルマガの雰囲気）\\n2.3 最新の開発者向け情報（メルマガ系）\\n週単位で届く最新の「データサイエンス系」や「開発系」のメルマガで活用しているのは以下の4つになります。\\n[4] Weekly Kaggle News\\n「毎週金曜日に日本語でKaggleに関する話題をお届けするニューズレター」\\n[5] Data Science Weekly\\n[6] Python Weekly\\n[7] The Machine Learning Engineer\\n（上記4つのメルマガの雰囲気）\\n他にデータサイエンス系であれば、\\nData Elixir\\nもおすすめです。\\n2.4 その他、毎週のメルマガ系\\nその他、メルマガは以下の3種類です。\\n[8] AI Weekly\\nAI関連の時事ニュース、応用事例、倫理、研究、ロボット系など幅広く扱う週刊ニュースとしては、いろいろ試して、「AI Weekly」に落ち着いています（無料です）\\n[9] Weekly Robotics\\nロボット関連はAIとも関係性が強い重要な分野なので以下を読んでいます。\\n[10] JNEWS\\n最新ビジネスの内容を紹介してくれる情報源としては、JNEWS（Japan Business News）を活用しています。こちらは海外での最新のビジネス事例の情報が多く、とても気に入っています（※有料）。\\n（上記3つのメルマガの雰囲気・概要）\\n2.5 紙媒体の週刊雑誌系\\n[11] 日経ビジネス\\n「日経」から週刊で出版されている、ビジネス情報誌になります。\\n私はテレビを見ないので、包括的な時事ニュースを見る機会がなく、最新の時事情報に追いつくために「日経ビジネス」を読むようにしています。\\n電子版もあるのですが、紙媒体の方が個人的には読みやすいので（物理的・心理的に）、紙版を購読しています。\\n[12] 日経コンピュータ\\n\\npage_id: e2cd16fe-881a-4c04-8660-7b1314a71239\\n\\n今回は、今話題の ChatGPT と Notion の連携についてのご紹介です。 AI機能は Notion にも搭載されているので、すでに活用している人も多いと思います。\\n※参考記事：\\nNotion AI と Save to Notion を組み合わせて効率的なインプットを実現する\\nしかし「ChatGPT のデータを取得しっぱなしでうまくまとめられていない」「もっと効果的に活用する方法を探している」という方もいらっしゃるのではないでしょうか。そこで Notion の出番です。\\n今回は、Notion と ChatGPT を連携する方法をご紹介します。\\n「効率よく情報処理したい」「リサーチの結果を上手にまとめたい」「いつでも情報を引き出せるようにしておきたい」という方は、今回の記事が参考になると思います。ぜひ最後まで読んでみてください。\\nまず最初に確認しておくこと\\n拡張機能を利用するためには、ChatGPT と Notion のアカウントが必要です。ここでは、それぞれのアカウント設定が完了しているという前提で解説を進めていきます。ちなみに、どちらのサービスも無料プランで使用できます。\\nまた、NotionAI のプランを契約していなくても『ChatGPT to Notion』は使えます。\\n※ ChatGPT のアカウント作成はこちらから \\nhttps://chat.openai.com/\\n[\\n『 ChatGPT to Notion 』のセットアップ手順\\n](https://notion-lab.jp/2023-05-14-chatgpt-to-notion#%E3%80%8E%20ChatGPT%20to%20Notion%20%E3%80%8F%E3%81%AE%E3%82%BB%E3%83%83%E3%83%88%E3%82%A2%E3%83%83%E3%83%97%E6%89%8B%E9%A0%86)[\\n1.\\n\\npage_id: e2cd16fe-881a-4c04-8660-7b1314a71239\\n\\nNotion の新規ページにテーブルを作成する\\n](https://notion-lab.jp/2023-05-14-chatgpt-to-notion#1.%20Notion%20%E3%81%AE%E6%96%B0%E8%A6%8F%E3%83%9A%E3%83%BC%E3%82%B8%E3%81%AB%E3%83%86%E3%83%BC%E3%83%96%E3%83%AB%E3%82%92%E4%BD%9C%E6%88%90%E3%81%99%E3%82%8B)\\nまずは、Notion に ChatGPT の会話を追加する新規データベースを作成します。このデータベースを作成しておかないと『 ChatGPT to Notion 』は機能しません。\\n① 左側のサイドバー「ページを追加」から新しいページにテーブルを作成します\\n\\u3000ここではタイトルを「 ChatGPT to Notion 」としました。\\n「新規テーブル作成」\\n② 次に「新規データベース」をクリックして、データベースを作成します。\\n「ChatGPT to Notion 新規データベース作成」\\n③ 以下のようなテーブルが作成されるので「タイトル」「タグ」「日付」「URL」を設定します。いつ保存したかを確認したいときのために、日付プロパティがあると便利です。また、連携する際にタグの設定ができるので、あらかじめ必要なタグを準備しておくと効率よく格納できます。\\n「ChatGPT to Notion テーブル_項目設定」\\nこれで、格納用データベースの準備が完了しました。\\n2. Chrome拡張機能『 ChatGPT to Notion 』 をインストール\\nChrome ウェブストアから『\\nChatGPT to Notion\\n』を追加します。\\nChromeウェブストア 「ChatGPT to Notion」\\n拡張機能をインストール終了後、拡張機能が並んでる場所にアイコンが表示されない場合は、「設定」→「拡張機能」から固定して呼び出しておきましょう。\\n拡張機能「ChatGPT to Notion」を追加\\n追加完了画面\\nピンマークをクリックして固定\\n3.\\n\\npage_id: e2cd16fe-881a-4c04-8660-7b1314a71239\\n\\nChrome拡張機能『 ChatGPT to Notion 』 をインストール\\nChrome ウェブストアから『\\nChatGPT to Notion\\n』を追加します。\\nChromeウェブストア 「ChatGPT to Notion」\\n拡張機能をインストール終了後、拡張機能が並んでる場所にアイコンが表示されない場合は、「設定」→「拡張機能」から固定して呼び出しておきましょう。\\n拡張機能「ChatGPT to Notion」を追加\\n追加完了画面\\nピンマークをクリックして固定\\n3. 拡張機能とデータベースの連携\\n次に、 Chrome 拡張機能とデータベースの連携をしていきます。拡張機能が固定されたらアイコンをクリック、以下の画面から「ページを選択する」をクリックして次に進みます。\\n「ページを選択する」をクリック\\n以下の画面が表示されるので、連携させたいページを選択します。ここで、最初に作成したページ「 ChatGPT to Notion 」を選択、「アクセスを許可する」をクリックします。\\nNotionへのアクセスを許可\\n設定が完了すると一旦下図のように公式ページが表示されます。\\n設定完了後の画面\\n上記画面が確認できたら、最初に作った「 ChatGPT to Notion 」のデータベースを開きます。拡張機能をクリックすると以下のような画面がでてきます。\\n拡張機能→データベースとの連携を確認\\n「 ChatGPT to Notion 」にチェックを入れて設定完了です。チェックを入れた際に以下の画面が出てきますが、特に設定の必要はありません。これで連携が完了しました。\\nこの画面が出てきたら設定完了\\nChatGPT から Notion への保存方法と使い方\\nNotion への保存は驚くほど簡単です。ChatGPT を利用すると、ChatGPT からの答えの左横に「ピン止めマーク」が付くようになります。これをクリックすると最初に作成した Notion のデータベース「 ChatGPT to Notion 」へ保存されていきます。\\n1.\\n\\npage_id: e2cd16fe-881a-4c04-8660-7b1314a71239\\n\\nチャットデータ保存方法\\nChatGPT の解答のアイコンボタンにあるピンのマークをクリックするとポップアップが表示されます。データベース作成時にタグを設定しておけば、タグの選択もできます。\\nピンをクリック→ポップアップ表示→タグを選択→「Save」で保存完了\\n保存完了画面\\nNotion データベース「 ChatGPT to Notion 」に戻ると、下図のようにデータが収められているのを確認できます。\\n保存されたデータベース\\nそのままの設定では日付を手動で入力する必要があるので、自動で入力したい場合は以下も参考にしてみてください。\\nデータベースに保存されたリンク（URL）をクリックすると、過去にやりとりした ChatGPT の内容がブラウザで開きます。また、Notionデータベース内では下図のようにデータが収納されています。\\n2. 全ての会話を保存する方法\\n全ての会話を保存したい場合は、Chrome の拡張機能ボタンをクリックします。\\nすると「 Save full chat 」というボタンが表示されるのでこちらをクリックすれば完了です。\\n連続して質問したすべての会話を保存\\n3.\\n\\npage_id: e2cd16fe-881a-4c04-8660-7b1314a71239\\n\\n全ての会話を保存する方法\\n全ての会話を保存したい場合は、Chrome の拡張機能ボタンをクリックします。\\nすると「 Save full chat 」というボタンが表示されるのでこちらをクリックすれば完了です。\\n連続して質問したすべての会話を保存\\n3. Notion AI を活用する\\nChatGPT で集約したデータや文章を、さらにアレンジして使いやすくするには Notion AI の機能がおすすめです。NotionAI は、Notion 内でスペースを押せば呼び出せるので、こちらを活用して、文体や文字数の調整、翻訳なども、そのまま作業できます。\\nChatGPT から得た情報だけだと、文章量が多かったり、ニュアンスが異なるものが出てきたりということもありますよね。ChatGPT から適切な情報を引き出すためのプロンプトもたくさん出回っていますが、それを探すのも大変ですし、自分で考えるとなるとさらにハードルが上がります。\\nその点、NotionAI には「要約機能」などすぐに使える機能が備わっているので、ChatGPT の膨大な情報量をあっという間にまとめてくれます。\\n「ChatGPT」「Notion」 双方の利点を活かしてうまく活用するとよいのではないでしょうか。\\nおわりに\\n今回は、ChatGPT と Notion を連携する方法を中心にご紹介しました。どちらの AI も私たちの作業効率を間違いなく上げてくれる便利なツールです。単体で使用するよりも、今回のように合わせて使うことでより効果を発揮するのではないでしょうか。気になった方はぜひお試しください。\\n💡\\n初学者からでも安心して Notion を学べるオンラインコミュニティ「Notion 大学」を運営中。Notion コミュニティとしては国内最大規模で、会員数は現在200名以上となっております。\\n分からないことは24時間チャットツールでいつでも質問できる\\nコミュニティ内の限定勉強会でタスク管理や知識管理術が学べる\\n1から学べる Notion 学習ロードマップで初心者からでも学習可能\\nNotion 大学限定の学習動画が100本以上\\n定期的に開催している有料セミナーへの無料参加券\\n過去の有料記事・有料テンプレートが全て閲覧可能\\nコンテンツや特典盛りだくさんです。参加方法は下記の記事をご覧ください。\\n\\npage_id: d9273367-6bee-4d39-bb14-baae74cf46b9\\n\\npage_id: ad16b58a-5f15-4dc8-9e9e-e7915c2beeb7\\n\\nTAG: Dynalyst\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nTAG: Dynalyst\\n\\npage_id: a1e6abf3-44e8-47f2-900f-efbd23661ba4\\n\\nEnglish | \\n日本語\\nastro-notion-blog\\n\\n\\n\\nastro-notion-blog enables you to create a blog using \\nNotion\\n and generates it statically, resulting in lightning-fast page views.\\n\\nLightning-fast\\n page views\\n\\nWith the ability to write blog content in \\nNotion\\n\\n\\nCustomize\\n your site\\'s appearance to your liking\\n\\nTake advantage of \\nthe official Notion APIs\\n\\nScreenshots\\n\\nDemo\\nhttps://astro-notion-blog.pages.dev\\nQuick Start\\nRequirements\\nNotion\\nCloudflare Pages\\nGit\\nSteps\\nIf you enjoy using this repo, \\ndon\\'t forget to give it a star!\\n \\n \\n\\n\\n\\tThis is very motivating!\\nSimply duplicate \\nthe blog template\\n into your Notion workspace.\\nOnce you\\'ve duplicated the page (database), customize it to your liking by changing the icon, title, and description.\\n\\nFor future reference, identify the \\nDATABASE_ID\\n by noting the portion of the duplicated page (database) URL that appears as \\nhttps://notion.so/your-account/\\n?v=xxxx.\\n\\n\\nCreate an integration\\n and note \"Internal Integration Token\" as \\nNOTION_API_SECRET\\nTo integrate your application with Notion, \\nshare a database with your integration\\n.\\nTo make a copy of this repository in your own account, fork it by clicking on the \\'Fork\\' button in the top-right corner of the repository page.\\nGo to \\nCloudflare Pages\\n and sign in\\nCreate new project with \"Connect to Git\" with your forked repository \\n<your-account>/astro-notion-blog\\n, then click \"Begin setup\"\\nIn \"Build settings\" section, \\n\\n\\tSelect \"Astro\" as \"Framework preset\"\\n\\tOpen \"Environment Variables (advanced)\" and set \\n\\tNODE_VERSION\\n\\t, \\n\\tNOTION_API_SECRET\\n\\t and \\n\\tDATABASE_ID\\n\\t \\n\\t\\n\\t\\tNODE_VERSION\\n\\t\\t is \\n\\t\\tv16.13.0\\n\\t\\t or higher\\n\\t\\tHow to deploy a site with Git\\n\\t\\t is helpful\\n\\n\\nAfter clicking the \\'Save and Deploy\\' button, your Notion Blog will be published once the deployment process is complete.\\nPlease note that the astro-notion-blog requires manual deployment every time you publish a new post or make updates. You can deploy manually from the Cloudflare Pages dashboard or set up a scheduled deploy using CI tools such as GitHub Actions.\\nHow to customize\\nAdditional requirements\\nNode.js v16 or higher\\nYarn\\nSteps\\nTo set your secrets as environment variables, run the following commands in your terminal:\\nexport NOTION_API_SECRET=<YOUR_NOTION_API_SECRET>\\nexport DATABASE_ID=<YOUR_DATABASE_ID>\\nInstall dependencies and start local server\\nyarn install\\nyarn dev\\nOpen \\nhttp://localhost:3000\\n in your browser\\nPress \\nCtrl+C\\n in the terminal to stop\\nFor more information\\nSee \\nwiki\\n.\\nBug reports & feature requests\\nTo report an issue, please create a new Issue. You can use \\neither English or Japanese\\n to describe the issue.\\nTwitter community\\n\\nIn our community, you have the opportunity to both support and be supported by other members.\\nastro-notion-blog\\nContribution\\nWe welcome pull requests from anyone who wants to contribute to our project. Your contributions are greatly appreciated!\\nastro-notion-blog is based \\notoyo/notion-blog\\n\\npage_id: b7f3cf45-a85f-40aa-b4ea-43df7d62f380\\n\\npage_id: 3b514d33-5de1-4ee7-ab96-50bff1a3b36d\\n\\nこの記事は、一度使われて終わるような、ChatGPT にちょっとした機能を追加しただけの GPTではなく、\\n本当に使われる素晴らしく便利な GPTs を作成、開発するための教科書\\nとして、書きました。\\n今までの GPTs 開発関連の情報を全てまとめた内容になっています。\\nこの note 一冊を読めば、GPTs 制作の基礎から応用まで全部わかります。\\n記事の内容は必要に応じて適宜アップデートしていきます。\\n目次は以下です：\\n目次\\n第1章 GPTsの概要とその可能性\\nそもそも GPTs とはなんでしょうか？\\n一言で言うと、\\nChatGPTを自分独自に大幅にカスタマイズできる機能とそのカスタマイズされたAIのこと\\nです。\\nただし、GPTsを単なるChatGPT のいち機能の一つとして考えるのは非常にもったいないです。\\nOpenAI は、GPT Store という、他の人が作ったGPTsを使えるようになるストアのリリースを来年控えており、ここでお金を稼ぐこともできるようになると、公式にアナウンスしています。\\nまた、GPTs は、まだそのポテンシャルが知れ渡っていませんが、特に業務効率化の面において、非常に大きな影響をもたらすものです。\\nまだ余りポテンシャルが知られていないと言ったのは、\\n本当に質が高い GPTs の数がまだまだ少ない\\nからです。\\n良い GPT を作れる GPTs 開発者の数が不足\\nしています。\\n例えば、ChatGPT研究所メンバーが作った以下のような秘書GPTはカレンダーの管理に便利で、実際に日常で普段使いしています：\\n\\n\\tGPTの秘書化に成功\\n\\t紐づくGoogleカレンダー情報の表示、追加、削除、編集作業をしてくれる、秘書のように使えるGPTを作成しました。\\n\\t以下デモ動画のように「空いている時間に予定入れといて」のような雑な命令でも適切に判断して追加してくれるので便利です。以前と同様にこのGPTも運用コストゼロ \\n\\tpic.twitter.com/EIzKcBUpby\\n\\t— ChatGPT研究所 (@ctgptlb) \\n\\tDecember 4, 2023\\nこのGPT自身、まだまだ改善の余地があり、本当に質が高いGPTとは言いません。\\n参考までに、以下に\\nChatGPT研究所がこれまでに作成したGPTs\\n を列挙します。\\n\\npage_id: 3b514d33-5de1-4ee7-ab96-50bff1a3b36d\\n\\n以下デモ動画のように「空いている時間に予定入れといて」のような雑な命令でも適切に判断して追加してくれるので便利です。以前と同様にこのGPTも運用コストゼロ \\n\\tpic.twitter.com/EIzKcBUpby\\n\\t— ChatGPT研究所 (@ctgptlb) \\n\\tDecember 4, 2023\\nこのGPT自身、まだまだ改善の余地があり、本当に質が高いGPTとは言いません。\\n参考までに、以下に\\nChatGPT研究所がこれまでに作成したGPTs\\n を列挙します。：\\n8412個のGPTsから最適なGPTを探索：\\nGPT Finder\\nGoogle ログインをして Google カレンダーやGmailを管理：\\n秘書GPT（限定公開）\\nGrok のシステムプロンプトをハックしてGrokをコピー：\\nGrok GPT\\nサムネイル画像の作成を画像からテキストまで完全に自動化：\\nTnumbnail Sckether\\nGIF画像を自動生成する：\\nGIF Maker\\nKnowldge を与えてカスタマーサポートを自動化するGPT （非公開）\\n語彙力推定と頻度順に単語を学べるGPT：\\nAITAN\\nデヴィ夫人の人格を模倣した\\nデヴィ夫人AI\\nその他多数。少なくとも50個以上は作ってきています。\\n\\n\\nこの記事は、これらのGPTの制作経験をもとにして書いています。\\n公開しているGPTが、他のユーザーに使用された合計回数は現状3万5千回以上です。GPT Finder は単体で1万回以上利用されています：\\n\\n世界に目を向けると、単体で15万回以上も使用されている、\\nGrimorie\\n \\nと言う GPTがあります\\n：\\n\\nしかしはっきりいって、この Grimorie ですらまだまだ改善の余地があり、最高のGPTとは言えないと私は考えています。\\nここで言いたいのは、\\n\\n\\n今、GPTs領域には無限の可能性があり、\\n\\n\\nアプリストアが出てきた、あの2008年当時のように、\\n\\n\\n大きなチャンスが目の前に広がっていると言うことです。\\nこの note を書いた理由のひとつが、\\n\\n\\n日本から素晴らしい GPTs がどんどんと作られていき、\\n\\n\\n世界で使われるGPTが出てきて欲しいから\\nです。\\nこの note を読み、\\nあなたが実際に本当に便利なGPTsを作って、\\n\\n\\nそれをみんなに共有してくれることを願っています\\n。\\nGPT Store に出さずとも、\\n\\n\\n自分や社内専用のGPTを作るのも良いでしょう。\\n\\n\\n今後の業務効率を何倍にもアップさせる可能性を秘めています。\\nちゃんとしたGPTsを作れる人はまだまだ限られているため、\\n\\npage_id: 3b514d33-5de1-4ee7-ab96-50bff1a3b36d\\n\\n日本から素晴らしい GPTs がどんどんと作られていき、\\n\\n\\n世界で使われるGPTが出てきて欲しいから\\nです。\\nこの note を読み、\\nあなたが実際に本当に便利なGPTsを作って、\\n\\n\\nそれをみんなに共有してくれることを願っています\\n。\\nGPT Store に出さずとも、\\n\\n\\n自分や社内専用のGPTを作るのも良いでしょう。\\n\\n\\n今後の業務効率を何倍にもアップさせる可能性を秘めています。\\nちゃんとしたGPTsを作れる人はまだまだ限られているため、\\n\\n\\nGPTs制作領域はチャンスしかないです。\\n【超簡単】 GPT の作り方\\nGPTs の素晴らしいところは、これまでのアプリ開発など、高度なエンジニアリングスキルを要求されるものとは異なり、\\nアイデアさえあれば誰でも本当に簡単に優秀なエージェントが作れてしまう点\\n、にあります。\\nまだ一回も作ったことがない人は、以下を参考にして、\\n\\n\\nとにかく一個、作ってみましょう。\\nここで紹介するやり方は、GPT Builder と対話しながら、作りたいGPTを尋ねていく方法です。\\n後述するように、この方法だとプロンプトが自分で自由に設定できないので、質が高いGPTを作るには GPT Builder に頼らず、自分でプロンプトを編集する必要があります。\\nですが、このやり方はとにかく簡単なため、\\n\\n\\nとにかく一個作ってみるには良い一歩です。\\nわかる方は、この章は飛ばしてOKです。\\nStep 1. GPT Builder を立ち上げる\\n新しい ChatGPT UI の My GPTs のすぐ下、Create a GPT をクリックします。\\n\\nGPT の作成を補助してくれる GPT Builder が立ち上がります。\\n以下のURLからでもOKです：\\nhttps://chat.openai.com/gpts/editor\\nStep 2. 何を作りたいのかを伝える、GPTタイトルの決定\\nここでインタラクティブに会話形式で作成します。\\n\\n\\n\\tこんにちは！新しいGPTを作るのを手伝います。例えば、\"新商品のビジュアル制作を手伝ってくれるクリエイターを作る \"とか、\"私のコードのフォーマットを手伝ってくれるソフトウェアエンジニアを作る \"とか。\\n\\tあなたは何を作りたいですか？\\nGPT Builder\\nといっています。\\n\\n\\nGPT Builder と会話していくだけで、簡単に完成\\nしてしまいます。\\n\\npage_id: 3b514d33-5de1-4ee7-ab96-50bff1a3b36d\\n\\nこんにちは！新しいGPTを作るのを手伝います。例えば、\"新商品のビジュアル制作を手伝ってくれるクリエイターを作る \"とか、\"私のコードのフォーマットを手伝ってくれるソフトウェアエンジニアを作る \"とか。\\n\\tあなたは何を作りたいですか？\\nGPT Builder\\nといっています。\\n\\n\\nGPT Builder と会話していくだけで、簡単に完成\\nしてしまいます。\\n\\n\\n試しに、ブログ記事タイトルを代わりに考えてくれるボットを作ってみます。日本語でも大丈夫ですが、今はなぜか返答が全て英語になってしまうようです。\\n\\nボットのタイトルを勝手に決めてくれました。他の提案が欲しかったらそのように尋ねればOKです。\\nStep 3. ロゴを決定する\\nタイトルが決まると、勝手にボットのロゴを決めてくれます。\\n\\nこれも、気に入らなかったら、変更をお願いすればOKです。\\nStep 4. トーンを決定する\\n画像が決まると、フォーマルか、カジュアルか、というトーンを聞いてきますので、答えます。\\n\\nそうすると、最後に\\n気を付けるべき点\\nなどを聞いてきますので、SEOに気をつけてなどをいっておきます。\\n\\n変更したいことを言うと、勝手にプロンプトを変更してくれます。\\n\\n\\n実際に作成された GPT の詳細は、Configure タブで確認できます。\\n\\n色々と設定できる項目がありますが、ここでは一旦無視しましょう。\\n\\n\\n後の章で、全て詳しく解説していきます。\\nこれらはもちろん手作業で変更することができます。\\n実際の GPT の動作は、右側の Preview タブからいつでも確認することができます。\\n\\nGPT の共有\\nGPT の共有範囲は、右上から、自分だけ、URLを知っている人だけ、パブリックに公開の三つから選ぶことができます。\\n\\n**Only me は、自分だけ。\\n\\n\\n**URLにアクセスしても自分のアカウントだけしかアクセスできないため、自分専用の特化型GPTに使います。\\nOnly people with a link は、リンクを知っている人だけ\\n。\\n\\npage_id: 3b514d33-5de1-4ee7-ab96-50bff1a3b36d\\n\\n**URLにアクセスしても自分のアカウントだけしかアクセスできないため、自分専用の特化型GPTに使います。\\nOnly people with a link は、リンクを知っている人だけ\\n。\\n\\n\\n例えば、社内用で、機密情報を扱わないGPTなどに使えます。\\nPublic は、GPT Store に並びます。\\nGPT Store が出る前に質の高いGPTを作っておくのがベストです。\\nGPT Store に出す場合は必須： Builder Profile を設定する\\nここでは、GPT Store に出す場合に必須のBuilder Profile の設定方法、特に、自社ドメインの設定方法を見ていきます。\\n自分の名前が出ても大丈夫な場合は、\\nName を ON\\n にするだけでもOKです。\\nただ、Website （独自ドメイン）を登録することで、信頼性が高まるのと、ここからの集客なども見込めますので設定するのがおすすめです。\\nStep 1. Settings → Builder Profile にいく\\n\\nStep 2. Verify new domain から、ドメインを追加\\nドメインを追加します。この際、https などは必要ありません。\\n\\n\\n入力後に Submit をクリックします。\\n\\nStep 3. TXTレコード用のデータをコピーします\\n\\nStep 4. しばらく待ってから Website を ON に\\n\\nしばらく（５〜30分）ほど待ってから、Website を ON にすれば、完了です。\\nこれで、こんな感じでリンクが作者欄に反映されます：\\n\\n第2章 GPTで出来ることのすべて\\nGPTsは多くの素晴らしい機能を搭載しており、そのポテンシャルは計り知れません。\\n本章は、GPTsに搭載された主要な機能を簡単に紹介し、\\n\\n\\n全体的な理解を深めることが目的です。\\nこれらの機能を適切に組み合わせることで、本当に便利なGPTsになっていきます。\\n各機能の詳細な解説は後続の章で行います。\\n\\npage_id: 4dc16d2a-bda8-4030-89f1-04da5797f2ed\\n\\npage_id: aaeaeea9-7674-4393-9bd5-f36ed2664a14\\n\\npage_id: e2b32e3e-09be-48b8-a7c5-9210d6421bc2\\n\\nDeepFoids: Simulation Of Fish School Behavior Using Deep Reinforcement Learning\\n01/05/2023  Reinforcement Learning\\n\\n VoxFormer\" Generates 3D Volumes From Images For Use In Automated Driving Technology. \\n    28/04/2023  Object Detection\\n\\n RT-1 Robot Learning System Operated From Images And Natural Language \\n    27/04/2023\\n\\n Spotlight\" For UI Modeling With Only UI Images, Independent Of View Hierarchy \\n    26/04/2023  Deep Learning\\n\\n TwiBot-22, A Large Graph-based Dataset For Detecting Twitter Bot Users, Is Now Available! \\n    25/04/2023\\n\\n Extracting Critical Information From Medical Documents Using InstructGPT \\n    19/04/2023  Natural Language Processing\\n\\n BILCO For Accurate And Fast Alignment Of Time Deviations Between Time Series Data Series \\n    18/04/2023  Time-series\\n\\n Wild Selfie Dataset (WSD), A Dataset For Facial Recognition Of Selfie Images \\n    14/04/2023  Face Recognition\\n\\n Can You Have A Conversational Dialogue With A Mobile UI In A Large Language Model? \\n    13/04/2023  Natural Language Processing\\n\\n Profiling The Relationship Between Websites And Their Audiences Enables The Detection Of Fake News And Political Bias! \\n    12/04/2023  GNN\\n\\n A New SoTA Model For CQA Tasks That Answers Questions About The Chart Is Now Available! \\n    11/04/2023  Chart Question Answering\\n\\n New Face Recognition Model \"part FViT\" Combining Vision Transformer With Landmark CNN \\n    07/04/2023  Face Recognition\\n\\n AttenFace, A Real-time Attendance Verification System Using Facial Recognition \\n    06/04/2023  Face Recognition\\n\\n Time Series Model LaST That Can Forecast Accurately Even With Mixed Seasonal Variations And Trends \\n    04/04/2023  Time-series\\n\\n ByteTrack+ Appearance Features Are The Strongest: SMILETrack \\n    03/04/2023  Object Tracking\\n\\npage_id: d0179395-600c-45a9-a9c9-e3fc9d89f5e1\\n\\n今までで最もインパクトのあるGPTsが完成しました。\\nその名も、「\\nGAS Interpreter\\n」です。\\n\\nこのGPTは名前の通り、\\nCode Interpreter のように Google Apps Script コードを生成し、その実行までを行います\\n。\\n\\n\\n他者に使ってもらうものではなく、\\n自分専用のプライベートGPT\\nです。\\n人によっては、Code Interpreter よりも便利です。なぜかというと、\\nインターネットアクセスができる\\nことに加えて**、GAS の便利で豊富なライブラリやリソースが活用できる**ためです。\\n例を示します。\\nGAS Interpreter の可能性\\n以下に示す、いくつかの業務フローの実例をGAS Interpreterで行い、業務活用への可能性を示します。\\n今日の予定を聞きます：\\n\\n正確に今日の予定を教えてくれました。\\nZoom会議参加者の相手に連絡したいので、そのメールアドレスを聞く：\\n\\nカレンダーの詳細を読み取って、会議参加者のメールアドレスを教えてくれました。\\n予定が合わなかったので、リスケのお願いメールを書いて、ドラフトに保存する：\\n\\nこちらが実際に保存されていたメールです：\\n\\n内容が問題なさそうなので、送信してもらいます：\\n\\n問題なく送信されました。\\nもちろん、内容を確認せずに直接送ることも可能です：\\n\\nGPTsに関する利用状況の調査フォームを作成：\\n\\n実際に作成されたフォーム：\\n\\n作られた調査フォームに対して、Team Planの項目を追加する：\\n\\n実際に追加された項目：\\n\\nこのような編集作業は、\\n以前作り方をご紹介した FormGPT\\n \\nには機能として入っていないもの\\nでした。\\nGAS Interpreterであれば、GASでできるあらゆることがノーコードで実行可能\\nになります。\\n例えば、このフォームに紐づくスプレッドシートを作成してもらいます：\\n\\n作成されたスプレッドシート：\\n\\nこのように、そもそもこんなことGASでできるのかわからない、みたいなことも、聞いてみると意外とやってくれます。\\n正直、開発者の私自身、このGPTの可能性をまだ測りきれていません。\\nぜひ、GAS Interpreter を導入する方は、さまざまな活用事例を探ってみてほしいです。\\n自動リトライ機能\\nGAS Interpreterには、 Code Interpreter と同様に、コードの実行が失敗した時には\\n再度コードを修正して実行する機能\\nが含まれます。\\n\\n上記の例では、先ほどの調査結果のスプレッドシートの解析を試みるも、2回トライした後に、失敗の報告がありました。\\n実は、\\nGAS Interpreter は全ての実行ログを、専用のスプレッドシートに保存する\\nようにしています。\\n\\npage_id: d0179395-600c-45a9-a9c9-e3fc9d89f5e1\\n\\nぜひ、GAS Interpreter を導入する方は、さまざまな活用事例を探ってみてほしいです。\\n自動リトライ機能\\nGAS Interpreterには、 Code Interpreter と同様に、コードの実行が失敗した時には\\n再度コードを修正して実行する機能\\nが含まれます。\\n\\n上記の例では、先ほどの調査結果のスプレッドシートの解析を試みるも、2回トライした後に、失敗の報告がありました。\\n実は、\\nGAS Interpreter は全ての実行ログを、専用のスプレッドシートに保存する\\nようにしています。\\n今回のケースでは、GAS Interpreterが自分自身で失敗原因を推定しており、実際に合っているのですが、詳しい原因を探るには、この実行ログ専用シートを参照することができます：\\n\\nコード実行の失敗時には赤色で、成功時には緑色になるようにしています。\\n今回の失敗原因は、シート名を指定していなかったことでした。\\n以下のように、正しいシート名を指定することで、スプレッドシートのデータを読み取ることができました：\\n\\nGAS Interpreter のその他の事例\\nGAS Interpreter は、上記で見てきたように、これまでAGIラボで作成方法を解説してきたGmailGPT, SpreadsheetGPT, DocumentGPT, FormGPTなどの全てのGPTsを内包します。\\nこれらの一般的な事例に留まらず、GASにYoutube ライブラリを追加することで以下のようなことが可能です。\\n自分が購読しているYouTubeチャンネルから、最新動画を取得\\n\\n特定のワードを含むYoutube動画を検索して、それらをスプレッドシートに構造的に出力：\\n\\n出力されたスプレッドシート：\\n\\nリストにあるYoutube動画の中で最もいいね数の比率が高い動画を探す：\\n\\n出力してきた最も評価の高いHeyGenのYoutubeの動画がこちらです。数値は会っています。\\n\\n最近実際に使った活用事例\\n他に、ここ数日、\\n実際に筆者が自分自身で使っていた業務活用事例\\nを示します。\\nソースコードを適当に突っ込んで、解説スライドを作る：\\n\\n大量の情報を適当に入れ、そのスライドを作ってもらうことができます。\\n適当な指示でスライドのデザインをかっこよくする：\\n\\n画像のように、適当な命令でも使えます。このスライドは、実際にイベント登壇時に使ったスライドです。元々は白地のつまらないスライドでしたが、自己判断で勝手にいい感じにかっこよくしてくれました。\\n\\nもちろんちゃんと指定すればそのように変更してくれます。\\n\\npage_id: d0179395-600c-45a9-a9c9-e3fc9d89f5e1\\n\\n適当な指示でスライドのデザインをかっこよくする：\\n\\n画像のように、適当な命令でも使えます。このスライドは、実際にイベント登壇時に使ったスライドです。元々は白地のつまらないスライドでしたが、自己判断で勝手にいい感じにかっこよくしてくれました。\\n\\nもちろんちゃんと指定すればそのように変更してくれます。\\nElevenLabsでAI音声を作成してもらったのち、そのファイルを Google Driveにアップロードする：\\n\\n上記画像のように、＠マークメンション機能を使うことで、さらに多くの場面での活用事例が考えられます。\\n適当な情報を投げてカレンダーに予定を入れる：\\n\\nチャット履歴を適当にコピペするだけで正確に予定を入れてくれます：\\n\\n業務委託契約書をGoogleDocsで作って、そのPDFを共有：\\n\\n（上記は仮の値に変更していますが実際に業務委託をお願いする際に使いました）\\n他にもGAS Interpretreで実現できることは、無数にあり活用事例は想像力次第です。\\nセキュリティについて\\nここでセキュリティについて述べておきます。\\nエンジニアリングに詳しい方は、\\u3000当然このGPTに対してセキュリティ上の懸念を示すはずです。\\nそれは、コードを実行できてしまう環境というのは、攻撃者からすると攻撃コードを仕込むことができるからです。つまり、APIサーバーのURLがわかっていればJavaScriptインジェクション攻撃が行えます。\\nそのため、私も当初、作ったはいいものの、このGPTの作り方を公開するのは、控えようかと考えていました。\\nAPIキーの導入によるセキュリティ対策\\nですが、GPTに対して、\\nAPIキーを発行、管理する実装を十分工夫することで、セキュリティ上の担保ができると考えたため、作り方を公開\\nすることにしました：\\n\\nまた、\\nアクセスを望まないGASライブラリには、アクセス権限を付与しないことが可能\\nです。\\nただし、\\nリスクは低いもののゼロではないため、自己責任で導入\\nしてください。正直言って、大企業にいる方が使うGPTではありません。\\n個人事業主や、小規模事業者の方が最も使用に適している\\nと感じます。\\nGAS Interpreter の導入\\n導入はいつも通り、\\nノーコードで簡単\\nにできます。\\nまた\\n運用コストも、ChatGPT Plusの代金以外は、ゼロ\\nです。\\n\\npage_id: d0179395-600c-45a9-a9c9-e3fc9d89f5e1\\n\\nただし、\\nリスクは低いもののゼロではないため、自己責任で導入\\nしてください。正直言って、大企業にいる方が使うGPTではありません。\\n個人事業主や、小規模事業者の方が最も使用に適している\\nと感じます。\\nGAS Interpreter の導入\\n導入はいつも通り、\\nノーコードで簡単\\nにできます。\\nまた\\n運用コストも、ChatGPT Plusの代金以外は、ゼロ\\nです。\\n**注意：**これまでに GAS系のGPTを作ったことがないひとは、\\n以下の記事\\nで、実際にGAS系のGPTが作れることを確認してからこのGPT導入を検討することをお勧めします：\\nGAS Interpreterへのアクセスは、AGIラボ会員の方限定\\nとなります。\\n\\npage_id: 3cfb8499-14f8-4078-8dab-c84191ade1f7\\n\\nはじめに\\n今回は有名企業の公開されているエンジニア新人研修資料をまとめました。\\n昨今、新人向けの研修資料を公開する企業が増えています。\\nまたクオリティーがかなり高いものが多く、初級者~中級者でも学びがある資料となっています。\\n資料の作り方も勉強になるので「勉強会で登壇している人」「企業の研修担当の人」にも有益な資料になっています。\\nこの記事の主な対象者\\n有名企業の研修資料を網羅的に見たい人\\nエンジニア初級~中級者の人\\n独学で学習をしている人\\n研修資料の作成を今後していきたい人\\n\\nミクシィ\\n\\nまずはじめに紹介するのは、毎年新人向けの研修資料を公開している株式会社ミクシィです。\\n今年もミクシィの22新卒技術研修の資料と動画を公開します！https://mixi-developers.mixi.co.jp\\nミクシィの研修資料で公開されている内容は、\\nGit研修\\nデータベース研修\\n設計・テスト研修\\nコンテナ研修\\niOSアプリ開発研修\\nAndroidアプリ開発研修\\nフロントエンド研修\\nゲーム開発研修\\nFlutter研修\\nAI研修\\nセキュリティー研修\\nチーム開発研修\\nと、正直「\\nここまで公開しちゃうんですか\\n」と思わんばかりに濃い内容になっています。\\nまたそのほとんどに動画、スライド、リポジトリーが付いているので学習教材としても十分な内容になっています。\\nさらに毎年更新されているので、最新の内容を学ぶことができます。\\n\\nリクルート\\n\\n次に紹介するのは株式会社リクルートが公開している新人向け研修資料です。\\n株式会社リクルート エンジニアコース新人研修の内容を公開します！（2022年度版）https://blog.recruit.co.jp\\nこちらの資料ではソフトエンジニアとしての心構えだったり、ABテストの概論、AWS、TypeScriptといったフロント周りと幅広く対応しています。\\n「\\nブラウザ上でどのような処理が行われているのか\\n」をトピックとしており、分野が組まれています。\\nこちらも資料も豊富でかなり勉強になると思うのでぜひ利用してみてください。\\n\\nサイボウズ\\n\\n次に紹介するのはサイボウズ株式会社が公開しているエンジニア新人研修の講義資料です。\\n2022年のエンジニア新人研修の講義資料を公開しました - Cybozu Inside Out | サイボウズエンジニアのブログhttps://blog.cybozu.\\n\\npage_id: 3cfb8499-14f8-4078-8dab-c84191ade1f7\\n\\nこちらも資料も豊富でかなり勉強になると思うのでぜひ利用してみてください。\\n\\nサイボウズ\\n\\n次に紹介するのはサイボウズ株式会社が公開しているエンジニア新人研修の講義資料です。\\n2022年のエンジニア新人研修の講義資料を公開しました - Cybozu Inside Out | サイボウズエンジニアのブログhttps://blog.cybozu.io\\nこちらの資料では、\\nモバイルアプリ開発\\nサイボウズのアジャイル・クオリティ\\nMySQL - テストデータが偏るということ\\nモブに早く慣れたい人のためのガイド\\nテクニカルライティングの基本\\nソフトウェアテスト\\nセキュリティ\\nソフトウェアライセンス\\nとアプリ開発に加えて、データベース周りだったりやテストやセキュリティー周りも対応している資料になっています。\\n内容も「\\nそもそもアプリとは何か\\n」といった初歩的なところから解説がはじまっているので知識がほとんどなくても読み進めることができます。\\nかつ図が多用されているので処理のイメージがつきやすい資料になっています。\\n\\nサイバーエージェント\\n\\n次は株式会社サイバーエージェントが公開している新卒向けの研修資料です。\\n良いコードとは何か - エンジニア新卒研修 スライド公開｜CyberZ Developerhttps://note.com\\n資料は「\\n良いコードとは何か\\n」といった誰もが学ぶべき内容になっています。\\n具体的には、\\n品質とスピードはトレードオフか\\n技術的負債の発生と解消\\n凝集度と結合度\\nclean\\nQuery: SQLを勉強するのに良い資料は？\\nOriginal Answer: SQLを勉強するのに良い資料は、GMOペパボのSQL研修の内容が基本的なものから始まり、RDBMSの歴史やデータベースの設計について触れているため、初心者にとって理解しやすい資料となっています。また、他の情報源としては、Business Insiderやダイヤモンド・シグナルもSQLを含むテクノロジー系の情報を提供しているので、そちらも参考になるでしょう。\\nNew Answer: '}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.1}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 01 Aug 2024 16:35:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-01p8otbt5gis2mt84rnzemio'), (b'openai-processing-ms', b'2997'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9998'), (b'x-ratelimit-remaining-tokens', b'184169'), (b'x-ratelimit-reset-requests', b'13.249s'), (b'x-ratelimit-reset-tokens', b'4.749s'), (b'x-request-id', b'req_13a0efbce24c6817f943a2cbdf3cb202'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ac73d767a25688c-NRT'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Thu, 01 Aug 2024 16:35:16 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-01p8otbt5gis2mt84rnzemio', 'openai-processing-ms': '2997', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9998', 'x-ratelimit-remaining-tokens': '184169', 'x-ratelimit-reset-requests': '13.249s', 'x-ratelimit-reset-tokens': '4.749s', 'x-request-id': 'req_13a0efbce24c6817f943a2cbdf3cb202', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ac73d767a25688c-NRT', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_13a0efbce24c6817f943a2cbdf3cb202\n",
      "DEBUG:llama_index.core.response_synthesizers.refine:> Refine context: エンジニアコース新人研修の内容を公開します！（2022年度版）https://blog.rec...\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are an expert Q&A system that strictly operates in two modes when refining existing answers:\\n1. **Rewrite** an original answer using the new context.\\n2. **Repeat** the original answer if the new context isn\\'t useful.\\nNever reference the original answer or context directly in your answer.\\nWhen in doubt, just repeat the original answer.\\nNew Context: エンジニアコース新人研修の内容を公開します！（2022年度版）https://blog.recruit.co.jp\\nこちらの資料ではソフトエンジニアとしての心構えだったり、ABテストの概論、AWS、TypeScriptといったフロント周りと幅広く対応しています。\\n「\\nブラウザ上でどのような処理が行われているのか\\n」をトピックとしており、分野が組まれています。\\nこちらも資料も豊富でかなり勉強になると思うのでぜひ利用してみてください。\\n\\nサイボウズ\\n\\n次に紹介するのはサイボウズ株式会社が公開しているエンジニア新人研修の講義資料です。\\n2022年のエンジニア新人研修の講義資料を公開しました - Cybozu Inside Out | サイボウズエンジニアのブログhttps://blog.cybozu.\\n\\npage_id: 3cfb8499-14f8-4078-8dab-c84191ade1f7\\n\\nこちらも資料も豊富でかなり勉強になると思うのでぜひ利用してみてください。\\n\\nサイボウズ\\n\\n次に紹介するのはサイボウズ株式会社が公開しているエンジニア新人研修の講義資料です。\\n2022年のエンジニア新人研修の講義資料を公開しました - Cybozu Inside Out | サイボウズエンジニアのブログhttps://blog.cybozu.io\\nこちらの資料では、\\nモバイルアプリ開発\\nサイボウズのアジャイル・クオリティ\\nMySQL - テストデータが偏るということ\\nモブに早く慣れたい人のためのガイド\\nテクニカルライティングの基本\\nソフトウェアテスト\\nセキュリティ\\nソフトウェアライセンス\\nとアプリ開発に加えて、データベース周りだったりやテストやセキュリティー周りも対応している資料になっています。\\n内容も「\\nそもそもアプリとは何か\\n」といった初歩的なところから解説がはじまっているので知識がほとんどなくても読み進めることができます。\\nかつ図が多用されているので処理のイメージがつきやすい資料になっています。\\n\\nサイバーエージェント\\n\\n次は株式会社サイバーエージェントが公開している新卒向けの研修資料です。\\n良いコードとは何か - エンジニア新卒研修 スライド公開｜CyberZ Developerhttps://note.com\\n資料は「\\n良いコードとは何か\\n」といった誰もが学ぶべき内容になっています。\\n具体的には、\\n品質とスピードはトレードオフか\\n技術的負債の発生と解消\\n凝集度と結合度\\nclean architecture\\nといった内容になっています。\\n若干難易度が高い内容もありますが、わかりやすい言葉で解説をされているので理解もしやすいです。\\n初心者から中級者まで学びになるような資料だったのでぜみ読んでみてください。\\n\\nゆめみ\\n\\n次に紹介するのは株式会社ゆめみが提供するiOSエンジニアの研修資料です。\\nこちらの研修資料ではGitHubのリポジトリーが公開されており、天気予報アプリを開発しながら学習を進めることができます。\\n14ステップの課題が用意されており、1ヶ月程度で完成できる内容になっています(Qiita参照)\\niOSアプリについてこれから学びたい人にとってかなりタメになる教材となっているのでぜひ使ってみてください。\\n\\nWantedly\\n\\n最後に紹介するのはウォンテッドリー株式会社が公開している新卒研修資料です。\\n\\npage_id: 3cfb8499-14f8-4078-8dab-c84191ade1f7\\n\\nこちらの研修資料ではGitHubのリポジトリーが公開されており、天気予報アプリを開発しながら学習を進めることができます。\\n14ステップの課題が用意されており、1ヶ月程度で完成できる内容になっています(Qiita参照)\\niOSアプリについてこれから学びたい人にとってかなりタメになる教材となっているのでぜひ使ってみてください。\\n\\nWantedly\\n\\n最後に紹介するのはウォンテッドリー株式会社が公開している新卒研修資料です。\\nこちらに関してはエンジニア向けの内容に加えて、社会人1年目として考え方やプロダクトについても学ぶことができる資料になっています。\\nそのため新卒向けの新人研修マニュアルや資料を作る新卒担当の人もかなり勉強になる内容になっています。\\n最後に\\nいかがだったでしょうか。\\n今回は有名企業の研修資料を紹介しました。\\n研修というだけあってわかりやすい構成なので、エンジニア初心者から中級者また社内の新卒担当者もかなり勉強になる内容と感じました。\\nぜひこれらの資料を使ってよりスキルアップしていただければなと思います。\\n自分は他にも様々な記事を出しているのであわせて読んでいただけると嬉しいです。\\n\\npage_id: 2152ea9c-71fb-4d35-9954-f88c69316cd9\\n\\n公開日：1日前 最終更新日：1日前\\n\\nAIエセ師\\nAIエセ師です。\\nさて今回も無料プレゼントです。\\n\\n\\nディープフェイクの注目度は高いですね。\\n\\n\\n2024年2月11日の時点で結構なインプレッション数を取れており、関心度が分かりますね。\\n\\n\\nディープフェイクは流行っており、その話題だけでもSNS運用のフォロワー獲得に役立ててくださいね。\\n\\n前置きはさておき早速ディープフェイク構築の説明を始めて行きますね。\\n今回はタイトル通りGoogle Colabの無料で構築します。\\n\\n\\n※Google Colabは無料でも利用可能です。無料でも可能ですが、作成までに時間が掛かるので有料プランに入る事をオススメします。\\n下記にアクセスしてください。\\n\\n\\n今回は「roop-unleashed」でディープフェイクを作成します。\\n\\n\\nエセフェイク\\nアクセスしたらドライブにコピーを保存(自分の環境にコピーしてください)\\n\\nランタイムのタイプ変更で「T4GPU」を選択\\n\\n\\n※これは無料で利用可能となりますが、有料プランを利用の方は「A100」や「V100」を選択するとディープフェイク生成のスピードが変わります。\\n\\n再生ボタンをクリックして、5分〜10分程度待ちます。\\n\\n下記のURLが表示されるのでクリック\\n\\nクリックすると下記の画面が表示されます。\\n\\n\\n「Source File」に元画像を選択「Target File」にディープフェイクしたい動画を選択\\n\\n今回の画像は下記を選択しました。\\n\\n画像を選択すると下記の様に顔を認識します。\\n\\n動画を選択します。\\n\\n\\nその後に「Use Face From this Frame」をクリック\\n\\n\\n動画は\\nこちら\\nをダウンロードしました。\\n\\n動画の顔が認識されます。\\n\\n両方認識したら、下の方にスクロールして「START」をクリックして、しばらく待ちます。\\n\\n\\n※結構時間掛かります。動画の内容によっては１時間以上掛かります、\\n\\nできた動画がこちらとなります。\\n\\n如何でしたか？？\\n\\n\\n待ち時間は結構掛かりますが、完全無料でいくらでもディープフェイクができますね。\\n\\n\\nディープフェイクは今流行っていて、完成動画を投稿するだけでもフォロワーが増えます。\\n\\n\\n是非作成いただき、私の\\nポスト\\nを引用リポストして完成した動画と感想をお願いします。\\n\\n\\n引用リポストいただければ私からリポストします。\\n\\n\\nそうする事でインプ数も稼ぎフォロワーさんが増える可能性がありますよー\\nAIエセ師を知らない方、まだ私のサロンに入っていない方へ\\n\\n\\n私はAIに関するマネタイズサロンの管理人をしており、1600名の参加をいただいております。\\n\\n\\nここでは様々なマネタイズに関する有益情報を発信しており、皆さんで情報共有をする場となっております。\\n\\npage_id: 2152ea9c-71fb-4d35-9954-f88c69316cd9\\n\\n引用リポストいただければ私からリポストします。\\n\\n\\nそうする事でインプ数も稼ぎフォロワーさんが増える可能性がありますよー\\nAIエセ師を知らない方、まだ私のサロンに入っていない方へ\\n\\n\\n私はAIに関するマネタイズサロンの管理人をしており、1600名の参加をいただいております。\\n\\n\\nここでは様々なマネタイズに関する有益情報を発信しており、皆さんで情報共有をする場となっております。\\n\\n\\n完全無料ですので是非ご参加くださいね。\\n[\\nJoin the AI画像生成マネタイズクラブ Discord Server!\\nCheck out the AI画像生成マネタイズクラブ community on Discord - hang out with 1626 other members and enjoy free voice and text chat.\\n\\n](https://discord.gg/qU2PePTtCD)\\n宣伝です。\\n\\n\\n私がオススメするTipsをご紹介しますね。\\n\\n\\nもっとディープフェイクが知りたい！本格的に参入したい！！と言う方は下記のTipsがオススメです。\\n\\n\\n熟知した方とのマンツーマン面談もあるので初心者からカナリお勧めなTipsとなります。\\n\\n\\n今回のプレゼント企画で特別クーポンをご用意しましたので、是非活用して購入ください。\\n15000円割引クーポンコード：NEKO10000\\n[\\n[PR]【ディープフェイク美女の教科書】TikTokでバズる「動く美女」の生成方法を徹底解説【ユニコ🦄式】 | Tips\\n〜このTipsは何が分かるの？〜ココ最近、Twitter界隈でよく耳にする「ディープフェイク美女」に関しての \"全て\" が分かる、決定版のTipsを目指したいと思います！！すでにユニコ🦄が管理人の400人が参加する「AIを研究するDiscord」への特別参加権が特典であります！そのDiscordでは2023年8月から日々、最新の技術やSNS運用...\\n\\n](https://tips.jp/u/unikoukokun/a/deepfake/0ockTib5%20)\\nAI画像界で最高峰と言われている「ユニコさん」と「みゆきさん」のコラボTipsです。\\n\\n\\n特に初心者の方にオススメでAI画像の環境から簡単に最高峰のやり方が詰まった美女画像が生成できるようにしています。\\n\\n\\nまたマンツーマン面談もあるので安心して画像が生成できますよ。\\n\\n\\nそれもなんと！！マガジン形式で記事が追加していくTipsとなり、記事を追加する毎に値上げをして行きます。\\n\\n\\nその為、現在が最安値となりますので、是非ご購入してください。\\n\\n\\nこのTipsは本当に後悔しない事をお約束しますよー\\n\\n\\n(私は追加の５記事分の内容を知ってますが、あり得ないぐらいお得です。)\\n\\npage_id: 2152ea9c-71fb-4d35-9954-f88c69316cd9\\n\\nまたマンツーマン面談もあるので安心して画像が生成できますよ。\\n\\n\\nそれもなんと！！マガジン形式で記事が追加していくTipsとなり、記事を追加する毎に値上げをして行きます。\\n\\n\\nその為、現在が最安値となりますので、是非ご購入してください。\\n\\n\\nこのTipsは本当に後悔しない事をお約束しますよー\\n\\n\\n(私は追加の５記事分の内容を知ってますが、あり得ないぐらいお得です。)\\n\\n\\nこの記事限定のクーポンも発行しました。\\n2500円割引クーポン：MANEMIYU\\n[\\n[PR]【ユニコ🦄 ✘ みゆき】カワイイAI美女を作るTipsセット | Tips\\nユニコ🦄 ✘ みゆき共著で執筆のTipsがセットで購入できます！ 今後も記事を追加していく予定です！！ ※単品で購入するよりもセット購入の方が安いですので、セット販売の購入をオススメ致します！\\n\\n](https://tips.jp/u/unikoukokun_sd/p/uKJTSPUX/0ockTib5)\\nまだFANZAを出版していない方は下記のTipsが本当にお勧めです。\\n\\n\\n特別クーポンもご用意してますので、是非ご検討ください。\\n\\n\\nクーポンコード：OGIKO8000R\\n\\n\\n8000円引きクーポン\\n\\n\\nこのURL限定の最安値クーポンです！\\n[\\n[PR]AI画像生成のスキルを次のレベルへ！FANZA同人で売り上げと生産性を爆発的に高める究極のガイド！ | Tips\\nAI画像生成で美しい、魅力的な作品を生み出せるのに、その才能をお金に変える方法がわからない。 このコンテンツでは、AI画像生成とFANZA同人を組み合わせたマネタイズ方法を紹介します。 1週間で売上を立てた方法から、長期的に安定した収益を上げる戦略まで、詳細にわたって解説します。\\n\\n](https://tips.jp/u/ogiko/a/ogiko-fanza/0ockTib5)\\nあなたも記事の投稿・販売を\\n\\n\\n始めてみませんか？\\nTipsなら簡単に記事を販売できます！\\n\\n\\n登録無料で始められます！\\n \\nTipsの詳細はこちら\\n\\nこの記事のライター\\n\\nAIエセ師\\nAI画像生成マネタイズのサロンを運営しております。\\nこのライターが書いた他の記事\\n\\n2023/08/06 13:38\\n\\n#### 【AI画像生成】あなたの画像は大丈夫？トラブルにならないコツ\\n関連のおすすめ記事\\n\\n2023/04/17 19:56\\n\\n#### 【全投稿790万再生】 画像生成AI x 美女 x TikTok でバズり散らかすガイドブック！ ウェブツールで完結。詳細なスクショ付き。\\n\\n_![FT飯田@エンジニア<<{}>>](https://static.tips.jp/2023/06/04/pks2emCdWXSdMeNfyYMEJUFlnrQOappn.png)_\\n\\nFT飯田@エンジニア\\n\\npage_id: 7ec92452-ff33-48de-960a-a68992a1b5e0\\n\\npage_id: a0dd9f3f-c7c7-48ee-a458-ad0d008a77b8\\n\\npage_id: 384ebb25-693b-45c7-afe9-489140511a80\\n\\npage_id: 72ed7890-749c-4f03-888d-287e1867ae85\\n\\nTranscript\\n\\n \\n\\n\\tMasanobu Naruse\\n\\tSQL Tutorial\\n\\tSQL\\n\\tView Slide\\n\\n \\n\\n\\tはじめに\\n\\tSQL\\n\\tView Slide\\n\\n \\n\\n\\t←アプリケーション開発者\\n\\t成瀬 允宣\\n\\t3\\n\\tView Slide\\n\\n \\n\\n\\tお話する内容は\\n\\tアプリケーション開発者が\\n\\t見ている景色です\\n\\t4\\n\\tView Slide\\n\\n \\n\\n\\t概要\\n\\tSQL\\n\\tView Slide\\n\\n \\n\\n\\tStructured Query Language\\n\\t6\\n\\tView Slide\\n\\n \\n\\n\\tStructured Query Language\\n\\t7\\n\\tView Slide\\n\\n \\n\\n\\tリレーショナルデータベースの\\n\\t管理や操作を行うための人工言語\\n\\t8\\n\\tView Slide\\n\\n \\n\\n\\tリレーショナルデータベースの\\n\\t管理や操作を行うための人工言語\\n\\t今日のメイン\\n\\t9\\n\\tView Slide\\n\\n \\n\\n\\tリレーショナルデータベース\\n\\tの\\n\\tイメージが沸かない方へ\\n\\t10\\n\\tView Slide\\n\\n \\n\\n\\t11\\n\\tView Slide\\n\\n \\n\\n\\t12\\n\\tView Slide\\n\\n \\n\\n\\tフィールド\\n\\t13\\n\\tView Slide\\n\\n \\n\\n\\tカラム\\n\\t14\\n\\tView Slide\\n\\n \\n\\n\\tレコード\\n\\t15\\n\\tView Slide\\n\\n \\n\\n\\tテーブル\\n\\t16\\n\\tView Slide\\n\\n \\n\\n\\tデータベース\\n\\t17\\n\\tView Slide\\n\\n \\n\\n\\tというところで\\n\\t問題です\\n\\t18\\n\\tView Slide\\n\\n \\n\\n\\tQ. 職業が「プログラマ」の人の条件は？\\n\\t19\\n\\tView Slide\\n\\n \\n\\n\\tQ. 職業が「プログラマ」の人の条件は？\\n\\tA. D列が”Programmer”であるデータ\\n\\t20\\n\\tView Slide\\n\\n \\n\\n\\tQ. 職業が「プログラマ」の人の条件は？\\n\\tA. D列が”Programmer”であるデータ\\n\\tSELECT * FROM users WHERE D = \\'Programmer\\'\\n\\t21\\n\\tView Slide\\n\\n \\n\\n\\t実行して取れるデータ\\n\\tSELECT * FROM users WHERE D = \\'Programmer\\'\\n\\t22\\n\\tView Slide\\n\\n \\n\\n\\t実行して取れるデータ\\n\\tSELECT * FROM users WHERE D = \\'Programmer\\'\\n\\t23\\n\\tView Slide\\n\\n \\n\\n\\tやってみよう\\n\\tSQL\\n\\tView Slide\\n\\n \\n\\n\\thttps://sqlzoo.net\\n\\t25\\n\\tView Slide\\n\\n \\n\\n\\thttps://sqlzoo.net\\n\\t26\\n\\tView Slide\\n\\n \\n\\n\\thttps://sqlzoo.net\\n\\t27\\n\\tView Slide\\n\\n \\n\\n\\thttps://sqlzoo.net\\n\\t28\\n\\tView Slide\\n\\n \\n\\n\\t29\\n\\tView Slide\\n\\n \\n\\n\\tここに SQL を入力して\\n\\t「Submit SQL」ボタンを押す\\n\\t30\\n\\tView Slide\\n\\n \\n\\n\\tテーブル名\\n\\tカラム名\\n\\tここに SQL を入力して\\n\\t「Submit SQL」ボタンを押す\\n\\t31\\n\\tView Slide\\n\\n \\n\\n\\tと入力して\\n\\t実行してみよう\\n\\tSELECT * FROM world\\n\\tExercise 1 : 最初のステップ SQLZOO: 0 SELECT basics\\n\\t32\\n\\tView Slide\\n\\n \\n\\n\\tWrong とか言われてるけど\\n\\t気にしない！\\n\\npage_id: 72ed7890-749c-4f03-888d-287e1867ae85\\n\\nnet\\n\\t26\\n\\tView Slide\\n\\n \\n\\n\\thttps://sqlzoo.net\\n\\t27\\n\\tView Slide\\n\\n \\n\\n\\thttps://sqlzoo.net\\n\\t28\\n\\tView Slide\\n\\n \\n\\n\\t29\\n\\tView Slide\\n\\n \\n\\n\\tここに SQL を入力して\\n\\t「Submit SQL」ボタンを押す\\n\\t30\\n\\tView Slide\\n\\n \\n\\n\\tテーブル名\\n\\tカラム名\\n\\tここに SQL を入力して\\n\\t「Submit SQL」ボタンを押す\\n\\t31\\n\\tView Slide\\n\\n \\n\\n\\tと入力して\\n\\t実行してみよう\\n\\tSELECT * FROM world\\n\\tExercise 1 : 最初のステップ SQLZOO: 0 SELECT basics\\n\\t32\\n\\tView Slide\\n\\n \\n\\n\\tWrong とか言われてるけど\\n\\t気にしない！\\n\\t33\\n\\tView Slide\\n\\n \\n\\n\\tworld テーブルのレコードを\\n\\tすべて取得\\n\\t34\\n\\tView Slide\\n\\n \\n\\n\\tSELECT * FROM world\\n\\tSELECT * FROM world\\n\\t35\\n\\tView Slide\\n\\n \\n\\n\\tSELECT * FROM world\\n\\tFROM 句\\n\\t36\\n\\tView Slide\\n\\n \\n\\n\\tSELECT * FROM world\\n\\tFROM 句\\n\\tテーブルを指定\\n\\t37\\n\\tView Slide\\n\\n \\n\\n\\tSELECT * FROM world\\n\\tSELECT * FROM world\\n\\t38\\n\\tView Slide\\n\\n \\n\\n\\tSELECT * FROM world\\n\\tSELECT 句\\n\\t39\\n\\tView Slide\\n\\n \\n\\n\\tSELECT * FROM world\\n\\tSELECT 句\\n\\t結果として取得するカラムを指定\\n\\t40\\n\\tView Slide\\n\\n \\n\\n\\tSELECT * FROM world\\n\\tSELECT 句\\n\\t結果として取得するカラムを指定\\n\\t（アスタリスク）はワイルドカードで\\n\\t「すべて」や「なんでも」の意味\\n\\t41\\n\\tView Slide\\n\\n \\n\\n\\t欲しいカラムが ‘name’ と ‘area’ なら\\n\\t42\\n\\tView Slide\\n\\n \\n\\n\\t欲しいカラムが ‘name’ と ‘area’ なら\\n\\tSELECT name, area FROM world\\n\\tSELECT world.name, world.area FROM world\\n\\t43\\n\\tView Slide\\n\\n \\n\\n\\tExercise 2 : 欲しいデータを取得 SQLZOO: 0 SELECT basics\\n\\t列の順序がアルファベット順になるような\\n\\tSQL を実行しよう\\n\\t44\\n\\tView Slide\\n\\n \\n\\n\\t答え合わせ\\n\\t45\\n\\tView Slide\\n\\n \\n\\n\\tWHERE 句\\n\\tSQL\\n\\tView Slide\\n\\n \\n\\n\\tarea（面積）が日本より大きい国を探そう\\n\\t47\\n\\tView Slide\\n\\n \\n\\n\\tarea（面積）が日本より大きい国を探そう\\n\\tまず日本の面積は？\\n\\t48\\n\\tView Slide\\n\\n \\n\\n\\tデータはここにある\\n\\t49\\n\\tView Slide\\n\\n \\n\\n\\tname はたぶん Japan\\n\\t50\\n\\tView Slide\\n\\n \\n\\n\\tname はたぶん Japan\\n\\tSELECT * FROM world WHERE name = \\'Japan\\'\\n\\t51\\n\\tView Slide\\n\\n \\n\\n\\tSELECT * FROM world WHERE name = \\'Japan\\'\\n\\t52\\n\\tView Slide\\n\\n \\n\\n\\tSELECT * FROM world WHERE name = \\'Japan\\'\\n\\tname が ‘Japan’ のレコードを取得\\n\\t53\\n\\tView Slide\\n\\n \\n\\n\\tSELECT * FROM world WHERE name = \\'Japan\\'\\n\\t54\\n\\tView Slide\\n\\n \\n\\n\\tSELECT * FROM world WHERE name = \\'Japan\\'\\n\\tarea が 377930 より大きい国を探す\\n\\t55\\n\\tView Slide\\n\\n \\n\\n\\tSELECT * FROM world WHERE area > 377930\\n\\t56\\n\\tView Slide\\n\\n \\n\\n\\tSELECT * FROM world WHERE area > 377930\\n\\tarea が 377930 より大きいレコードを取得\\n\\t57\\n\\tView Slide\\n\\n \\n\\n\\tSELECT * FROM world WHERE area > 377930\\n\\t58\\n\\tView Slide\\n\\n \\n\\n\\tSELECT * FROM world WHERE area > 377930\\n\\t条件追加：日本より人口の多い国\\n\\t59\\n\\tView Slide\\n\\n \\n\\n\\tSELECT * FROM world WHERE name = \\'Japan\\'\\n\\t60\\n\\tView Slide\\n\\n \\n\\n\\tSELECT * FROM world WHERE name = \\'Japan\\'\\n\\tarea が 377930 より大きい\\n\\tかつ\\n\\t人口が 127,090,\\n\\npage_id: 72ed7890-749c-4f03-888d-287e1867ae85\\n\\n090,000 人より\\n\\t多い国\\n\\t61\\n\\tView Slide\\n\\n \\n\\n\\tFROM world WHERE area > 377930 AND population > 1\\n\\t62\\n\\tView Slide\\n\\n \\n\\n\\tインデント大事\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area > 377930\\n\\tAND population > 127090000\\n\\t63\\n\\tView Slide\\n\\n \\n\\n\\tインデント大事\\n\\t予約語で改行するといい感じ\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area > 377930\\n\\tAND population > 127090000\\n\\t64\\n\\tView Slide\\n\\n \\n\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area > 377930\\n\\tAND population > 127090000\\n\\t65\\n\\tView Slide\\n\\n \\n\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area > 377930\\n\\tAND population > 127090000\\n\\tarea が 377,930 より大きい\\n\\t66\\n\\tView Slide\\n\\n \\n\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area > 377930\\n\\tAND population > 127090000\\n\\tarea が 377,930 より大きい\\n\\tかつ\\n\\t67\\n\\tView Slide\\n\\n \\n\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area > 377930\\n\\tAND population > 127090000\\n\\tarea が 377,930 より大きい\\n\\tかつ population が 127,090,000 より大きい\\n\\t68\\n\\tView Slide\\n\\n \\n\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area > 377930\\n\\tAND population > 127090000\\n\\t69\\n\\tView Slide\\n\\n \\n\\n\\tExercise 3 : 条件指定 SQLZOO: 0 SELECT basics\\n\\t面積か人口の数字が\\n\\t日本以下の国を取得しよう\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area > 377930\\n\\tAND population > 127090000\\n\\tSample\\n\\t70\\n\\tView Slide\\n\\n \\n\\n\\t答え合わせ\\n\\t71\\n\\tView Slide\\n\\n \\n\\n\\tORDER BY 句\\n\\tSQL\\n\\tView Slide\\n\\n \\n\\n\\t日本より面積と人口が大きい国で\\n\\tGDP が最も少ない国は？\\n\\t73\\n\\tView Slide\\n\\n \\n\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area > 377930\\n\\tAND population > 127090000\\n\\tORDER BY gdp\\n\\t74\\n\\tView Slide\\n\\n \\n\\n\\t逆に日本より面積と人口が小さい国で\\n\\tGDP が最も多い国は？\\n\\t75\\n\\tView Slide\\n\\n \\n\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area < 377930\\n\\tAND population < 127090000\\n\\tORDER BY gdp DESC\\n\\t76\\n\\tView Slide\\n\\n \\n\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area > 377930\\n\\tAND population > 127090000\\n\\tORDER BY gdp\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area < 377930\\n\\tAND population < 127090000\\n\\tORDER BY gdp DESC 77\\n\\tView Slide\\n\\n \\n\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area > 377930\\n\\tAND population > 127090000\\n\\tORDER BY gdp\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area < 377930\\n\\tAND population < 127090000\\n\\tORDER BY gdp DESC\\n\\t昇順\\n\\t78\\n\\tView Slide\\n\\n \\n\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area > 377930\\n\\tAND population > 127090000\\n\\tORDER BY gdp\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area < 377930\\n\\tAND population < 127090000\\n\\tORDER BY gdp DESC\\n\\t降順\\n\\t79\\n\\tView Slide\\n\\n \\n\\n\\tSELECT *\\n\\tFROM world\\n\\tORDER BY gdp DESC,\\n\\tarea,\\n\\npage_id: 72ed7890-749c-4f03-888d-287e1867ae85\\n\\narea,\\n\\tpopulation DESC\\n\\tソートするカラムは複数指定できる\\n\\t80\\n\\tView Slide\\n\\n \\n\\n\\tExercise 4 : ソート SQLZOO: 0 SELECT basics\\n\\t（１）もっとも人口が少ない国を探そう\\n\\t（２）面積がもっとも小さい国ベスト３を探そう\\n\\t81\\n\\tView Slide\\n\\n \\n\\n\\t答え合わせ\\n\\t82\\n\\tView Slide\\n\\n \\n\\n\\t副問い合わせ（サブクエリ）\\n\\tSQL\\n\\tView Slide\\n\\n \\n\\n\\tところで\\n\\t84\\n\\tView Slide\\n\\n \\n\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area > 377930\\n\\tAND population > 127090000\\n\\tORDER BY gdp\\n\\t85\\n\\tView Slide\\n\\n \\n\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area > 377930\\n\\tAND population > 127090000\\n\\tORDER BY gdp\\n\\t人口変わったらどうしよう\\n\\t86\\n\\tView Slide\\n\\n \\n\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area > 377930\\n\\tAND population > 127090000\\n\\tORDER BY gdp\\n\\t87\\n\\tView Slide\\n\\n \\n\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area > 377930\\n\\tAND population >\\n\\t(\\n\\tSELECT population\\n\\tFROM WORLD\\n\\tWHERE name = \\'Japan\\'\\n\\t)\\n\\tORDER BY gdp\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area > 377930\\n\\tAND population > 127090000\\n\\tORDER BY gdp\\n\\t88\\n\\tView Slide\\n\\n \\n\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area > 377930\\n\\tAND population >\\n\\t(\\n\\tSELECT population\\n\\tFROM world\\n\\t)\\n\\tORDER BY gdp\\n\\t副問い合わせが\\n\\t複数行の結果になるとエラー\\n\\t89\\n\\tView Slide\\n\\n \\n\\n\\tExercise 5 : 副問い合わせ SQLZOO: 0 SELECT basics\\n\\t面積も副問い合わせを利用するようにしよう\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE area > 377930\\n\\tAND population >\\n\\t(\\n\\tSELECT population\\n\\tFROM WORLD\\n\\tWHERE name = \\'Japan\\'\\n\\t)\\n\\tORDER BY gdp\\n\\t90\\n\\tView Slide\\n\\n \\n\\n\\t答え合わせ\\n\\t91\\n\\tView Slide\\n\\n \\n\\n\\tLIKE句\\n\\tSQL\\n\\tView Slide\\n\\n \\n\\n\\t日本みたいな国探して\\n\\t93\\n\\tView Slide\\n\\n \\n\\n\\t日本みたいな国探して\\n\\t94\\n\\tView Slide\\n\\n \\n\\n\\t‘Ja’ で始まる国を探して\\n\\t95\\n\\tView Slide\\n\\n \\n\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE name LIKE \\'Ja%\\'\\n\\t96\\n\\tView Slide\\n\\n \\n\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE name LIKE \\'Ja%\\'\\n\\t97\\n\\tView Slide\\n\\n \\n\\n\\tSELECT *\\n\\tFROM world\\n\\tWHERE name LIKE \\'Ja%\\'\\n\\tワイルドカード\\n\\t98\\n\\tView Slide\\nSELECT *\\nFROM world\\nWHERE name LIKE \\'J%\\';\\nSELECT *\\nFROM world\\nWHERE name LIKE \\'%n\\';\\nSELECT *\\nFROM world\\nWHERE name LIKE \\'J%n\\';\\n99\\nView Slide\\n\\npage_id: dbf19418-ddcf-4a9c-aad0-e79d7221ad74\\n\\n本記事では、私が2022年に読んでよかったO\\'Reillyの技術書とその要点を簡潔に解説する。本記事の内容はあくまで一個人の見解にすぎないので、参考程度に。今後O\\'Reilly関連の技術書を購入する上で、少しでも参考になるものがあれば幸いだ。\\n\\n読みやすいコード、質の高いコードを書く上で重要な原則が体系的にまとめられている。プログラミング初心者から上級者まで幅広く使える。プログラミングを学ぶ上で重要な原則(例：制御フロー、論理式など)やその書き方をこの１冊でまるごと学べる。本質的な内容と具体的なテクニックが両方ともまとめられていて読みやすい。何回も読み直して普段の開発に活かすべき重要な書籍である。\\n\\nアプリケーションの設計・開発における原則を図解やソースコード付きで丁寧に解説されている。今後のアプリケーション開発における原則をデータの量と煩雑さにフォーカスして書かれている。\\n本書の要旨は、「信頼性」「スケーラビリティ」「メンテナンス性」の三つを念頭に置いてアプリケーション開発を進めることである。その他にも、データの処理の仕方(エンコードなど)、レプリケーションやトランザクションなど、良質なアプリケーションを開発するために必要なテクニックが図解で丁寧にまとめられている。\\n640ページにも及ぶ非常に分厚い書籍であるものの、書いてあることは本質的で学びがある。今後、アプリケーション開発で生計を立てるプログラマーは全員読んでおくべきである。\\n\\n本書では、「レガシーコード」を改善するための原則が丁寧に解説されている。「レガシーコード」とは、バグを多く含んでいて、しかも壊れやすく拡張が難しいコードを意味する。「レガシーコード」の保守や管理には多大な労力が注ぎ込まれる。\\n本書では、「レガシーコード」を修正する上で重要なポイントを9つにわけてまとめられている。その中で、個人的に特に重要だと考えたものは次の3つだ。\\nやり方より先に目的、理由、誰のためかを伝える\\n協力しあう\\n設計は最後に行う\\n本書は「レガシーコード」を修正する――つまり、良質なコードを書くテクニックは書かれていない。「レガシーコード」をなくすための原則に焦点を当てて解説している。\\n\\npage_id: dbf19418-ddcf-4a9c-aad0-e79d7221ad74\\n\\n本書では、「レガシーコード」を修正する上で重要なポイントを9つにわけてまとめられている。その中で、個人的に特に重要だと考えたものは次の3つだ。\\nやり方より先に目的、理由、誰のためかを伝える\\n協力しあう\\n設計は最後に行う\\n本書は「レガシーコード」を修正する――つまり、良質なコードを書くテクニックは書かれていない。「レガシーコード」をなくすための原則に焦点を当てて解説している。本書は、普段自分の書いているコードを根本的に見直すきっかけを与える良書だ。\\n\\nソフトウェア開発における重要な概念である「ソフトウェアアーキテクチャ」を丁寧に解説している。ソフトウェアアーキテクチャの種類とその説明だけではなく、アーキテクチャを設計する上で重要な思考法やコミュニケーションの原則についてもまとめられている。\\nITアーキテクトや、これから設計等の上流工程で生計を立てるプログラマーは絶対に読んで損はないだろう。ソフトウェアアーキテクチャはソフトウェア開発を成功させるためには必要不可欠な概念である。\\n\\n本書は、ソフトウェアアーキテクチャにおける難題――「ハードパーツ」の取り扱い方にフォーカスを当てて詳細に説明されている。数多くあるソフトウェアアーキテクチャの中から、開発しているアプリケーションやプロダクトに応じて最適なアーキテクチャを選択する際の原則、テクニックについて丁寧にまとめられている。\\n『ソフトウェアアーキテクチャの基礎』とセットで、ソフトウェアアーキテクチャの分析・選択について詳細に学びたいなら本書を購読しよう。ソフトウェアアーキテクチャは非常に難解なので、本書を何回も読み直して基本を身につけておこう。\\n\\nマイクロサービスとは、簡単に言えばアプリケーションを複数の小さなサービスに分割して開発・運用されているサービスである。マイクロサービスは\\nLINE\\nや\\nCookpad\\nで採用されている。マイクロサービスの仕組み、特徴、長所、短所や課題点がまるごとこの１冊で学べる。\\nマイクロサービスについてわからない場合、あるいは実務でマイクロサービスを設計する必要に迫られた場合に本書の内容が役立つだろう。\\n\\npage_id: dbf19418-ddcf-4a9c-aad0-e79d7221ad74\\n\\nマイクロサービスは\\nLINE\\nや\\nCookpad\\nで採用されている。マイクロサービスの仕組み、特徴、長所、短所や課題点がまるごとこの１冊で学べる。\\nマイクロサービスについてわからない場合、あるいは実務でマイクロサービスを設計する必要に迫られた場合に本書の内容が役立つだろう。\\n\\nモノリシックなアプリケーションにマイクロサービスを適用したり、アーキテクチャの構造そのものを変えてマイクロサービスに変換したりする上で重要な原則が本書で丁寧に解説されている。マイクロサービスを適用させるテクニックはもちろん、マイクロサービスが成長するにつれて発生する課題への対応の仕方まで、豊富な具体例やシナリオを使って詳細に解説している。\\n実務でマイクロサービスを活用する上で、『マイクロサービスアーキテクチャ』とセットで確認しておきたい非常に重要な書籍である。\\n\\n認知科学や心理学などの学術的な議論や研究をベースに、人間の脳のメカニズムに最適な学習法や思考法を徹底解説している。それをプログラミング・エンジニアリングにどのように適用させる方法についても丁寧に解説している。\\n本書で紹介されている学習法は「SMART」な目標を立てることである。「SMART」は、「Specific」(具体的)、「Measurable」(測定可能)、「Achivable」(達成可能)、「Relevant」(適切)と「Time-boxed」(期限を決める)の5つの英単語の頭文字を取ったものである。\\n新しい技術やツールの使い方をどのように勉強すればいいのかわからないプログラマーは、とりあえず本書さえ読んでおけば問題ないだろう。内容はプログラミング・エンジニアリングに特化しているのですぐに実践できると思う。\\n本書は、良質なAPIを設計・開発する上で重要な原則やテクニックを丁寧に解説している。API設計・開発で生計を立てるプログラマーは全員読んでおくべき。APIに関する書籍は数多く存在するものの、正直本書さえ購入しておけば問題ないだろう。\\n本書はRESTというWebのアーキテクチャスタイルについて詳細に解説している、初めての本格的な書籍である。RESTの基礎知識から、RESTfulなWebサービスを設計する上で基本的な原則・テクニックまで幅広く網羅している。\\n\\npage_id: dbf19418-ddcf-4a9c-aad0-e79d7221ad74\\n\\nAPI設計・開発で生計を立てるプログラマーは全員読んでおくべき。APIに関する書籍は数多く存在するものの、正直本書さえ購入しておけば問題ないだろう。\\n本書はRESTというWebのアーキテクチャスタイルについて詳細に解説している、初めての本格的な書籍である。RESTの基礎知識から、RESTfulなWebサービスを設計する上で基本的な原則・テクニックまで幅広く網羅している。REST APIでWebアプリケーションを設計・開発することを検討しているプログラマーは全員読んでおくべきだろう。\\n初心者から上級者までPythonの基礎文法や応用的な内容(例：Webスクレイピングやデータ分析、データベースとの連携など)を丁寧に解説している。O\\'Reillyだけではなく、日本語のPythonに関する入門書は数多くあるものの、\\n『Python1年生』\\nと本書さえあればPythonの基礎知識をマスターできる。\\n本書はTypeScriptの基礎知識だけではなく、JSXやReact等の活用事例まで徹底解説しているTypeScriptの入門書。TypeScriptを本格的に学習したい初心者は絶対に購入するべきだ。\\n余談だが、私は本書をきっかけにTypeScriptにますます興味を持つようになった。\\n本書はReactの基礎知識やベストプラクティスをソースコード付きで丁寧に解説している良書である。学習・開発でReactを使っているなら買って損はないだろう。直接Reactの知識を説明するのではなく、前置きとしてReactの開発に必要なJavaScriptの基礎知識も説明していてわかりやすい。JavaScriptの基礎知識とReactの基本や開発フローをこの１冊で学習できる。\\n本書はSQLを使ってデータベースを設計するうえでやってはいけないことと、その対処法をソースコード付きで詳細に解説している。SQLを学習・実務で使っているなら絶対に買って損はない。SQLのコードをリファクタリングする上では必須の書籍である。\\n本書はDockerとコンテナ技術の双璧をなすKubernetes(k8s)の基礎知識やワークフローを詳細に解説している。Dockerのコンテナ作成のプロセスと比較しながら、Kubernetesのワークフローを学べる。学習・実務でKubernetesを使うなら絶対に読んでおこう。\\n余談だが、KubernetesはRaspberry Piと連携できて電子工作にも応用できる。\\n本記事では、私が2022年に読んでよかったO\\'Reillyの技術書とその要点を簡潔に解説した。\\n\\npage_id: dbf19418-ddcf-4a9c-aad0-e79d7221ad74\\n\\nDockerのコンテナ作成のプロセスと比較しながら、Kubernetesのワークフローを学べる。学習・実務でKubernetesを使うなら絶対に読んでおこう。\\n余談だが、KubernetesはRaspberry Piと連携できて電子工作にも応用できる。\\n本記事では、私が2022年に読んでよかったO\\'Reillyの技術書とその要点を簡潔に解説した。\\n今年読んでみたO\\'Reilly関連の技術書はハズレが１冊もなかった。今回の記事で紹介した技術書はまだ私のTwitterで紹介していないものも数多くあるので、年末年始をフル活用して精読し、内容をTwitterやZennでアウトプットしていきたい。\\n学生時代に読書や技術書の購読を習慣づけることができた。この経験は今後のエンジニアリングで大いに活かされるだろう。\\n今回の記事で紹介している書籍を網羅できればO\\'Reillyのオタクを名乗れるだろう。\\n本記事で掲載されている書籍の画像は以下のリンクから引用したものである。\\n\\npage_id: ae35984f-3003-490a-afe1-92bdc241c4e9\\n\\n始めに はじめまして、2022年4月に新卒として入社した Customer Analytics Division / DX Technology Unit の日比です。弊社では、より高性能なAIを開発するためのスキル研鑽として社内ブログでのアウトプットが盛んに行われています。本日はその中で私が執筆した「ワクチン接種後の体温変化をガウス過程回帰してみた」とい\\n【Go言語入門】goroutineとは？ 実際に手を動かしながら goroutineの基礎を理解しよう！\\nはじめまして。2022年4月に中途入社し、現在Analytics Delivery Divisionでバックエンド開発をしているエンジニアのナムです。ARISE analyticsに入社してから開発言語としてGoを使うことになりました。Goの特徴・メリットはいろいろありますが、今回はその中でもgoroutineについて簡単に話したいと思います。 gorou\\nはじめに ARISE analytics の近藤です。本記事では、次世代の意思決定技術として注目されている反実仮想機械学習（Counterfactual Machine Learning：CFML）を紹介します。 本記事は、CFMLを日本語で体系的に整理し、初学者の理解を手助けすることをねらいとして執筆しました。本記事の理解促進につながるように、ベー\\n\\n    ARISE Tech Blog  2022.01.28\\n \\n\\n\\n社内勉強会・資格取得制度を用いてAWS SAAの資格を取得した話\\n  \\n\\n\\n初めまして、Marketing Solution Divisionの原田と申します。ARISE analytics新卒1期生として入社し、すでに2年以上が経過しました。時間が経つのは一瞬ですね。さて、今回の記事では、ARISE analyticsの数あるスキル研鑽の取り組みの一つである有志勉強会で行われた「AWSカスケードトレーニング」に参加し、資格取得制度\\n\\n\\n    ARISE Tech Blog  2021.12.24\\n \\n\\n\\nConcentration Timeを活用した分析コンペ参加体験記\\n  \\n\\n\\nこんにちは。2020年4月に新卒として入社したMaketing Solution Division (MSD) 所属の小林と申します。 前回の記事では、私が従事していたWEB閲覧履歴によるターゲティングモデルについての技術紹介をさせていただきました。今回の記事は、業務技術紹介ではなく分析スキル向上のため同期と参加したKaggleの分析コンペ参加体験記となっ\\n\\n\\n    ARISE Tech Blog  2021.12.10\\n \\n\\n\\nPySparkで線形回帰モデルを作成する\\n  \\n\\n\\nこんにちは、Customer Analytics Divisionの石川航作と申します。Customer Analytics Divisionはお客様が展開するサービスの改善を目的としたコンサルティング業務を行っております。このサービスは1,000万人以上の会員様にご利用頂いており、一般的なデータ分析でお馴染みのpandasやscikit-learnを用いて\\n\\n\\n    ARISE Tech Blog  2021.11.18\\n\\npage_id: ae35984f-3003-490a-afe1-92bdc241c4e9\\n\\nARISE Tech Blog  2021.12.10\\n \\n\\n\\nPySparkで線形回帰モデルを作成する\\n  \\n\\n\\nこんにちは、Customer Analytics Divisionの石川航作と申します。Customer Analytics Divisionはお客様が展開するサービスの改善を目的としたコンサルティング業務を行っております。このサービスは1,000万人以上の会員様にご利用頂いており、一般的なデータ分析でお馴染みのpandasやscikit-learnを用いて\\n\\n\\n    ARISE Tech Blog  2021.11.18\\n \\n\\n\\nScala×Sparkによる位置情報分析例のご紹介 part2\\n  \\n\\n\\nこんにちは。Marketing Solution Divisionに所属している2年目データサイエンティストの山嵜です。私はデータ分析を通してマーケティングのサポートを行うBIツールの開発チームに3ヶ月ほど在籍したのち、位置情報を扱う分析チームに移籍しました。こちらのチームではデータ分析として広く一般的に扱われているPythonのみならず、Scala×Spa\\n\\nInfrastructure as Codeの冪等性とプロジェクトの関係性\\n\\n初めまして、New Business Sector (NBS), Advanced Tech Division所属の坂本です。プロジェクトではインフラエンジニアを担当しております。 現在、私が所属しているチームではヘルスケア領域におけるプロダクトを開発しており、その中で今回はバックエンド、特にインフラ領域に特化したIaCの管理手法をお話をさせていただければ\\n\\n\\n    ARISE Tech Blog  2021.10.08\\n \\n\\n\\nARISE analytics流SaaS開発・運用術 #1 TerraformとArgoCDで開発効率化\\n  \\n\\n\\nこんにちは。Marketing Solution Division(MSD)でDevOpsエンジニアと活動している山中です。 ARISE analyticsの提供するSaaSプロダクトを「1.新規顧客に迅速に提供(オンボーディング)する」「2.継続的なアップデートを提供(CD)する」ためにTerraformとArgoCDを活用した社内システム統合管理環境を\\n\\n\\n    ARISE Tech Blog  2021.08.13\\n \\n\\n\\n組織拡大に伴う、分析プロジェクトの品質平準化に向けた取り組み\\n  \\n\\n\\n初めまして、Digital Consulting Sector（DCS）, Marketing Solution Division所属の後藤です。 DCSでは、これまでに多くの分析プロジェクトを推進してまいりました。 今回は、分析プロジェクトの品質平準化に向けた、過去知見の体系化・方法論構築の取り組みについてご紹介します。 背景と課題 組織の規模\\n\\n\\n    ARISE Tech Blog  \\n   \\n\\n\\n皆さまこんにちは。 Marketing Solution Division, Partnering Solution Unitに所属している伊藤と申します。 今回は私も運営メンバの一員である、社内競技プログラミング大会について紹介します。 ARISE analyticsでは今年1月から社内で競技プログラミング大会が開催されています。ARISE anal\\n\\npage_id: ae35984f-3003-490a-afe1-92bdc241c4e9\\n\\nARISE Tech Blog  \\n   \\n\\n\\n皆さまこんにちは。 Marketing Solution Division, Partnering Solution Unitに所属している伊藤と申します。 今回は私も運営メンバの一員である、社内競技プログラミング大会について紹介します。 ARISE analyticsでは今年1月から社内で競技プログラミング大会が開催されています。ARISE anal\\n\\n\\n    ARISE Tech Blog  2021.06.25\\n \\n\\n\\nFlutter#2 〜Flutterの状態管理パターン （Riverpod）〜\\n  \\n\\n\\nはじめまして、Advance Tech Divisionでモバイルエンジニアをしている中塚です。今回はFlutterシリーズの第２弾ということで、Flutterでの状態管理パターンについて書こうと思います。Flutter での状態管理は様々なパターンが存在しており、当社でもプロジェクトによって利用しているパターンが異なっております。その中で、今回は状態管理で\\n\\nARISE analyticsの秋元です。 画像処理システムの開発では様々な画像処理技術をシステムに組み込んでいきますが、システムの要件に応じて適切なモデルや実行方法を選択する必要があります。今回は画像処理技術の一つである物体検知のモデルを実用向けに速度チューニングするという例を通して、画像処理システム開発の裏側の努力をご紹介します。 物体検知とは\\n\\n    ARISE Tech Blog  2021.04.23\\n \\n\\n\\n【効果検証】差分の差分法とは？\\n  \\n\\n\\nMarketing Solution Division所属の長谷井です。Marketing Solution Divisionでは、主にKDDI関連会社に対し、データ分析観点でのコンサルティング、ソリューションの提供などを行っています。 今回のトピック マーケティングの領域ではユーザーに対して、施策を実施します。施策の結果を確認する際、効果検証は重要なプ\\n\\n\\n    ARISE Tech Blog  2021.04.09\\n \\n\\n\\nめっさ分かりやすい因果推論 (その1) 概論とMeta-learner系手法\\n  \\n\\n\\nはじめに こんにちは、Customer-Analytics-Divisionの徳山と申します。本稿では因果推論手法の全体像を解説します。筆者は英語の通訳やカスタマーサクセス職を経てARISE analyticsに入社し、クライアント企業様の主力事業における販促施策について、施策に対する反応(『この施策によってどれくらいこのお客様はXXXとい\\n\\n\\n    ARISE Tech Blog  2021.03.26\\n \\n\\n\\nweb閲覧履歴を用いた広告ターゲティングモデルとは?\\n\\npage_id: ae35984f-3003-490a-afe1-92bdc241c4e9\\n\\nはじめに こんにちは、Customer-Analytics-Divisionの徳山と申します。本稿では因果推論手法の全体像を解説します。筆者は英語の通訳やカスタマーサクセス職を経てARISE analyticsに入社し、クライアント企業様の主力事業における販促施策について、施策に対する反応(『この施策によってどれくらいこのお客様はXXXとい\\n\\n\\n    ARISE Tech Blog  2021.03.26\\n \\n\\n\\nweb閲覧履歴を用いた広告ターゲティングモデルとは?\\n  \\n\\n\\n初めまして、2020年4月に新卒として入社したMaketing Solution Division (MSD) 所属の小林と申します。 普段の業務ではweb広告の支援をしております。具体的にはターゲティング広告の支援を行っており、web閲覧履歴データ・機械学習の手法を用いてモデルを作成し、どのような人にweb広告を表示させるべきかという広告配信リストを\\n\\nARISE Tech Blog  2021.01.22\\n\\nPylanceとVisual Studio Codeでバックエンドサーバを爆速開発\\n  \\n\\n\\nこんにちは。Marketing Solution Division(MSD)でAnalytics\\nQuery: SQLを勉強するのに良い資料は？\\nOriginal Answer: SQLを学ぶための良い資料として、GMOペパボのSQL研修資料が基本から始まり、RDBMSの歴史やデータベース設計に触れているので初心者にも理解しやすいです。また、Business Insiderやダイヤモンド・シグナルもSQLを含むテクノロジー系の情報を提供しているので、参考になるでしょう。\\nNew Answer: '}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.1}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 01 Aug 2024 16:35:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-01p8otbt5gis2mt84rnzemio'), (b'openai-processing-ms', b'2816'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'180043'), (b'x-ratelimit-reset-requests', b'18.394s'), (b'x-ratelimit-reset-tokens', b'5.987s'), (b'x-request-id', b'req_40044e9f63b4a3d11b7a288223775c56'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ac73d8b99b6688c-NRT'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Thu, 01 Aug 2024 16:35:19 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-01p8otbt5gis2mt84rnzemio', 'openai-processing-ms': '2816', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9997', 'x-ratelimit-remaining-tokens': '180043', 'x-ratelimit-reset-requests': '18.394s', 'x-ratelimit-reset-tokens': '5.987s', 'x-request-id': 'req_40044e9f63b4a3d11b7a288223775c56', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ac73d8b99b6688c-NRT', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_40044e9f63b4a3d11b7a288223775c56\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': \"You are an expert Q&A system that strictly operates in two modes when refining existing answers:\\n1. **Rewrite** an original answer using the new context.\\n2. **Repeat** the original answer if the new context isn't useful.\\nNever reference the original answer or context directly in your answer.\\nWhen in doubt, just repeat the original answer.\\nNew Context: 今回は、分析プロジェクトの品質平準化に向けた、過去知見の体系化・方法論構築の取り組みについてご紹介します。 背景と課題 組織の規模\\n\\n\\n    ARISE Tech Blog  \\n   \\n\\n\\n皆さまこんにちは。 Marketing Solution Division, Partnering Solution Unitに所属している伊藤と申します。 今回は私も運営メンバの一員である、社内競技プログラミング大会について紹介します。 ARISE analyticsでは今年1月から社内で競技プログラミング大会が開催されています。ARISE anal\\n\\npage_id: ae35984f-3003-490a-afe1-92bdc241c4e9\\n\\nARISE Tech Blog  \\n   \\n\\n\\n皆さまこんにちは。 Marketing Solution Division, Partnering Solution Unitに所属している伊藤と申します。 今回は私も運営メンバの一員である、社内競技プログラミング大会について紹介します。 ARISE analyticsでは今年1月から社内で競技プログラミング大会が開催されています。ARISE anal\\n\\n\\n    ARISE Tech Blog  2021.06.25\\n \\n\\n\\nFlutter#2 〜Flutterの状態管理パターン （Riverpod）〜\\n  \\n\\n\\nはじめまして、Advance Tech Divisionでモバイルエンジニアをしている中塚です。今回はFlutterシリーズの第２弾ということで、Flutterでの状態管理パターンについて書こうと思います。Flutter での状態管理は様々なパターンが存在しており、当社でもプロジェクトによって利用しているパターンが異なっております。その中で、今回は状態管理で\\n\\nARISE analyticsの秋元です。 画像処理システムの開発では様々な画像処理技術をシステムに組み込んでいきますが、システムの要件に応じて適切なモデルや実行方法を選択する必要があります。今回は画像処理技術の一つである物体検知のモデルを実用向けに速度チューニングするという例を通して、画像処理システム開発の裏側の努力をご紹介します。 物体検知とは\\n\\n    ARISE Tech Blog  2021.04.23\\n \\n\\n\\n【効果検証】差分の差分法とは？\\n  \\n\\n\\nMarketing Solution Division所属の長谷井です。Marketing Solution Divisionでは、主にKDDI関連会社に対し、データ分析観点でのコンサルティング、ソリューションの提供などを行っています。 今回のトピック マーケティングの領域ではユーザーに対して、施策を実施します。施策の結果を確認する際、効果検証は重要なプ\\n\\n\\n    ARISE Tech Blog  2021.04.09\\n \\n\\n\\nめっさ分かりやすい因果推論 (その1) 概論とMeta-learner系手法\\n  \\n\\n\\nはじめに こんにちは、Customer-Analytics-Divisionの徳山と申します。本稿では因果推論手法の全体像を解説します。筆者は英語の通訳やカスタマーサクセス職を経てARISE analyticsに入社し、クライアント企業様の主力事業における販促施策について、施策に対する反応(『この施策によってどれくらいこのお客様はXXXとい\\n\\n\\n    ARISE Tech Blog  2021.03.26\\n \\n\\n\\nweb閲覧履歴を用いた広告ターゲティングモデルとは?\\n\\npage_id: ae35984f-3003-490a-afe1-92bdc241c4e9\\n\\nはじめに こんにちは、Customer-Analytics-Divisionの徳山と申します。本稿では因果推論手法の全体像を解説します。筆者は英語の通訳やカスタマーサクセス職を経てARISE analyticsに入社し、クライアント企業様の主力事業における販促施策について、施策に対する反応(『この施策によってどれくらいこのお客様はXXXとい\\n\\n\\n    ARISE Tech Blog  2021.03.26\\n \\n\\n\\nweb閲覧履歴を用いた広告ターゲティングモデルとは?\\n  \\n\\n\\n初めまして、2020年4月に新卒として入社したMaketing Solution Division (MSD) 所属の小林と申します。 普段の業務ではweb広告の支援をしております。具体的にはターゲティング広告の支援を行っており、web閲覧履歴データ・機械学習の手法を用いてモデルを作成し、どのような人にweb広告を表示させるべきかという広告配信リストを\\n\\nARISE Tech Blog  2021.01.22\\n\\nPylanceとVisual Studio Codeでバックエンドサーバを爆速開発\\n  \\n\\n\\nこんにちは。Marketing Solution Division(MSD)でAnalytics Platform(APF)を開発している山中です。MSDはデータ分析による顧客のマーケティングコンサルティング、機械学習マーケティング施策支援ツールの開発・導入支援を行っています。 今年の6月にリリースされたPylanceをAPF開発にも採用しており、日々\\n\\n\\n    ARISE Tech Blog  2020.12.25\\n \\n\\n\\nGitHub\\nQuery: SQLを勉強するのに良い資料は？\\nOriginal Answer: SQLを学ぶための良い資料として、GMOペパボのSQL研修資料が基本から始まり、RDBMSの歴史やデータベース設計に触れているので初心者にも理解しやすいです。また、Business Insiderやダイヤモンド・シグナルもSQLを含むテクノロジー系の情報を提供しているので、参考になるでしょう。\\nNew Answer: \"}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.1}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 01 Aug 2024 16:35:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-01p8otbt5gis2mt84rnzemio'), (b'openai-processing-ms', b'2222'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9997'), (b'x-ratelimit-remaining-tokens', b'184803'), (b'x-ratelimit-reset-requests', b'23.794s'), (b'x-ratelimit-reset-tokens', b'4.558s'), (b'x-request-id', b'req_f33e7d50a8cbe4d4bf6bc6641f33c6c9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ac73da11ffd688c-NRT'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Thu, 01 Aug 2024 16:35:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-01p8otbt5gis2mt84rnzemio', 'openai-processing-ms': '2222', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9997', 'x-ratelimit-remaining-tokens': '184803', 'x-ratelimit-reset-requests': '23.794s', 'x-ratelimit-reset-tokens': '4.558s', 'x-request-id': 'req_f33e7d50a8cbe4d4bf6bc6641f33c6c9', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ac73da11ffd688c-NRT', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_f33e7d50a8cbe4d4bf6bc6641f33c6c9\n",
      "DEBUG:llama_index.core.response_synthesizers.refine:> Refine context: 今回は私も運営メンバの一員である、社内競技プログラミング大会について紹介します。 ARISE ...\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are an expert Q&A system that strictly operates in two modes when refining existing answers:\\n1. **Rewrite** an original answer using the new context.\\n2. **Repeat** the original answer if the new context isn\\'t useful.\\nNever reference the original answer or context directly in your answer.\\nWhen in doubt, just repeat the original answer.\\nNew Context: 今回は私も運営メンバの一員である、社内競技プログラミング大会について紹介します。 ARISE analyticsでは今年1月から社内で競技プログラミング大会が開催されています。ARISE anal\\n\\npage_id: ae35984f-3003-490a-afe1-92bdc241c4e9\\n\\nARISE Tech Blog  \\n   \\n\\n\\n皆さまこんにちは。 Marketing Solution Division, Partnering Solution Unitに所属している伊藤と申します。 今回は私も運営メンバの一員である、社内競技プログラミング大会について紹介します。 ARISE analyticsでは今年1月から社内で競技プログラミング大会が開催されています。ARISE anal\\n\\n\\n    ARISE Tech Blog  2021.06.25\\n \\n\\n\\nFlutter#2 〜Flutterの状態管理パターン （Riverpod）〜\\n  \\n\\n\\nはじめまして、Advance Tech Divisionでモバイルエンジニアをしている中塚です。今回はFlutterシリーズの第２弾ということで、Flutterでの状態管理パターンについて書こうと思います。Flutter での状態管理は様々なパターンが存在しており、当社でもプロジェクトによって利用しているパターンが異なっております。その中で、今回は状態管理で\\n\\nARISE analyticsの秋元です。 画像処理システムの開発では様々な画像処理技術をシステムに組み込んでいきますが、システムの要件に応じて適切なモデルや実行方法を選択する必要があります。今回は画像処理技術の一つである物体検知のモデルを実用向けに速度チューニングするという例を通して、画像処理システム開発の裏側の努力をご紹介します。 物体検知とは\\n\\n    ARISE Tech Blog  2021.04.23\\n \\n\\n\\n【効果検証】差分の差分法とは？\\n  \\n\\n\\nMarketing Solution Division所属の長谷井です。Marketing Solution Divisionでは、主にKDDI関連会社に対し、データ分析観点でのコンサルティング、ソリューションの提供などを行っています。 今回のトピック マーケティングの領域ではユーザーに対して、施策を実施します。施策の結果を確認する際、効果検証は重要なプ\\n\\n\\n    ARISE Tech Blog  2021.04.09\\n \\n\\n\\nめっさ分かりやすい因果推論 (その1) 概論とMeta-learner系手法\\n  \\n\\n\\nはじめに こんにちは、Customer-Analytics-Divisionの徳山と申します。本稿では因果推論手法の全体像を解説します。筆者は英語の通訳やカスタマーサクセス職を経てARISE analyticsに入社し、クライアント企業様の主力事業における販促施策について、施策に対する反応(『この施策によってどれくらいこのお客様はXXXとい\\n\\n\\n    ARISE Tech Blog  2021.03.26\\n \\n\\n\\nweb閲覧履歴を用いた広告ターゲティングモデルとは?\\n\\npage_id: ae35984f-3003-490a-afe1-92bdc241c4e9\\n\\nはじめに こんにちは、Customer-Analytics-Divisionの徳山と申します。本稿では因果推論手法の全体像を解説します。筆者は英語の通訳やカスタマーサクセス職を経てARISE analyticsに入社し、クライアント企業様の主力事業における販促施策について、施策に対する反応(『この施策によってどれくらいこのお客様はXXXとい\\n\\n\\n    ARISE Tech Blog  2021.03.26\\n \\n\\n\\nweb閲覧履歴を用いた広告ターゲティングモデルとは?\\n  \\n\\n\\n初めまして、2020年4月に新卒として入社したMaketing Solution Division (MSD) 所属の小林と申します。 普段の業務ではweb広告の支援をしております。具体的にはターゲティング広告の支援を行っており、web閲覧履歴データ・機械学習の手法を用いてモデルを作成し、どのような人にweb広告を表示させるべきかという広告配信リストを\\n\\nARISE Tech Blog  2021.01.22\\n\\nPylanceとVisual Studio Codeでバックエンドサーバを爆速開発\\n  \\n\\n\\nこんにちは。Marketing Solution Division(MSD)でAnalytics Platform(APF)を開発している山中です。MSDはデータ分析による顧客のマーケティングコンサルティング、機械学習マーケティング施策支援ツールの開発・導入支援を行っています。 今年の6月にリリースされたPylanceをAPF開発にも採用しており、日々\\n\\n\\n    ARISE Tech Blog  2020.12.25\\n \\n\\n\\nGitHub Actionsは商用システムのCI/CDツールとして使えるか？！\\n  \\n\\n\\nAdvanced Tech Divisionでデータエンジニアをしている對馬（つしま）です。前回は分析モデルを商用化する際に考慮すべき5つのこと について書かせて頂きましたが、今回は少し毛色を変えてCI/CDについて書かせて頂きます。CI/CDはGitHub Actions、CircleCI、Travis CI、AWS CodePipelineなど、様々なサ\\n\\n\\n    ARISE Tech Blog  2020.12.20\\n \\n\\n\\nレコメンド#2 Sparkで機械学習モデルを高速分散推論させる\\n  \\n\\n\\n導入 レコメンドエンジン連載の第2回目です。 前回の「レコメンドって何？」はこちらを御覧ください。 Analytics Delivery Division Initiative Center機械学習担当の下野です。 Initiative Centerでは最新技術を用いて、分析の手法や環境を業務適用可能な品質で実現する活動しています。\\n\\n\\n    ARISE Tech Blog  2020.12.07\\n \\n\\n\\nデータ分析におけるコーディング規約とフォーマッターの役割\\n\\npage_id: ae35984f-3003-490a-afe1-92bdc241c4e9\\n\\n導入 レコメンドエンジン連載の第2回目です。 前回の「レコメンドって何？」はこちらを御覧ください。 Analytics Delivery Division Initiative Center機械学習担当の下野です。 Initiative Centerでは最新技術を用いて、分析の手法や環境を業務適用可能な品質で実現する活動しています。\\n\\n\\n    ARISE Tech Blog  2020.12.07\\n \\n\\n\\nデータ分析におけるコーディング規約とフォーマッターの役割\\n  \\n\\n\\nこんにちは。Customer Analytics Divisionでデータサイエンティストをしている高田です。Customer Analytics Divisionでは、KDDIやauに関連するサービスのデータ分析や、それに伴うコンサルティングを行っています。データ分析ではpandasやPySparkを使うことが多く、私含むデータサイエンティストの多くの方が\\n\\nARISE Tech Blog  2020.10.30\\n\\nsparkパラメータ最適化チューニング\\n  \\n\\n\\nこんにちは。Customer Analytics Division所属データサイエンティスト兼データエンジニアの渡邉です。ARISE analyticsでは数百人のデータサイエンティストが活躍しています。一般的な分析環境は、データサイエンティストがそれぞれEMRを立て、その上のsparkで分析を走らせています。ただ、その分日々の分析費用も大きいものとなってい\\n\\n\\n    ARISE Tech Blog  2020.10.23\\n \\n\\n\\nコロナ禍における経済分析と位置情報の活用\\n  \\n\\n\\nこんにちは、Social Innovation Divisionで位置情報分析を担当している高良と申します。今回は、コロナ禍における経済活動の分析と、それに対して位置情報がどのように活用されているかをご紹介します。 コロナ禍における経済分析の急速な蓄積 2020年初めから世界的に感染拡大が生じている新型コロナウィルス感染症は、各国の経済活動にとても大きな\\n\\n\\n    ARISE Tech Blog  2020.10.16\\n \\n\\n\\nMulti-Object Trackingの精度評価指標\\n  \\n\\n\\nBusiness Development Divisionでデータサイエンティストをしている秋元です。 今回はARISEの画像分析チームが取り組んでいる画像処理技術の一つであるMulti-Object Trackingについて、その評価指標を紹介します。 1.Multi-Object Trackingとは Multi-Object Tracking（M\\n\\n\\n    ARISE Tech Blog  2020.09.25\\n \\n\\n\\nARISE analytics流ギルド活動\\n  \\n\\n\\n初めまして、Advanced Tech Divisionに所属している村瀬と申します。 Advanced Tech Divisionでは、多くの会社と協創しながら分析ソリューション案件を推進しております。 今回は、多くの案件を推進していく中で得られた暗黙知を形式知にしていくための活動をご紹介いたします。 背景と課題 ARISE analyti\\n\\n\\n    ARISE Tech Blog\\n\\npage_id: ae35984f-3003-490a-afe1-92bdc241c4e9\\n\\nARISE Tech Blog  2020.09.25\\n \\n\\n\\nARISE analytics流ギルド活動\\n  \\n\\n\\n初めまして、Advanced Tech Divisionに所属している村瀬と申します。 Advanced Tech Divisionでは、多くの会社と協創しながら分析ソリューション案件を推進しております。 今回は、多くの案件を推進していく中で得られた暗黙知を形式知にしていくための活動をご紹介いたします。 背景と課題 ARISE analyti\\n\\n\\n    ARISE Tech Blog  \\n   \\n\\n\\nARISE libraryとは こんにちは、新人エンジニアの森田です。ARISEでは自己研鑽として全社員が書籍・論文を自由に購入出来る制度があります。読了後はARISEの本棚に納付し社員全員で共有しています。この納付された本を管理する社内書籍管理システム”ARISE library”が社員に提供されています。実はこれ、自社内開発でシステムを提供してます\\n\\n初めまして、Advanced Tech Divisionでデータエンジニアをしている對馬（つしま）です。 実証実験等の検証フェーズで構築した機械学習や深層学習を用いた分析モデルをシステムとして商用化する際に、どのようにシステムに組み込めば良いか戸惑うことはありませんか？ 今回は私自身のこれまでの経験(長くなるので今度紹介します)をもとに分析モデ\\n\\n    ARISE Tech Blog  2020.07.20\\n \\n\\n\\nFlutter#1 〜ARISE analyticsのプロジェクトでFlutterを採用してみました〜\\n  \\n\\n\\n初めまして、Advanced Tech Divisionでモバイルエンジニアをしている酒井です。最近モバイル界隈で盛り上がっているFlutterを、ARISEのプロジェクトでも採用しており、なかなか良いなと思っているので、記事を書いていこうと思います（がんばって連載にしたい）。 盛り上がってきたのが割と最近ということもあり、特に日本語の記事があまり無い\\n\\npage_id: 02a22182-b9b8-46a7-be58-6ceaf9575623\\n\\n画像生成AI（midjourney）の基礎プロンプト集をつくりました。\\n100以上のおすすめ基礎プロンプトを公開しています。\\n実際にmidjourneyなどの画像生成AIを使う時に参考にしてください。\\n完全に無料で公開\\nしているので、この記事が良いと思った方は、\\nお金はいりませんが、\\nTwitter\\nをフォロー\\nしていただけると喜びます。\\n普段、AIの最新情報を発信しています。\\nYoutubeで、この記事に沿った「やさしい教科書」解説をしている\\nので、そちらも参照ください。\\nhttps://www.youtube.com/@aibujp/featured\\nおかげさまでかなり多くの方に、チャンネル登録していただいています（現在1万人超）。\\nnoteのメンバーシップもやってます。\\n注目のAIニュースやツールをほぼ毎日まとめてレポートを紹介しています。\\nおかげさまで100人以上の方に登録いただいてて好評です。\\nこの記事は随時更新予定です。ブックマーク(noteのスキなど)推奨。\\nプロンプトキーワード集\\n特に初心者向けには、以下の公式を用いて\\nそれぞれのスタイルや、構図、ライティングなどにプロンプトを１つ１つ当てはめていって試していくのをおすすめしています。\\nプロンプト例\\n詳細できれいな画像描写\\nA detailed image of [subject] [doing something] during [time of day], taken with a [camera], using [lens] with cinematic lighting --v 5 --ar 16:9\\nA detailed image of woman dancing and smile during evening, taken with a fujifilm, using Leica 11678 with cinematic lighting --v 5 --ar 16:9\\n\\nスタイル\\nZoomorphism\\nrabbit, Zoomorphism --ar 16:9 --v 5\\n\\nStudio Ghibli\\nrabbit, Studio Ghibli --ar 16:9\\n\\nPixar\\nrabbit, Pixar --ar 16:9\\n\\nCyberpunk\\nWasteland Punk\\nrabbit, Wasteland Punk --ar 16:9\\n\\nPhantasmal iridescent きらきらに\\nrabbit, Phantasmal iridescent --ar 16:9 --v 5\\n\\nIllustration\\nvintage ヴィンテージ\\nRealism リアルに\\nSurrealism こういうスタイルのアート\\nPaper art 紙のアート\\nLayered Paper\\nIsometric art かわいい3D図形\\nNaive art\\nWatercolor painting 水彩画\\nBlacklight ブラックライト\\nStained Glass window ステンドグラス\\nUkiyoe 浮世絵\\nDouble Exposure\\nInfographic drawing インフォグラフィック\\nDiagrammatic drawing 図面\\nNeo-realism\\nPost-impressionism\\nAnthropomorphism 擬人化\\nA as B BになったA\\n8-bit pixel art ピクセルアート\\nPoster style ポスター\\nInk style インク\\ncomic drawing 漫画系\\nduotone\\nsynthwave\\nkawaii\\nA made of B BでできたA（例はダイヤモンド）\\nジャンル\\nLandscape 風景\\nArchitectural design 建物\\ninterior インテリア\\nportrait ポートレート\\nwildlife 野生動物\\nidentification symbol ロゴシンボル\\nart\\nanime\\nアーティスト\\nVincent van Gogh\\nPablo Picasso\\nLeonardo da Vinci\\nSalvador Dali\\nBanksy\\nこのアーティスト集がおすすめです。\\n\\npage_id: 02a22182-b9b8-46a7-be58-6ceaf9575623\\n\\nhttps://docs.google.com/spreadsheets/d/1cm6239gw1XvvDMRtazV6txa9pnejpKkM5z24wRhhFz0/edit#gid=1057933666\\n写真家\\nphoto by ~~\\nportrait photo by ~~\\nstreet photo by ~~\\nこのように記載し、写真家の名前を記載することで、\\nその写真家が撮ったような画像を生成できます。\\nどのような写真家がいるかは、このスプレットシートが便利です。\\nhttps://docs.google.com/spreadsheets/d/16KKh1FQmd-r98K9aWPBux5m9lc9PCV_T1AWgU54qXm8/edit?usp=sharing\\n構図\\nclose up\\nextreme closeup\\nwide view\\nbird’s-eye view\\nfull body 全身\\nground-level shot\\nhead shot\\nface shot\\n\\npage_id: ec403f89-2c5f-4dcb-a96c-afffb2e9a601\\n\\nアイデアの力を解き放つ\\nEdrawMind（エドラマインド）は、マインドマップが書きやすい。\\nあなたのアイディアを加速させる。それが「エドラマインド」\\nMac, LinuxWindows, LinuxWindows, Mac, Web, Android,iOSにも利用可能。 \\n詳しく見る\\n\\nブレインストーミング＆発想\\n素晴らしいアイデアは、コーヒーとブレインストーミングから始まる\\n行き詰まった感じですか？飲み物を飲みながら「マインドマップ」でブレストしましょう。柔軟な発想には自由に記載出来る。 AI を活用したブレインストーミング機能を試して、革新的なアイデアをたくさん生み出しましょう。\\n心を動かすプレゼンテーション\\n「情報をただ提示」するのではなく、「キモチ」が動くプレゼンを作成\\nEdrawMind を使用すると、数秒で美しいプレゼンテーションを作成できます。 マインドマップに話題を書き留め、色や画像を追加するだけで、PPTのようなスライドショーに変えることができます!\\n戦略と計画\\n心配がある？全てを書き込み事前に解消してみましょう！\\nエドラマインドならマインドマップ、フローチャート、ガントチャート、戦略分析、製品管理、プロジェクト計画などが\\n\\n\\nスムーズに行えます。リアルタイムに変更可能なので、チームの全員で同じ目標に取り組むことが出来ます。\\n\\n共有とコラボレーション\\n「みんなで」「ディレクターだけ」「制作部だけ」・・・閲覧／編集権限を簡単に変更\\n閲覧と編集の権限を細かく設定できるので、友達、チームメンバーまたは同僚と資料を共有できます。家にいても、オフィスにいても、地球の反対側にいても、一緒にプロジェクトに取り組めます。\\n\\nマインドマップを書く上で「エドラマインド」が優れている\\n\\npage_id: ec403f89-2c5f-4dcb-a96c-afffb2e9a601\\n\\n９つのスペシャルポイント\\n\\n企業認証レベルの安全性\\n転送されるすべての情報は、最高レベルの SSL 暗号化によって保護されます。\\n\\nマルチプラットフォームの互換性\\n利用可能なすべてのOSおよびすべての最新の Web ブラウザでの実行をサポートします。\\n\\nリアルタイムコラボレーション\\n複数のチーム メンバーが同期して共同作成できます。\\n\\nワンクリック作成\\nワンクリックで、Word、HTML、Markdownドキュメントをマインドマップに変換できます。\\n\\nエクスポート\\nマインド マップを PDF、Word、Excel、PowerPoint®、画像に簡単にエクスポートできます。\\n\\nスマートレイアウト\\nノードを追加、削除、または移動すると、マップが自動的に調整され、配置が維持されます。\\n\\nアウトライン\\nアウトラインとマインドマップの間でビューを切り替えて、さまざまな視点から見ることができます。\\n\\nテーマ\\n豊富な組み込みテーマから適切なものを選択し、調整して独自のスタイルを作成できます。\\n\\nDropboxを併用して便利に使う\\nDropbox と連携することも可能。マインドマップを便利に利用する事が出来ます。\\n公開されている膨大なマインドマップの例とテンプレートから\\n\\n\\nインスピレーションを得る\\n\\nタイムライン\\n\\nバブルチャート\\n\\nサークル図\\n\\nサンバーストマップ\\n\\nマインドマップ\\n\\n魚の骨図\\n\\n組織図\\n\\nツリー型マップ\\n\\nタイムライン\\n\\nバブルチャート\\n\\nサークル図\\n\\nサンバーストマップ\\n\\nマインドマップ\\n\\n魚の骨図\\n\\n組織図\\n\\nツリー型マップ\\n\\npage_id: 72b5b718-4ab8-422a-b062-94d668041014\\n\\nこの記事は、一度使われて終わるような、ChatGPT にちょっとした機能を追加しただけの GPTではなく、\\n本当に使われる素晴らしく便利な GPTs を作成、開発するための教科書\\nとして、書きました。\\n今までの GPTs 開発関連の情報を全てまとめた内容になっています。\\nこの note 一冊を読めば、GPTs 制作の基礎から応用まで全部わかります。\\n記事の内容は必要に応じて適宜アップデートしていきます。\\n目次は以下です：\\n目次\\n第1章 GPTsの概要とその可能性\\nそもそも GPTs とはなんでしょうか？\\n一言で言うと、\\nChatGPTを自分独自に大幅にカスタマイズできる機能とそのカスタマイズされたAIのこと\\nです。\\nただし、GPTsを単なるChatGPT のいち機能の一つとして考えるのは非常にもったいないです。\\nOpenAI は、GPT Store という、他の人が作ったGPTsを使えるようになるストアのリリースを来年控えており、ここでお金を稼ぐこともできるようになると、公式にアナウンスしています。\\nまた、GPTs は、まだそのポテンシャルが知れ渡っていませんが、特に業務効率化の面において、非常に大きな影響をもたらすものです。\\nまだ余りポテンシャルが知られていないと言ったのは、\\n本当に質が高い GPTs の数がまだまだ少ない\\nからです。\\n良い GPT を作れる GPTs 開発者の数が不足\\nしています。\\n例えば、ChatGPT研究所メンバーが作った以下のような秘書GPTはカレンダーの管理に便利で、実際に日常で普段使いしています：\\nこのGPT自身、まだまだ改善の余地があり、本当に質が高いGPTとは言いません。\\n参考までに、以下に\\nChatGPT研究所がこれまでに作成したGPTs\\n を列挙します。：\\n8412個のGPTsから最適なGPTを探索：\\nGPT Finder\\nGoogle ログインをして Google カレンダーやGmailを管理：\\n秘書GPT（限定公開）\\nGrok のシステムプロンプトをハックしてGrokをコピー：\\nGrok GPT\\nサムネイル画像の作成を画像からテキストまで完全に自動化：\\nTnumbnail Sckether\\nGIF画像を自動生成する：\\nGIF Maker\\nKnowldge を与えてカスタマーサポートを自動化するGPT （非公開）\\n語彙力推定と頻度順に単語を学べるGPT：\\nAITAN\\nデヴィ夫人の人格を模倣した\\nデヴィ夫人AI\\nその他多数。少なくとも50個以上は作ってきています。\\n\\npage_id: 72b5b718-4ab8-422a-b062-94d668041014\\n\\nこの記事は、これらのGPTの制作経験をもとにして書いています。\\n公開しているGPTが、他のユーザーに使用された合計回数は現状3万5千回以上です。GPT Finder は単体で1万回以上利用されています：\\n\\n世界に目を向けると、単体で15万回以上も使用されている、\\nGrimorie\\n \\nと言う GPTがあります\\n：\\n\\nしかしはっきりいって、この Grimorie ですらまだまだ改善の余地があり、最高のGPTとは言えないと私は考えています。\\nここで言いたいのは、\\n\\n\\n今、GPTs領域には無限の可能性があり、\\n\\n\\nアプリストアが出てきた、あの2008年当時のように、\\n\\n\\n大きなチャンスが目の前に広がっていると言うことです。\\nこの note を書いた理由のひとつが、\\n\\n\\n日本から素晴らしい GPTs がどんどんと作られていき、\\n\\n\\n世界で使われるGPTが出てきて欲しいから\\nです。\\nこの note を読み、\\nあなたが実際に本当に便利なGPTsを作って、\\n\\n\\nそれをみんなに共有してくれることを願っています\\n。\\nGPT Store に出さずとも、\\n\\n\\n自分や社内専用のGPTを作るのも良いでしょう。\\n\\n\\n今後の業務効率を何倍にもアップさせる可能性を秘めています。\\nちゃんとしたGPTsを作れる人はまだまだ限られているため、\\n\\n\\nGPTs制作領域はチャンスしかないです。\\n【超簡単】 GPT の作り方\\nGPTs の素晴らしいところは、これまでのアプリ開発など、高度なエンジニアリングスキルを要求されるものとは異なり、\\nアイデアさえあれば誰でも本当に簡単に優秀なエージェントが作れてしまう点\\n、にあります。\\nまだ一回も作ったことがない人は、以下を参考にして、\\n\\n\\nとにかく一個、作ってみましょう。\\nここで紹介するやり方は、GPT Builder と対話しながら、作りたいGPTを尋ねていく方法です。\\n後述するように、この方法だとプロンプトが自分で自由に設定できないので、質が高いGPTを作るには GPT Builder に頼らず、自分でプロンプトを編集する必要があります。\\nですが、このやり方はとにかく簡単なため、\\n\\n\\nとにかく一個作ってみるには良い一歩です。\\nわかる方は、この章は飛ばしてOKです。\\nStep 1. GPT Builder を立ち上げる\\n新しい ChatGPT UI の My GPTs のすぐ下、Create a GPT をクリックします。\\n\\nGPT の作成を補助してくれる GPT Builder が立ち上がります。\\n以下のURLからでもOKです：\\nhttps://chat.openai.com/gpts/editor\\nStep 2. 何を作りたいのかを伝える、GPTタイトルの決定\\nここでインタラクティブに会話形式で作成します。\\n\\npage_id: 72b5b718-4ab8-422a-b062-94d668041014\\n\\nとにかく一個作ってみるには良い一歩です。\\nわかる方は、この章は飛ばしてOKです。\\nStep 1. GPT Builder を立ち上げる\\n新しい ChatGPT UI の My GPTs のすぐ下、Create a GPT をクリックします。\\n\\nGPT の作成を補助してくれる GPT Builder が立ち上がります。\\n以下のURLからでもOKです：\\nhttps://chat.openai.com/gpts/editor\\nStep 2. 何を作りたいのかを伝える、GPTタイトルの決定\\nここでインタラクティブに会話形式で作成します。\\n\\n\\n\\tこんにちは！新しいGPTを作るのを手伝います。例えば、\"新商品のビジュアル制作を手伝ってくれるクリエイターを作る \"とか、\"私のコードのフォーマットを手伝ってくれるソフトウェアエンジニアを作る \"とか。\\n\\tあなたは何を作りたいですか？\\nGPT Builder\\nといっています。\\n\\n\\nGPT Builder と会話していくだけで、簡単に完成\\nしてしまいます。\\n\\n\\n試しに、ブログ記事タイトルを代わりに考えてくれるボットを作ってみます。日本語でも大丈夫ですが、今はなぜか返答が全て英語になってしまうようです。\\n\\nボットのタイトルを勝手に決めてくれました。他の提案が欲しかったらそのように尋ねればOKです。\\nStep 3. ロゴを決定する\\nタイトルが決まると、勝手にボットのロゴを決めてくれます。\\n\\nこれも、気に入らなかったら、変更をお願いすればOKです。\\nStep 4. トーンを決定する\\n画像が決まると、フォーマルか、カジュアルか、というトーンを聞いてきますので、答えます。\\n\\nそうすると、最後に\\n気を付けるべき点\\nなどを聞いてきますので、SEOに気をつけてなどをいっておきます。\\n\\n変更したいことを言うと、勝手にプロンプトを変更してくれます。\\n\\n\\n実際に作成された GPT の詳細は、Configure タブで確認できます。\\n\\n色々と設定できる項目がありますが、ここでは一旦無視しましょう。\\n\\n\\n後の章で、全て詳しく解説していきます。\\nこれらはもちろん手作業で変更することができます。\\n実際の GPT の動作は、右側の Preview タブからいつでも確認することができます。\\n\\nGPT の共有\\nGPT の共有範囲は、右上から、自分だけ、URLを知っている人だけ、パブリックに公開の三つから選ぶことができます。\\n\\n**Only me は、自分だけ。\\n\\n\\n**URLにアクセスしても自分のアカウントだけしかアクセスできないため、自分専用の特化型GPTに使います。\\nOnly people with a link は、リンクを知っている人だけ\\n。\\n\\npage_id: 72b5b718-4ab8-422a-b062-94d668041014\\n\\n**URLにアクセスしても自分のアカウントだけしかアクセスできないため、自分専用の特化型GPTに使います。\\nOnly people with a link は、リンクを知っている人だけ\\n。\\n\\n\\n例えば、社内用で、機密情報を扱わないGPTなどに使えます。\\nPublic は、GPT Store に並びます。\\nGPT Store が出る前に質の高いGPTを作っておくのがベストです。\\nGPT Store に出す場合は必須： Builder Profile を設定する\\nここでは、GPT Store に出す場合に必須のBuilder Profile の設定方法、特に、自社ドメインの設定方法を見ていきます。\\n自分の名前が出ても大丈夫な場合は、\\nName を ON\\n にするだけでもOKです。\\nただ、Website （独自ドメイン）を登録することで、信頼性が高まるのと、ここからの集客なども見込めますので設定するのがおすすめです。\\nStep 1. Settings → Builder Profile にいく\\n\\nStep 2. Verify new domain から、ドメインを追加\\nドメインを追加します。この際、https などは必要ありません。\\n\\n\\n入力後に Submit をクリックします。\\n\\nStep 3. TXTレコード用のデータをコピーします\\n\\nStep 4. しばらく待ってから Website を ON に\\n\\nしばらく（５〜30分）ほど待ってから、Website を ON にすれば、完了です。\\nこれで、こんな感じでリンクが作者欄に反映されます：\\n\\n第2章 GPTで出来ることのすべて\\nGPTsは多くの素晴らしい機能を搭載しており、そのポテンシャルは計り知れません。\\n本章は、GPTsに搭載された主要な機能を簡単に紹介し、\\n\\n\\n全体的な理解を深めることが目的です。\\nこれらの機能を適切に組み合わせることで、本当に便利なGPTsになっていきます。\\n各機能の詳細な解説は後続の章で行います。\\nそれぞれ、GPT Builder の Configure 画面からチェックボックスをオンにしたりすることで使えます。GPT-4 Vision については常にオンです。\\n\\npage_id: 6c716e86-cca3-4351-b87e-73d2238dc0c9\\n\\npage_id: 264d4d13-3c50-47d1-b355-6a13c24ba1e2\\n\\npage_id: 7e723dc7-8522-426b-812c-0d08cddce70d\\n\\nupdated at 2022-02-05\\n,\\nこんにちは、高校 2 年生の E869120 です。\\n私は\\n競技プログラミング\\nが趣味で、\\nAtCoder\\n や\\n日本情報オリンピック\\nなどの各種コンテストに出場しております。ちなみに、2020 年 2 月 19 日現在、AtCoder では赤（レッドコーダー）です。\\n今回は、競技プログラミング上達のためのガイドラインを記します。初級編では未経験者が競プロを始めるところからサポートしますので、是非お読みください。\\n【シリーズ】\\nレッドコーダーが教える、競プロ・AtCoder上達のガイドライン【初級編：競プロを始めよう】 ←本記事\\nレッドコーダーが教える、競プロ・AtCoder上達のガイドライン【中級編：目指せ水色コーダー！】\\n\\nレッドコーダーが教える、競プロ・AtCoder上達のガイドライン【上級編：目指せレッドコーダー！】\\n \\n\\n0. はじめに\\n皆さん、競技プログラミング (競プロ) をご存知でしょうか。\\n近年、競プロの存在感が日に日に高まってきており、最近では IT 業界・大学生・中高生の間でも広まっています。\\nその中でも特に、\\nAtCoder 株式会社\\n1\\n の存在感が高まっています。AtCoder は日本発の\\nプログラミングコンテスト\\n運営会社として 2012 年 6 月に設立されて以来、年々活動の幅を広げていきました。2017 年 9 月時点での参加者数は \\n37,000 人\\nでしたが、2020 年 6 月時点では \\n206,000 人\\nと、約 3 年の間に 6 倍になるなど、最近急上昇中の会社です。\\n\\n最近では、\\nAtCoderJobs\\n といわれる、AtCoder でのコンテスト成績で就職が有利になるサービスも話題になっており、競プロの実力を上げることが直接就職に役立つようになっています。\\nしかしながら、\\n「競プロでどうやって上達すれば良いのかわからない」\\nと思い悩んでいる方はとても多いと思います。その悩みも、実力帯ごとに異なり、\\n最初に何をやれば良いのか悩んでいる競プロ未経験者もいる\\n競プロ成績上位に食い込むためには何をやれば良いのか悩んでいる人もいる\\n部活や社内などで、どういう競プロの教え方をすれば良いのか悩んでいる人もいる\\nと思います。\\n\\npage_id: 7e723dc7-8522-426b-812c-0d08cddce70d\\n\\nその悩みも、実力帯ごとに異なり、\\n最初に何をやれば良いのか悩んでいる競プロ未経験者もいる\\n競プロ成績上位に食い込むためには何をやれば良いのか悩んでいる人もいる\\n部活や社内などで、どういう競プロの教え方をすれば良いのか悩んでいる人もいる\\nと思います。そこで本記事では、\\n競技プログラミングで実力を上げるにはどういうことを学べば良いのか、どういう練習をすれば良いのかのガイドラインをレベル別に示し、上達に役立ててもらう\\nことを最大の目標にします！\\n\\n競プロをはじめて知ったという方へ\\n(2020.2.28 追記)\\n本記事で「競技プログラミング」を初めて知ったという方もいると思います。初級編では、\\n「競技プログラミング」がどういうものなのか。\\n学習していくことによって、どういうメリットがあるのか。\\nどのようにして競技プログラミングを始められるのか\\nから紹介しておりますので、ご安心ください。本教材では、仮にプログラミング未経験者であっても、競技プログラミングが始められるよう、サポートしております。\\nアルゴリズム本を出版！（2021/12/25）\\n(2022.2.5 追記)\\n私は競技プログラミングで必要なアルゴリズムや数学に関する記事を、これまで Qiita に執筆してきました。それらのトピックをまとめた書籍を出版しましたので、ぜひ読んでみてください。\\nAmazon｜「アルゴリズム×数学」が基礎からしっかり身につく本\\nまた、「アルゴリズム×数学」の本の演習を AtCoder で進める目的でこの記事を見たという方もいると思います。この場合は本記事の「\\n1-3. 早速競プロを始めてみよう\\n」に AtCoder への登録方法などが記されていますので、こちらをご覧ください。\\n\\n目次\\n初級編\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n中級編\\n\\n\\n\\n\\n\\n\\n\\n上級編\\n\\npage_id: 7e723dc7-8522-426b-812c-0d08cddce70d\\n\\nそれらのトピックをまとめた書籍を出版しましたので、ぜひ読んでみてください。\\nAmazon｜「アルゴリズム×数学」が基礎からしっかり身につく本\\nまた、「アルゴリズム×数学」の本の演習を AtCoder で進める目的でこの記事を見たという方もいると思います。この場合は本記事の「\\n1-3. 早速競プロを始めてみよう\\n」に AtCoder への登録方法などが記されていますので、こちらをご覧ください。\\n\\n目次\\n初級編\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n中級編\\n\\n\\n\\n\\n\\n\\n\\n上級編\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n1-1. 競プロとは何か\\n競プロとは、以下のようなものです。\\n\\t競技プログラミングでは、参加者全員に同一の課題が出題され、より早く与えられた要求を満足するプログラムを正確に記述することを競う。 (Wikipedia より引用)\\nつまり、プログラミングで解ける問題が何問か出されて、それぞれの問題について「この問題を解いたら何点獲得できるか」というものが決まっていて、2 時間などといった制限時間内でできるだけ多くの得点を獲得することが目的の競技です。（どんな問題が出されるかについては\\n後述\\n。以下の画像はコンテストの例です。）\\n競プロの特徴：自動採点\\n競技プログラミングの最大の特徴の一つとして、「ソースコードを出したらすぐに採点される」ということが挙げられます。つまり、ソースコードをコンテストサイトに提出すると、\\n通常 1 分以内に正解か不正解かわかります。\\nこれが競技プログラミングの面白さの一つで、正誤がすぐにわかるだけでなく、リアルタイムで順位表が更新されます。これがとても楽しいのです。\\nどんな問題が出されるか（１）\\nさて、競技プログラミングではどのような問題が出されるのでしょうか。まずは簡単な例から紹介します。\\n\\t整数 A と B が与えられます。\\n\\tそのとき、縦 A センチ、横 B センチの長方形の周の長さを整数で出力してください。\\n\\tテストデータの制約：1≤A,B≤100\\nこのような問題について、作問者側が用意した\\n全てのテストデータ\\n（ここでは (A,B) の組）に対して正解するようなコードを書けば正解です。以下の例のように、1 ケースでも間違った出力をした場合、この提出は\\n不正解\\nとなります。\\n\\npage_id: 7e723dc7-8522-426b-812c-0d08cddce70d\\n\\nこのように、競技プログラミングは\\nコーディングの正確性\\nが問われるコンテストです。\\nどんな問題が出されるか（２）\\n競プロは正確性だけではありません。例えば、以下の問題を考えてみてください。\\n\\tN 枚のカードが一列に並べられています。\\n\\t左から i 番目のカードには、整数 Ai が書かれています。\\n\\tあなたは N 枚のカードの中から 2 枚同時に選び、取ることができます。取った 2 枚に書かれた整数の合計がちょうど 101 となるような、カードの選び方の通り数を求めてください。\\n\\tテストデータの制約：1≤N≤106,1≤Ai≤109\\n一番最初に考えられる解法は、以下のように「何枚目と何枚目を選ぶか全探索する」という方法だと思います。つまり、1≤i<j≤N を満たすすべての (i,j) の組を全探索し、Ai+Aj=101 となる通り数を数え上げるという方法です。\\nしかし、その解法の場合、N2 回程度のループを回す必要があります。 N≤106 なので、最大 1012 回程度のループを回す必要があります。しかし、競技プログラミングにおいて、およそ 108 ～ 109 回を超える回数のループをした場合、\\n実行時間超過 (TLE)\\n となり、1 ケースでも TLE を起こすと不正解となってしまいます。\\n2\\nそのため、より効率的なアルゴリズムを実装することが求められます。例えば、本問題であれば、以下のような解法を使うと、高々 N 回程度のループでプログラムの実行が終わります。\\nAi≥101 のカードはすべて無視する。\\nAi=1,Ai=2,...,Ai=100 のカードの枚数を数える。それぞれ c1,c2,...,c100 とする。\\nそのとき、(c1×c100)+(c2×c99)+(c3×c98)+...+(c50×c51) が答えである。\\n一応、C++ での実装例を載せておきます。\\n※ 必ず読まなくても、本記事を読める構成になっております。 (2/20 01:28 AM.\\n\\npage_id: 7e723dc7-8522-426b-812c-0d08cddce70d\\n\\n一部修正しました)\\n#include <iostream>\\n#include <cstdio>\\nusing namespace std;\\n\\nlong long N, A[1000009];\\nlong long cnt[109];\\n\\nint main() {\\n    scanf(\"%lld\", &N);\\n    for (int i = 1; i <= N; i++) {\\n        scanf(\"%lld\", &A[i]);\\n        if (A[i] <= 100) cnt[A[i]]++;\\n    }\\n\\n    long long Answer = 0;\\n    for (int i = 1; i <= 50; i++) Answer += cnt[i] * cnt[101 - i];\\n    cout << Answer << endl;\\n    return 0;\\n}\\n\\nこのように、コーディングの正確性だけでなく、\\n現実的な実行時間に間に合わせるようなプログラムの書き方（アルゴリズム）を考える\\nというのが、競技プログラミングの本質です。競プロの世界は広く、今回説明した問題はまだ簡単な方です。競プロには、もっと解法が難しい問題はたくさんあります。\\n3\\n1-2. 競プロの 6 つの面白さ\\n競技プログラミングについて知っていただいたところで、競プロが如何に面白いかを紹介します。競プロというのは、実はとてつもなく学びがいがあり、とてつもなく広く、とてつもなく面白いことなのです。\\n1-2-1. プログラミングスキルが向上する！\\n競技プログラミングでは、当然プログラムを早く正確に書くことが求められます。競プロをやると、コンテストに出たり過去問を解いたりすることで沢山のコードを書くので、コーディングに慣れ、スキルアップに直接繋がります。\\n実際に、競技プログラマーは、とてつもなく速くコーディングする能力を持っています。例えば、\\n1-1. 節で紹介した 2 つ目の問題\\nを解くプログラムを 2 分程度で書ける人も多いです。\\nまた、後で紹介しますが、競プロでは C++ という言語がメジャーです。そのため、C++ 未経験の人にとっては、C++ というプログラミング言語を新たに学習する良い機会にもなるのです。（もちろん C++ 以外の言語で参加しても構いません）\\n1-2-2. アルゴリズムが学べる！\\n先程述べたように、競技プログラミングでは\\n「ただコードを速く正確に書く能力」 だけでなく、\\n「実行時間に間に合うような、効率的に動くプログラムを書く」\\n能力も求められます。そこで、様々な\\nアルゴリズム\\nを学習すると、効率的に動くプログラムが書きやすくなります。競技プログラミングは、アルゴリズムを学習・復習・学び直しする良い機会にもなるのです。\\n1-2-3.\\n\\npage_id: 7e723dc7-8522-426b-812c-0d08cddce70d\\n\\n数学的考察力が向上する！\\n一般に、AtCoder の問題をたくさん解いていくと、数学的考察力・論理的考察力が向上します。つまり数理パズルのような問題を簡単に解けるようになるのです。(2/20 00:57 AM 表記を一部修正)\\nでは何故 \\nAtCoder\\n などのコーディングコンテストで、数学的考察力が磨けるのでしょうか？ この答えは競プロで出題されている問題にあります。競プロでは、\\nアルゴリズムによって計算回数を少なくできる問題 だけでなく、\\n数学的考察によって計算回数を少なくできる問題\\nも多く出題されるからです。\\n1-2-4. リアルタイムで戦える！\\n先程述べたように、競技プログラミングでは\\n自動採点\\nのシステムが使われているため、順位表が\\nリアルタイム\\nで更新されます。その間、例えば \\nAtCoder\\n という日本最大手のコンテストサイトの場合、世界の\\n10000人以上\\n4\\nの参加者が同時に戦っています。\\nですので、コーディングを高められるだけでなく、ネットゲーム（あるいは競技）としても十分楽しめるのです。\\n1-2-5. コミュニティーが優しい！\\n競プロが楽しい理由として、競プロコミュニティー（競プロ界隈）の優しさがあります。\\n例えば、初心者が \\nTwitter\\n で競プロのわからないことをツイートしたら、上級者が親切に答えを返してくれることも多いです。\\n5\\n また、競プロをやっている人は、競プロ初学者に厳しく接することがほぼありません。そのため、楽しみながら上達することができます。\\n1-2-6. 就職に役立つ！\\n競技プログラミングは、前述したとおり、ネットゲーム感覚で楽しめるコンテスト（あるいは趣味）です。一方で、実は就職にも役立つことがあるのです。\\n日本最大手の競プロコンテストを開催する AtCoder では、コンテストに参加すると成績に応じて\\nレーティング\\nが付くのですが、そのレーティングが一定以上あれば、様々な会社の求人に応募できるというサービスがあります。\\nAtCoderJobs (jobs.atcoder.jp)\\nです。求人は年収が高いものが多く、競技プログラミングの能力で高い給料のエンジニア職に就ける、といったケースも多いです。\\n1-3.\\n\\npage_id: 7e723dc7-8522-426b-812c-0d08cddce70d\\n\\n早速競プロを始めてみよう\\n競プロの楽しさ、面白さはわかりましたでしょうか？\\n皆さんも、早速今日から競技プログラミングを始めてみましょう。本節では、どのようにして競プロを始めればよいのかを分かりやすく解説します。\\n\\npage_id: d855efb8-53d2-481d-ac8a-962ee80411a9\\n\\nWe recruit annotators to search for relevant information using our interface and then answer questions.\\nInformation Retrieval  \\n \\n   Long Form Question Answering  \\n \\n  \\n+1\\n\\nPaper \\n\\nCode\\n\\nShap-E: Generating Conditional 3D Implicit Functions\\n\\n openai/shap-e \\n  •   • 3 May 2023\\nWe present Shap-E, a conditional generative model for 3D assets.\\n8,440\\nPaper \\n\\nCode\\n\\nHuaTuo: Tuning LLaMA Model with Chinese Medical Knowledge\\n\\n scir-hi/huatuo-llama-med-chinese \\n  •   • 14 Apr 2023\\nLarge Language Models (LLMs), such as the LLaMA model, have demonstrated their effectiveness in various general-domain natural language processing (NLP) tasks.\\n\\npage_id: e09c8b24-84bc-49d7-86b8-6774513bac70\\n\\npage_id: 9bba3af0-10ce-4dbd-8414-2ceebd4cce37\\n\\nDL SEMINARS\\n\\n\\n\\nDeep Learning技術は、他の分野では例を見ないスピードで世界的に研究が進められています。\\nこのような状況の下、DL Seminarsは、最先端の研究動向の調査を目的とし、論文の輪読会を毎週開催しております。\\nDL Papers 2023\\nDL Papers 2022\\nDL Papers 2021\\nDL Papers 2020\\nDL Papers 2019\\nDL Papers 2018\\nDL Papers 2017\\nDL Papers 2016\\nDL Papers 2015\\nReadings\\nInfo\\nLinks\\nREADINGs\\nDL Seminersでは、機械学習・深層学習の名著の輪読会を行なっております。こちらのページでは、輪読会のスライドを公開しています。\\nDeep Learning\\nIan Goodfellow, Yoshua Bengio, Aaron Courville\\n\\n\\n\\n\\n\\n\\n\\n\\nPRML\\n, Pattern Recognition and Machine Learning\\n\\npage_id:\\nQuery: SQLを勉強するのに良い資料は？\\nOriginal Answer: SQLを学ぶための良い資料として、GMOペパボのSQL研修資料が基本から始まり、RDBMSの歴史やデータベース設計に触れているので初心者にも理解しやすいです。また、Business Insiderやダイヤモンド・シグナルもSQLを含むテクノロジー系の情報を提供しているので、参考になるでしょう。\\nNew Answer: '}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.1}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 01 Aug 2024 16:35:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-01p8otbt5gis2mt84rnzemio'), (b'openai-processing-ms', b'2831'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9996'), (b'x-ratelimit-remaining-tokens', b'181583'), (b'x-ratelimit-reset-requests', b'29.741s'), (b'x-ratelimit-reset-tokens', b'5.524s'), (b'x-request-id', b'req_7cd2b9ff170f49aaf346bdd03f314c58'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ac73db1281b688c-NRT'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Thu, 01 Aug 2024 16:35:25 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-01p8otbt5gis2mt84rnzemio', 'openai-processing-ms': '2831', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9996', 'x-ratelimit-remaining-tokens': '181583', 'x-ratelimit-reset-requests': '29.741s', 'x-ratelimit-reset-tokens': '5.524s', 'x-request-id': 'req_7cd2b9ff170f49aaf346bdd03f314c58', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ac73db1281b688c-NRT', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_7cd2b9ff170f49aaf346bdd03f314c58\n",
      "DEBUG:llama_index.core.response_synthesizers.refine:> Refine context: 7e723dc7-8522-426b-812c-0d08cddce70d\n",
      "\n",
      "数学的考察力が向上...\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are an expert Q&A system that strictly operates in two modes when refining existing answers:\\n1. **Rewrite** an original answer using the new context.\\n2. **Repeat** the original answer if the new context isn\\'t useful.\\nNever reference the original answer or context directly in your answer.\\nWhen in doubt, just repeat the original answer.\\nNew Context: 7e723dc7-8522-426b-812c-0d08cddce70d\\n\\n数学的考察力が向上する！\\n一般に、AtCoder の問題をたくさん解いていくと、数学的考察力・論理的考察力が向上します。つまり数理パズルのような問題を簡単に解けるようになるのです。(2/20 00:57 AM 表記を一部修正)\\nでは何故 \\nAtCoder\\n などのコーディングコンテストで、数学的考察力が磨けるのでしょうか？ この答えは競プロで出題されている問題にあります。競プロでは、\\nアルゴリズムによって計算回数を少なくできる問題 だけでなく、\\n数学的考察によって計算回数を少なくできる問題\\nも多く出題されるからです。\\n1-2-4. リアルタイムで戦える！\\n先程述べたように、競技プログラミングでは\\n自動採点\\nのシステムが使われているため、順位表が\\nリアルタイム\\nで更新されます。その間、例えば \\nAtCoder\\n という日本最大手のコンテストサイトの場合、世界の\\n10000人以上\\n4\\nの参加者が同時に戦っています。\\nですので、コーディングを高められるだけでなく、ネットゲーム（あるいは競技）としても十分楽しめるのです。\\n1-2-5. コミュニティーが優しい！\\n競プロが楽しい理由として、競プロコミュニティー（競プロ界隈）の優しさがあります。\\n例えば、初心者が \\nTwitter\\n で競プロのわからないことをツイートしたら、上級者が親切に答えを返してくれることも多いです。\\n5\\n また、競プロをやっている人は、競プロ初学者に厳しく接することがほぼありません。そのため、楽しみながら上達することができます。\\n1-2-6. 就職に役立つ！\\n競技プログラミングは、前述したとおり、ネットゲーム感覚で楽しめるコンテスト（あるいは趣味）です。一方で、実は就職にも役立つことがあるのです。\\n日本最大手の競プロコンテストを開催する AtCoder では、コンテストに参加すると成績に応じて\\nレーティング\\nが付くのですが、そのレーティングが一定以上あれば、様々な会社の求人に応募できるというサービスがあります。\\nAtCoderJobs (jobs.atcoder.jp)\\nです。求人は年収が高いものが多く、競技プログラミングの能力で高い給料のエンジニア職に就ける、といったケースも多いです。\\n1-3.\\n\\npage_id: 7e723dc7-8522-426b-812c-0d08cddce70d\\n\\n早速競プロを始めてみよう\\n競プロの楽しさ、面白さはわかりましたでしょうか？\\n皆さんも、早速今日から競技プログラミングを始めてみましょう。本節では、どのようにして競プロを始めればよいのかを分かりやすく解説します。\\n\\npage_id: d855efb8-53d2-481d-ac8a-962ee80411a9\\n\\nWe recruit annotators to search for relevant information using our interface and then answer questions.\\nInformation Retrieval  \\n \\n   Long Form Question Answering  \\n \\n  \\n+1\\n\\nPaper \\n\\nCode\\n\\nShap-E: Generating Conditional 3D Implicit Functions\\n\\n openai/shap-e \\n  •   • 3 May 2023\\nWe present Shap-E, a conditional generative model for 3D assets.\\n8,440\\nPaper \\n\\nCode\\n\\nHuaTuo: Tuning LLaMA Model with Chinese Medical Knowledge\\n\\n scir-hi/huatuo-llama-med-chinese \\n  •   • 14 Apr 2023\\nLarge Language Models (LLMs), such as the LLaMA model, have demonstrated their effectiveness in various general-domain natural language processing (NLP) tasks.\\n\\npage_id: e09c8b24-84bc-49d7-86b8-6774513bac70\\n\\npage_id: 9bba3af0-10ce-4dbd-8414-2ceebd4cce37\\n\\nDL SEMINARS\\n\\n\\n\\nDeep Learning技術は、他の分野では例を見ないスピードで世界的に研究が進められています。\\nこのような状況の下、DL Seminarsは、最先端の研究動向の調査を目的とし、論文の輪読会を毎週開催しております。\\nDL Papers 2023\\nDL Papers 2022\\nDL Papers 2021\\nDL Papers 2020\\nDL Papers 2019\\nDL Papers 2018\\nDL Papers 2017\\nDL Papers 2016\\nDL Papers 2015\\nReadings\\nInfo\\nLinks\\nREADINGs\\nDL Seminersでは、機械学習・深層学習の名著の輪読会を行なっております。こちらのページでは、輪読会のスライドを公開しています。\\nDeep Learning\\nIan Goodfellow, Yoshua Bengio, Aaron Courville\\n\\n\\n\\n\\n\\n\\n\\n\\nPRML\\n, Pattern Recognition and Machine Learning\\n\\npage_id: ed4bf90f-7dfc-4f90-83ef-fd3a3a044a88\\n\\nはじめに\\n早速ですが、皆さんは投資をしているでしょうか。しているとすれば、どのような投資をしていらっしゃるでしょうか。\\n世の中には様々な投資対象が存在し、またその投資手法も様々です。投資に関する情報は世の中に溢れています。氾濫していると言ったほうがよいかもしれません。書籍を例に取ると、甘い文句で投資を奨励するライトな入門書から金融の専門書までずらりと並びます。またブログやSNSも重要な情報源となっており、最近では投資向けのYouTubeも人気を集めているようです。\\nしかしこれだけ多様な情報ソースが存在するにも関わらず、投資で成功を収めることができるのはごく一握りです。少し古いリサーチになりますが2015年の野村證券の個人投資家リサーチでは、通算で利益が出ている個人投資家の割合は9.3%とのことです。どうしてこのような事態に陥ってしまうのでしょうか。投資の初級者の方はどのようなアプローチをしているのか、いくつか例を挙げてみましょう。\\n流行りのテーマ株の高騰に飛びついて高値掴みをしてしまう\\nバフェットの真似をして四季報から割安成長株を選んでみる\\n聞きかじった知識を元にPERやROEで銘柄をスクリーニングしてみる\\n配当狙いで銘柄を保有してみる\\n雑誌のアナリストが推していた銘柄を購入してみる\\n企業決算や経済指標の発表に合わせて取引してみる\\n流行りのESG企業を買ってみる\\nテクニカルを使ってチャートから上昇するか下落するか予想してみる\\nこのような手法を鵜呑みにトレードしてしまい、勤労時間の昼休みが来るたびに含み損を見て落胆している方もいるのではないでしょうか。もう一度言いますが、なぜこのような事態に陥ってしまうのでしょうか。それは、\\nそもそも初級者の方はどのようなトレーディングスタイルが本質的に優位であるか知らないからです\\n。\\n本記事の目的\\n本記事では兎にも角にも、初級者の方が持つ投資観に対して全く新しい気付きを与えることを念頭に置きました。トレーディングは科学です。科学的なトレーディングとは、すなわち計量的・実証的なトレーディングのことです。\\n本記事では統計的な考えに基づき、どのようなトレーディングスタイルが優位であるか示します。\\n\\npage_id: ed4bf90f-7dfc-4f90-83ef-fd3a3a044a88\\n\\n本記事の目的\\n本記事では兎にも角にも、初級者の方が持つ投資観に対して全く新しい気付きを与えることを念頭に置きました。トレーディングは科学です。科学的なトレーディングとは、すなわち計量的・実証的なトレーディングのことです。\\n本記事では統計的な考えに基づき、どのようなトレーディングスタイルが優位であるか示します。記事中では、初級者の方が平易に読むことができるようになるべく分かりやすい用語を選び、難しい数式や専門的な考察は可能な限り省略するようにしました。\\nまた、科学的なトレーディングを実行に移すための具体的な手法について手ほどきします。計量的・実証的なトレーディングを行うためにはプログラミングは必須です。本記事ではPythonという言語を用いて必要最低限の検証を行うためのプログラムを記しました。プログラミングと聞いて身構える人も多いでしょうが、この機会に勉強を始めてみるのもよいでしょう。何事も目的意識をもって取り組むことが上達への近道となります。\\n筆者の投資パフォーマンス\\n記事のはじめに、まず筆者のこれまでの投資のパフォーマンスを紹介しておきます。いきなり自分が儲けたカネの話をしていやらしいと思われるでしょうが、結果を出していない人が何を言っても説得力はないのです。なお一言加えておきますが、投資において最も重要なことは結果ではなくプロセス管理です。なぜなら後述するように、投資のパフォーマンスは運に左右される部分が大きく、結果のみに基づいて判断すると間違った結論を招いてしまう場合が多いからです。\\n筆者はもともと本職のエンジニアの傍らで投資をしていましたが、2014年から本格的に資産運用を開始しました。このときのスタートアップ資金は5000万円でした。2016年に現在主力となっている運用システムを開発しました。この運用システムは運用開始から現在までにおよそ1億4000万円を稼ぎ出している我々の旗艦システムです。運用は日本株のTOPIX500と呼ばれる大型銘柄が対象で、直近4年間の平均利回りは40%程度となっています。\\n\\npage_id: ed4bf90f-7dfc-4f90-83ef-fd3a3a044a88\\n\\nこのときのスタートアップ資金は5000万円でした。2016年に現在主力となっている運用システムを開発しました。この運用システムは運用開始から現在までにおよそ1億4000万円を稼ぎ出している我々の旗艦システムです。運用は日本株のTOPIX500と呼ばれる大型銘柄が対象で、直近4年間の平均利回りは40%程度となっています。\\n\\n\\n\\n問題提起\\nでは冒頭に上げた初級者のアプローチではなぜ成功することができないのか、何が問題であるのか解説します。ここでいう成功とは、少なくとも5年以上の投資期間において途中で挫折することなく継続的・安定的に所望の利回りを得ることを指します。\\nまず冒頭の手法によって利益が出るのか出ないのか考えてみましょう。一例として割安でクオリティが高いと考えられる銘柄への投資を考えてみます。株の個別銘柄を選定するとき、証券会社のツールを使って銘柄をスクリーニングする方が多いでしょう。ここではPERが10倍以下でROEが10%以上の銘柄に1ヶ月間投資したときのパフォーマンスを見てみましょう。\\n集計期間は2017年4月から2020年10月であり、スクリーニングした銘柄を月初に購入して（正確には前月の終値で購入して）、当月の月末の終値で決済した場合の獲得利益の分布図（ヒストグラム）です。このとき、個別銘柄のリターンからマーケットのリターンを差し引いています。こうしなければ日経平均の急騰などの影響を受けてしまい、その獲得した利益が銘柄選定のスキルに依るものなのか、それとも運よくマーケット上昇の恩恵を受けただけなのか、切り分けできないからです。\\n\\n\\n\\nさて、この投資手法で利益は出るのでしょうか。\\n結論として、利益が出る場合もあれば出ない場合もあります。あなたの投資した銘柄は、上図の分布のうち、最も右端（つまり利益が出た銘柄）かもしれません。はたまた、分布の最も左端（つまり損失が出た銘柄）かもしれません。上図の分布に含まれている銘柄は全てあなたの基準にとって「割安でクオリティが高い」銘柄です。\\n\\npage_id: ed4bf90f-7dfc-4f90-83ef-fd3a3a044a88\\n\\nさて、この投資手法で利益は出るのでしょうか。\\n結論として、利益が出る場合もあれば出ない場合もあります。あなたの投資した銘柄は、上図の分布のうち、最も右端（つまり利益が出た銘柄）かもしれません。はたまた、分布の最も左端（つまり損失が出た銘柄）かもしれません。上図の分布に含まれている銘柄は全てあなたの基準にとって「割安でクオリティが高い」銘柄です。この中から最終的な損益を決定づけるのは「割安でクオリティが高い」という事実ではなく、対象となった数ある銘柄の中からその時期にその銘柄をピックアップした、いわゆるあなたの指運だと言えます。それは例えば、たまたまその企業の名称が気に入ったものであるだとか、たまたまスクリーニングの一番上の段に表示されただとか、雑誌を読んで急に投資を思い立っただとか、そのような些細なことでしょう。\\n投資は、つまりガチャのようなもの\\n投資の結果は運に左右されます。というよりも殆どが運で決まるのです。ここでいう運とはすなわち上図のような確率分布のことを指します。上記の事例から分かるように投資の結果だけに着目すると、その投資そのものが上手くいったかどうかという判定は決してできないのです。あなたの行ったトレードの結果はご自身のスキルに依るものなのか偶然の産物なのか全く区別は付きません。\\nこのように結果を正しく判断できないということは、その手法に依存してよいかどうかは分からないということです。つまりビジネスでいうところの改善のプロセスを回すことはできません。冒頭のようなアプローチでは、改善プロセスを回すという考え方が抜けているのです。改善プロセスを回すためには、定量的な結果を短期間でフィードバックさせる仕組みが必要となるのです。\\nもしも改善プロセスを回せないのであれば、あなたの投資スキルは未来永劫、決して向上することはないのです。これは中身の分からないガチャをひたすら回しているのと同じことです。あなたは年に数回ほど上記の排出分布の中から数個のガチャを引いて、その結果が良ければ歓喜し悪ければ落胆するという不毛な行為を繰り返しているにすぎないのです。\\n解決手段\\nではこのガチャを攻略する方法はあるのでしょうか。当然、答えは「YES」です。\\n\\npage_id: ed4bf90f-7dfc-4f90-83ef-fd3a3a044a88\\n\\nこれは中身の分からないガチャをひたすら回しているのと同じことです。あなたは年に数回ほど上記の排出分布の中から数個のガチャを引いて、その結果が良ければ歓喜し悪ければ落胆するという不毛な行為を繰り返しているにすぎないのです。\\n解決手段\\nではこのガチャを攻略する方法はあるのでしょうか。当然、答えは「YES」です。\\nガチャ台の素性\\nガチャ台にも良いもの悪いものがあります。中身に当たりがたくさん入っている台は良い台、クズのようなものしか入っていない台は悪い台です。これらの台を排出分布で見てみるとどのようになっているのでしょうか。以下に3つの例を示します。\\n\\n\\n\\nまず一番左の台はどうでしょうか。この台の排出分布の中心は殆ど0となっています。すわなちこの台の期待値は0です。この台でいくらガチャを引いてもあなたの資産が伸びることはないでしょう。一時的に利益が出ても、それは偶然パフォーマンスが上振れしているだけのことです。長い目でみると獲得した損益の平均値は必ず0に近づきます。\\n続いて真ん中の台はどうでしょう。この台の排出分布をよく見てみると、わずかに右側（プラス側）にシフトしていることが分かります。これは「期待値がプラス」である状態です。トレードでは、「エッジがある」「アルファ（期待超過収益）がある」などという表現をします。この台は、ガチャを引き続けていくことで右肩上がりに資産を伸ばすことができます。しかし道中の資産の上下変動は激しく、もしかするとあなたは途中でやめてしまうかもしれません。\\n最後に一番右の台です。この台の排出分布は真ん中の台と同じようにわずかに右側にシフトしています。そしてさらに目を凝らして見てみると、そのバラツキ（中心からの広がり）が真ん中の台と比べて小さな範囲に収まっていることが分かります。期待値がプラスで且つバラツキが小さい、すなわち「シャープレシオ」の高い台です。このようなガチャ台を見つけることができ、さらにそれを引き続けていくことであなたの成功は盤石なものとなるでしょう。\\nとにかく何回もガチャを回し続ける\\nガチャを1回か2回引いた程度では、ガチャ台の中身がどのようなものなのか傾向を掴むことはできません。\\n\\npage_id: ed4bf90f-7dfc-4f90-83ef-fd3a3a044a88\\n\\n期待値がプラスで且つバラツキが小さい、すなわち「シャープレシオ」の高い台です。このようなガチャ台を見つけることができ、さらにそれを引き続けていくことであなたの成功は盤石なものとなるでしょう。\\nとにかく何回もガチャを回し続ける\\nガチャを1回か2回引いた程度では、ガチャ台の中身がどのようなものなのか傾向を掴むことはできません。従ってもしも本当に中身の傾向を掴みたいのであれば、とにかく何回も何回も回し続けるしかありません。ここで重要なことは、わき目をふらず1つのガチャだけを回し続けるということです。途中まで引いて、こっちのガチャはあまり当たりが入ってなさそうだからこっちのガチャに替えてみる、というやり方では一生かかっても傾向を掴むことはできません。\\nつまりトレードでは、1つの手法だけに基づいて一貫してトレードを継続しなければならないのです。それも10回や100回そこらでは足りません。1000回を超えるような多数回施行をしなければならないのです。雑誌などの投資手法に次から次へと目移りしてはいけないのです。投資の持つ不確実性と戦うためには、とにかく試行回数を稼ぐしかありません。我々が持つ唯一の武器は大数の法則なのです。\\n従って、\\n優位なトレーディング戦略とは「数をこなせる」戦略\\nとなります。個人投資家が行うトレードに月次以上のスパンのものは不適です。少なくともトレーディングは毎日行う必要があります。その最たるものはスキャルピングでしょう。また、トレーディングの期間が短くなればなるほど、価格の動きの不確実性は少なくなりその傾向を掴みやすくなるのです（具体的には投資の不確実性は投資期間の平方根に比例します）。\\nガチャを引き続けるとお金がなくなっていく\\nしかし、当然の話ですがガチャを引くためにはお金が必要です。引けば引くだけあなたの財布からお金は消えていきます。これはトレードでも同じことです。トレードでは1回の取引に必ずコストが掛かります。株式であれば銘柄購入の際の手数料や信用金利、FXであれば1回のトレードでスプレッドを業者に支払っていることになります。何回もトレードを繰り返すとあっという間にあなたの資金は尽きてしまうでしょう。\\n\\npage_id: ed4bf90f-7dfc-4f90-83ef-fd3a3a044a88\\n\\n引けば引くだけあなたの財布からお金は消えていきます。これはトレードでも同じことです。トレードでは1回の取引に必ずコストが掛かります。株式であれば銘柄購入の際の手数料や信用金利、FXであれば1回のトレードでスプレッドを業者に支払っていることになります。何回もトレードを繰り返すとあっという間にあなたの資金は尽きてしまうでしょう。\\n実弾投入しながらガチャの中身の傾向を推定するのは、正直全く割りに合わない行為です。そんなことをするよりも、予め割の良いガチャ台に当たりを付ける方法があります。\\nデータから予めガチャ台の中身を推定する\\n投資の世界では、我々は予めガチャ台に使われているデータの一部を集めることができます。そしてこのデータを使ってどのようなガチャ台の素性が良いのか、すなわちどのようなトレーディング戦略にベットすべきか、ガチャを引く前に検証することができます。これが計量的・実証的と呼ばれるトレーディング手法です。取引コストに打ち勝つことのできる期待値をデータ分析によって探すのです。\\n計量的・実証的なトレーディングに関する研究は長年行われています。特に最近では、これに機械学習を用いる事例も多数見掛けるようになりました。機械学習はデータの持つ統計的な有意性を確認できるだけではなく、誰も知らないような隠れた市場特性を抽出するためにも非常に有用です。プログラミングのライブラリは充実しており、データをダウンロードするためのAPIも整備されつつあります。個人投資家にも充分なデータ分析はできるのです。\\nそして運用へ\\n実際の運用では検証結果に基づいて可能な限り条件を固定して機械的にトレードを行わなければなりません。そこに人間の感情を挟んではいけないのです。そしてどうせ機械的に多数回のトレードを繰り返すのであれば、これを自動化しない理由はありません。このようなトレーディングスタイルは、包括的に「システムトレーディング」とも呼ばれています。\\n実際には、事前の検証（すなわちバックテスト）と実際の運用のパフォーマンスを比較しながら改善のプロセスを回すことが成功する投資のアプローチとなるのです。データ分析などしたことがないという人のために、以降の章ではPythonを使ったデータ分析の方法について紹介します。\\n\\npage_id: ed4bf90f-7dfc-4f90-83ef-fd3a3a044a88\\n\\nこのようなトレーディングスタイルは、包括的に「システムトレーディング」とも呼ばれています。\\n実際には、事前の検証（すなわちバックテスト）と実際の運用のパフォーマンスを比較しながら改善のプロセスを回すことが成功する投資のアプローチとなるのです。データ分析などしたことがないという人のために、以降の章ではPythonを使ったデータ分析の方法について紹介します。\\n計量的・実証的トレーディングの準備\\nさて、それではまずデータを集めます。データはYahoo FinanceのAPIを使って集めます。このときyfinanceというライブラリを使用しますので、まずこれをインストールします。yfinanceの詳細は\\nこちら\\nをご参照下さい。\\n（追記）yfinanceのバグについて\\n\\n\\nyfinanceにはバグがあり、デフォルトのままでは財務諸表データを取得できません。以下のようにyfinanceのbase.pyファイルを修正することで取得できるようになります。\\n# base.py 353行目付近\\n# get fundamentals\\n# data = utils.get_json(url+\\'/financials\\', proxy)    ←デフォルトプログラム。マスクします。\\nurl = \"{}/{}/financials\".format(self._scrape_url, self.ticker)   # 追加\\ndata = utils.get_json(url, proxy)                                # 追加\\n価格のヒストリカルデータ\\nでは、まず日本の株式市場の銘柄について、価格データをダウンロードしてみましょう。\\n以下のコードを実行すると、一瞬で7203トヨタ自動車のヒストリカルデータを取得することができます。日本市場の銘柄のtickerシンボルは、証券コード+\".T\"で表されるため、特にYahoo Financeのシンボルを調べなくとも簡単にほぼ全ての銘柄のデータを取得することができます。\\nimport yfinance as yf\\nticker = yf.Ticker(\"7203.T\")\\nhist = ticker.history(period=\"max\")\\nprint(hist)\\n＜実行画面＞\\n               Open     High      Low    Close    Volume  Dividends  Stock Splits\\nDate\\n1999-05-06  2259.74  2337.44  2233.84  2337.44   3115000        0.0             0\\n1999-05-07  2324.49  2330.96  2233.84  2253.27   3033000        0.0             0\\n1999-05-10  2253.27  2279.16  2233.84  2246.79   1261000        0.0             0\\n1999-05-11  2266.22  2279.17  2227.37  2227.37   1686000        0.0             0\\n1999-05-12  2227.37  2266.21  2227.37  2266.21   2596000        0.0             0\\n.             .      .      .      .       .        .           .\\n2020-11-02  6866.00  7016.00  6850.00  6949.00   5721200        0.\\n\\npage_id: ed4bf90f-7dfc-4f90-83ef-fd3a3a044a88\\n\\n0             0\\n1999-05-10  2253.27  2279.16  2233.84  2246.79   1261000        0.0             0\\n1999-05-11  2266.22  2279.17  2227.37  2227.37   1686000        0.0             0\\n1999-05-12  2227.37  2266.21  2227.37  2266.21   2596000        0.0             0\\n.             .      .      .      .       .        .           .\\n2020-11-02  6866.00  7016.00  6850.00  6949.00   5721200        0.0             0\\n2020-11-04  7024.00  7054.00  6976.00  6976.00   6278100        0.0             0\\n2020-11-05  6955.00  7032.00  6923.00  6984.00   5643400        0.0             0\\n2020-11-06  7070.00  7152.00  7015.00  7019.00  11092900        0.0             0\\n2020-11-09  7159.00  7242.00  7119.00  7173.00   7838600        0.0             0\\n[5324 rows x 7 columns]\\n損益計算書\\n続いて財務諸表のデータを見てみましょう。まずは損益計算書からです。\\n以下のコードから直近およそ3年分の損益計算書を取得できます。この中で特に重要なのは、Total Revenue(売上高)、Operating Income(営業利益)、Net Income(当期純利益)でしょうか。\\nfinancials = ticker.financials\\nprint(financials)\\n＜実行画面＞\\n                                         2020-03-31   2019-03-31   2018-03-31   2017-03-31\\nResearch Development                           None         None         None         None\\nEffect Of Accounting Charges                   None         None         None         None\\nIncome Before Tax                       2.82576e+12  2.64553e+12  3.09051e+12  2.55588e+12\\nMinority Interest                       6.77064e+11  7.18985e+11   6.9412e+11  6.68264e+11\\nNet Income                              2.07618e+12  1.88287e+12  2.49398e+12  1.83111e+12\\nSelling General Administrative          2.97317e+12   2.9867e+12   3.0905e+12  2.86848e+12\\nGross Profit                            5.40763e+12   5.4439e+12  5.49036e+12  4.86286e+12\\nEbit                                    2.43446e+12   2.4572e+12  2.39986e+12  1.99437e+12\\nOperating Income                        2.43446e+12   2.4572e+12  2.39986e+12  1.99437e+12\\nOther Operating Expenses                       None         None         None         None\\nInterest Expense                        -3.2217e+10  -2.8078e+10  -2.7586e+10  -2.9353e+10\\nExtraordinary Items                            None         None         None         None\\nNon Recurring                                  None         None         None         None\\nOther Items                                    None         None         None         None\\nIncome Tax Expense                       6.8343e+11  6.59944e+11  5.04406e+11    6.\\n\\npage_id: ed4bf90f-7dfc-4f90-83ef-fd3a3a044a88\\n\\n43446e+12   2.4572e+12  2.39986e+12  1.99437e+12\\nOperating Income                        2.43446e+12   2.4572e+12  2.39986e+12  1.99437e+12\\nOther Operating Expenses                       None         None         None         None\\nInterest Expense                        -3.2217e+10  -2.8078e+10  -2.7586e+10  -2.9353e+10\\nExtraordinary Items                            None         None         None         None\\nNon Recurring                                  None         None         None         None\\nOther Items                                    None         None         None         None\\nIncome Tax Expense                       6.8343e+11  6.59944e+11  5.04406e+11    6.289e+11\\nTotal Revenue                             2.993e+13  3.02257e+13  2.93795e+13  2.75972e+13\\nTotal Operating Expenses                2.74955e+13  2.77685e+13  2.69796e+13  2.56028e+13\\nCost Of Revenue                         2.45224e+13  2.47818e+13  2.38892e+13  2.27343e+13\\nTotal Other Income Expense Net          3.91297e+11   1.8833e+11   6.9065e+11  5.61513e+11\\nDiscontinued Operations                        None         None         None         None\\nNet Income From Continuing Ops          2.14233e+12  1.98559e+12  2.58611e+12  1.92698e+1\\n2\\nNet Income Applicable To Common Shares   2.0589e+12  1.86808e+12  2.48169e+12  1.82131e+12\\n貸借対照表（バランスシート）\\n次は貸借対照表です。\\n以下のコードから直近およそ3年分の貸借対照表を取得できます。この中で特に重要なのは、Total Assets(総資産)、Total Liab(総負債)、Total Stockholder Equity(自己資本)でしょうか。\\nbalance_sheet = ticker.balance_sheet\\nprint(balance_sheet)\\n＜実行画面＞\\n                                    2020-03-31    2019-03-31    2018-03-31    2017-03-31\\nCapital Surplus                   4.893340e+11  4.871620e+11  4.875020e+11  4.840130e+11\\nTotal Liab                        3.194275e+13  3.186981e+13  3.087815e+13  3.056711e+13\\nTotal Stockholder Equity          2.006062e+13  1.934815e+13  1.873598e+13  1.751481e+13\\nMinority Interest                 6.770640e+11  7.189850e+11  6.941200e+11  6.682640e+11\\nOther Current Liab                4.102642e+12  4.479344e+12  4.399669e+12  3.979935e+12\\nTotal Assets                      5.268044e+13  5.193695e+13  5.030825e+13  4.875019e+13\\nCommon Stock                      3.970500e+11  3.970500e+11  3.970500e+11  3.970500e+11\\nOther Current Assets              2.469880e+11  1.425310e+11  2.022920e+11  1.235700e+10\\nRetained Earnings                 2.342761e+13  2.198752e+13  1.947346e+13  1.760107e+13\\nOther Liab                        2.\\n\\npage_id: ed4bf90f-7dfc-4f90-83ef-fd3a3a044a88\\n\\n102642e+12  4.479344e+12  4.399669e+12  3.979935e+12\\nTotal Assets                      5.268044e+13  5.193695e+13  5.030825e+13  4.875019e+13\\nCommon Stock                      3.970500e+11  3.970500e+11  3.970500e+11  3.970500e+11\\nOther Current Assets              2.469880e+11  1.425310e+11  2.022920e+11  1.235700e+10\\nRetained Earnings                 2.342761e+13  2.198752e+13  1.947346e+13  1.760107e+13\\nOther Liab                        2.746823e+12  2.887743e+12  2.902003e+12  3.163780e+12\\nTreasury Stock                   -4.253379e+12 -3.523575e+12 -1.622034e+12 -9.673210e+11\\nOther Assets                      8.905140e+11  1.182809e+12  1.067759e+12  1.012639e+12\\nCash                              2.774498e+12  2.790212e+12  2.390524e+12  2.257064e+12\\nTotal Current Liabilities         1.790238e+13  1.822694e+13  1.779689e+13  1.731896e+13\\nDeferred Long Term Asset Charges  3.547850e+11  5.018720e+11  4.941200e+11  5.039850e+11\\nShort Long Term Debt              1.418710e+11  1.560380e+11  1.674550e+11  2.285990e+11\\nOther Stockholder Equity         -1.166273e+12 -9.166500e+11  4.356990e+11  6.409220e+11\\nProperty Plant Equipment          1.087864e+13  1.068549e+13  1.026767e+13  1.019711e+13\\nTotal Current Assets              1.864253e+13  1.887924e+13  1.815266e+13  1.783370e+13\\nLong Term Investments             1.184489e+13  1.090829e+13  1.133854e+13  1.069452e+13\\nNet Tangible Assets               2.006062e+13  1.934815e+13  1.873598e+13  1.751481e+13\\nShort Term Investments            1.477202\\ne+12  2.234892e+12  2.447703e+12  2.522598e+12\\nNet Receivables                   2.659748e+12  2.940890e+12  2.708900e+12  2.552805e+12\\nLong Term Debt                    1.029678e+12  7.655860e+11  5.910860e+11  5.784750e+11\\nInventory                         2.434918e+12  2.656396e+12  2.539789e+12  2.388617e+12\\nAccounts Payable                  2.434180e+12  2.645984e+12  2.586657e+12  2.566382e+12\\nキャッシュフロー計算書\\n財務諸表の最後はキャッシュフロー計算書です。\\n以下のコードから直近およそ3年分のキャッシュフロー計算書を取得できます。\\n\\npage_id: ed4bf90f-7dfc-4f90-83ef-fd3a3a044a88\\n\\n552805e+12\\nLong Term Debt                    1.029678e+12  7.655860e+11  5.910860e+11  5.784750e+11\\nInventory                         2.434918e+12  2.656396e+12  2.539789e+12  2.388617e+12\\nAccounts Payable                  2.434180e+12  2.645984e+12  2.586657e+12  2.566382e+12\\nキャッシュフロー計算書\\n財務諸表の最後はキャッシュフロー計算書です。\\n以下のコードから直近およそ3年分のキャッシュフロー計算書を取得できます。この中で特に重要なのは、Total Cashflows From Operating Activities(営業キャッシュフロー)、Total Cashflows From Financing Activities(財務キャッシュフロー)、Total Cashflows From Investing Activities(投資キャッシュフロー)でしょうか。\\ncashflow = ticker.cashflow\\nprint(cashflow)\\n＜実行画面＞\\n                                             2020-03-31    2019-03-31    2018-03-31    2017-03-31\\nInvestments                                2.334300e+11  6.166420e+11 -3.322730e+11  6.950000e+08\\nChange To Liabilities                     -7.641000e+10  9.488700e+10  4.664800e+10  1.459570e+11\\nTotal Cashflows From Investing Activities -3.150861e+12 -2.697241e+12 -3.660092e+12 -2.969939e+12\\nNet Borrowings                             1.558199e+12  7.229710e+11  6.893390e+11  1.030929e+12\\nTotal Cash From Financing Activities       3.971380e+11 -5.408390e+11 -4.491350e+11 -3.751650e+11\\nChange To Operating Activities            -2.703900e+11  4.084000e+11  4.857250e+11  7.724320e+11\\nNet Income                                 2.076183e+12  1.882873e+12  2.493983e+12  1.831109e+12\\nChange In Cash                             7.056750e+11  4.868760e+11  7.031300e+10  2.098980e+11\\nRepurchase Of Stock                       -4.761290e+11 -5.496370e+11 -4.478180e+11 -7.039860e+11\\nEffect Of Exchange Rate                   -1.312450e+11 -4.164100e+10 -4.358800e+10 -1.348600e+10\\nTotal Cash From Operating Activities       3.590643e+12  3.766597e+12  4.223128e+12  3.568488e+12\\nDepreciation                               1.605383e+12  1.792375e+12  1.734033e+12  1.610950e+12\\nDividends Paid                            -6.299870e+11 -6.448060e+11 -6.268920e+11 -6.381720e+11\\nChange To Inventory                       -1.140960e+11 -1.669020e+11 -1.711480e+11 -2.463260e+11\\nChange To Account Receivables              2.488950e+11 -2.468450e+11 -1.054350e+11 -2.647840e+11\\nOther Cashflows From Financing Activities -5.494500e+10 -6.936700e+10 -6.376400e+10 -6.393600e+10\\nChange To Netincome                        2.228170e+11  1.431380e+11 -4.994310e+11 -1.\\n\\npage_id: ed4bf90f-7dfc-4f90-83ef-fd3a3a044a88\\n\\n610950e+12\\nDividends Paid                            -6.299870e+11 -6.448060e+11 -6.268920e+11 -6.381720e+11\\nChange To Inventory                       -1.140960e+11 -1.669020e+11 -1.711480e+11 -2.463260e+11\\nChange To Account Receivables              2.488950e+11 -2.468450e+11 -1.054350e+11 -2.647840e+11\\nOther Cashflows From Financing Activities -5.494500e+10 -6.936700e+10 -6.376400e+10 -6.393600e+10\\nChange To Netincome                        2.228170e+11  1.431380e+11 -4.994310e+11 -1.598180e+11\\nCapital Expenditures                      -3.595131e+12 -3.738887e+12 -3.598707e+12\\nQuery: SQLを勉強するのに良い資料は？\\nOriginal Answer: SQLを学ぶための良い資料として、GMOペパボのSQL研修資料が基本から始まり、RDBMSの歴史やデータベース設計に触れているので初心者にも理解しやすいです。また、Business Insiderやダイヤモンド・シグナルもSQLを含むテクノロジー系の情報を提供しているので、参考になるでしょう。\\nNew Answer: '}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.1}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 01 Aug 2024 16:35:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-01p8otbt5gis2mt84rnzemio'), (b'openai-processing-ms', b'3070'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9995'), (b'x-ratelimit-remaining-tokens', b'179643'), (b'x-ratelimit-reset-requests', b'34.738s'), (b'x-ratelimit-reset-tokens', b'6.107s'), (b'x-request-id', b'req_359386df9e0b211572621c3649d6f467'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ac73dc85900688c-NRT'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Thu, 01 Aug 2024 16:35:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-01p8otbt5gis2mt84rnzemio', 'openai-processing-ms': '3070', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9995', 'x-ratelimit-remaining-tokens': '179643', 'x-ratelimit-reset-requests': '34.738s', 'x-ratelimit-reset-tokens': '6.107s', 'x-request-id': 'req_359386df9e0b211572621c3649d6f467', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ac73dc85900688c-NRT', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_359386df9e0b211572621c3649d6f467\n",
      "DEBUG:llama_index.core.response_synthesizers.refine:> Refine context: 2.586657e+12  2.566382e+12\n",
      "キャッシュフロー計算書\n",
      "財務諸表の最後は...\n",
      "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'user', 'content': 'You are an expert Q&A system that strictly operates in two modes when refining existing answers:\\n1. **Rewrite** an original answer using the new context.\\n2. **Repeat** the original answer if the new context isn\\'t useful.\\nNever reference the original answer or context directly in your answer.\\nWhen in doubt, just repeat the original answer.\\nNew Context: 2.586657e+12  2.566382e+12\\nキャッシュフロー計算書\\n財務諸表の最後はキャッシュフロー計算書です。\\n以下のコードから直近およそ3年分のキャッシュフロー計算書を取得できます。この中で特に重要なのは、Total Cashflows From Operating Activities(営業キャッシュフロー)、Total Cashflows From Financing Activities(財務キャッシュフロー)、Total Cashflows From Investing Activities(投資キャッシュフロー)でしょうか。\\ncashflow = ticker.cashflow\\nprint(cashflow)\\n＜実行画面＞\\n                                             2020-03-31    2019-03-31    2018-03-31    2017-03-31\\nInvestments                                2.334300e+11  6.166420e+11 -3.322730e+11  6.950000e+08\\nChange To Liabilities                     -7.641000e+10  9.488700e+10  4.664800e+10  1.459570e+11\\nTotal Cashflows From Investing Activities -3.150861e+12 -2.697241e+12 -3.660092e+12 -2.969939e+12\\nNet Borrowings                             1.558199e+12  7.229710e+11  6.893390e+11  1.030929e+12\\nTotal Cash From Financing Activities       3.971380e+11 -5.408390e+11 -4.491350e+11 -3.751650e+11\\nChange To Operating Activities            -2.703900e+11  4.084000e+11  4.857250e+11  7.724320e+11\\nNet Income                                 2.076183e+12  1.882873e+12  2.493983e+12  1.831109e+12\\nChange In Cash                             7.056750e+11  4.868760e+11  7.031300e+10  2.098980e+11\\nRepurchase Of Stock                       -4.761290e+11 -5.496370e+11 -4.478180e+11 -7.039860e+11\\nEffect Of Exchange Rate                   -1.312450e+11 -4.164100e+10 -4.358800e+10 -1.348600e+10\\nTotal Cash From Operating Activities       3.590643e+12  3.766597e+12  4.223128e+12  3.568488e+12\\nDepreciation                               1.605383e+12  1.792375e+12  1.734033e+12  1.610950e+12\\nDividends Paid                            -6.299870e+11 -6.448060e+11 -6.268920e+11 -6.381720e+11\\nChange To Inventory                       -1.140960e+11 -1.669020e+11 -1.711480e+11 -2.463260e+11\\nChange To Account Receivables              2.488950e+11 -2.468450e+11 -1.054350e+11 -2.647840e+11\\nOther Cashflows From Financing Activities -5.494500e+10 -6.936700e+10 -6.376400e+10 -6.393600e+10\\nChange To Netincome                        2.228170e+11  1.431380e+11 -4.994310e+11 -1.\\n\\npage_id: ed4bf90f-7dfc-4f90-83ef-fd3a3a044a88\\n\\n610950e+12\\nDividends Paid                            -6.299870e+11 -6.448060e+11 -6.268920e+11 -6.381720e+11\\nChange To Inventory                       -1.140960e+11 -1.669020e+11 -1.711480e+11 -2.463260e+11\\nChange To Account Receivables              2.488950e+11 -2.468450e+11 -1.054350e+11 -2.647840e+11\\nOther Cashflows From Financing Activities -5.494500e+10 -6.936700e+10 -6.376400e+10 -6.393600e+10\\nChange To Netincome                        2.228170e+11  1.431380e+11 -4.994310e+11 -1.598180e+11\\nCapital Expenditures                      -3.595131e+12 -3.738887e+12 -3.598707e+12 -3.541437e+12\\n銘柄のサマリー\\n最後に銘柄のサマリーの入手方法です。\\n以下のコードからその銘柄の基本情報を取得できます。この中で特に重要なのは、marketCap(時価総額)、sharesOutstanding(発行株数)、forwardPE(予測PER)、dividendYield(配当利回り)、profitMargins(純利益比率)など、様々なものがあります。\\ninfo = ticker.info\\nprint(info)\\n＜実行画面＞\\n\\n\\nディクショナリ型のため省略\\n複数銘柄の取得\\n複数銘柄を同時に取得する場合はTickersクラスを使い、引数はスペースで区切ります。\\ntickers = yf.Tickers(\"7203.T 9984.T 6861.T\")\\nhists = []\\nfor i in range(len(tickers.tickers)):\\n    hists.append(tickers.tickers[i].history())\\nprint(hists[0])\\n＜実行画面＞\\n              Open    High     Low   Close    Volume  Dividends  Stock Splits\\nDate\\n2020-10-09  7026.0  7029.0  6947.0  6967.0   3395900          0             0\\n2020-10-12  6932.0  6945.0  6900.0  6911.0   2638200          0             0\\n2020-10-13  6977.0  7030.0  6946.0  7030.0   3667700          0             0\\n2020-10-14  6962.0  6970.0  6919.0  6935.0   3065400          0             0\\n2020-10-15  6898.0  6933.0  6895.0  6915.0   2844800          0             0\\n2020-10-16  6940.0  6944.0  6825.0  6829.0   3770200          0             0\\n2020-10-19  6874.0  6948.0  6870.0  6945.0   3047000          0             0\\n2020-10-20  6926.0  6945.0  6889.0  6897.0   2342400          0             0\\n2020-10-21  6962.0  7052.0  6956.0  7009.0   4795000          0             0\\n2020-10-22  6967.0  6984.0  6941.0  6966.0   3207500          0             0\\n2020-10-23  7009.0  7010.0  6944.\\n\\npage_id: ed4bf90f-7dfc-4f90-83ef-fd3a3a044a88\\n\\n0  6948.0  6870.0  6945.0   3047000          0             0\\n2020-10-20  6926.0  6945.0  6889.0  6897.0   2342400          0             0\\n2020-10-21  6962.0  7052.0  6956.0  7009.0   4795000          0             0\\n2020-10-22  6967.0  6984.0  6941.0  6966.0   3207500          0             0\\n2020-10-23  7009.0  7010.0  6944.0  6973.0   3963300          0             0\\n2020-10-26  6970.0  7003.0  6955.0  6990.0   2675000          0             0\\n2020-10-27  6970.0  6993.0  6924.0  6961.0   3234300          0             0\\n2020-10-28  6888.0  6927.0  6845.0  6895.0   3760200          0             0\\n2020-10-29  6795.0  6924.0  6780.0  6893.0   4099900          0             0\\n2020-10-30  6848.0  6878.0  6803.0  6803.0   5207800          0             0\\n2020-11-02  6866.0  7016.0  6850.0  6949.0   5721200          0             0\\n2020-11-04  7024.0  7054.0  6976.0  6976.0   6278100          0             0\\n2020-11-05  6955.0  7032.0  6923.0  6984.0   5643400          0             0\\n2020-11-06  7070.0  7152.0  7015.0  7019.0  11092900          0             0\\n2020-11-09  7159.0  7242.0  7119.0  7173.0   7838600          0             0\\n株価以外のデータ取得（為替）\\nYahoo Financeに存在するティッカーであれば、株式銘柄でなくともデータを取得することができます。一例として為替のデータを取得してみましょう。\\nimport pandas as pd\\nfxs = [\"JPY=X\", \"EURUSD=X\", \"GBPUSD=X\"]\\ntickers = yf.Tickers(\" \".join(fxs))\\ncloses = []\\nfor i in range(len(tickers.tickers)):\\n    closes.append(tickers.tickers[i].history(period=\"max\").Close)\\ndf = pd.DataFrame(closes).T\\ndf.columns = fxs\\nprint(df)\\n＜実行結果＞\\n              JPY=X  EURUSD=X  GBPUSD=X\\nDate\\n1996-10-30  114.180       NaN       NaN\\n1996-11-01  113.500       NaN       NaN\\n1996-11-04  113.880       NaN       NaN\\n1996-11-05  114.250       NaN       NaN\\n1996-11-06  113.950       NaN       NaN\\n.             .       .       .\\n2020-11-03  104.725    1.1643    1.2924\\n2020-11-04  104.546    1.1762    1.3122\\n2020-11-05  104.438    1.1733    1.2967\\n2020-11-06  103.603    1.\\n\\npage_id: ed4bf90f-7dfc-4f90-83ef-fd3a3a044a88\\n\\n180       NaN       NaN\\n1996-11-01  113.500       NaN       NaN\\n1996-11-04  113.880       NaN       NaN\\n1996-11-05  114.250       NaN       NaN\\n1996-11-06  113.950       NaN       NaN\\n.             .       .       .\\n2020-11-03  104.725    1.1643    1.2924\\n2020-11-04  104.546    1.1762    1.3122\\n2020-11-05  104.438    1.1733    1.2967\\n2020-11-06  103.603    1.1818    1.3139\\n2020-11-09  104.871    1.1910    1.3193\\n[6243 rows x 3 columns]\\n世界の主要株価指数\\n以下、世界の主要株価指数の取得方法です。ここに挙げたもの以外でも取れる指標はあります。ご自身でYahoo Financeで探してみることをお勧めします。\\nindices = [\"^N225\", \"^DJI\", \"^GSPC\", \"^IXIC\", \"^GDAXI\", \"^FTSE\", \"^FCHI\", \"^HSI\", \"^SSEC\", \"^BVSP\", \"^KOSPI\"]\\n# 以下、省略\\n計量的・実証的トレーディングの実行\\n\\npage_id: 271228ae-4f59-4a2d-8539-a4f19c5bef55\\n\\nAmazonシアトル本社でプロダクトマネージャーをしていましたが、2021年8月にスタートアップに転職しました。2013年からアメリカ在住。アメリカ生活の魅力や、アメリカで就職するためのポイント、英語の学習方法などをお伝えできればと思っています。\\n\\n\\n※記事の内容は全て個人の見解であり、所属する組織・部門等を代表するものではありません。\\n【主な講演実績】\\n\\n\\n・2021年4月『純ジャパな僕がAmazonシアトル本社の英語面接を突破するためにやったこと』（キャリアフォーラムLiveSeminar）\\n\\n\\n・2020年10月・11月『シャイな日本人のためのレジュメと英語面接対策』（ボストンキャリアフォーラム）\\n\\n\\n・2019年7月『「海外で働く」という選択』（サンクチュアリ出版）\\n\\n\\n他、大学のゲスト講師など色々と。\\nお仕事のご依頼は「お問い合わせ」フォームにて受け付けております。\\nお勧めカテゴリ\\n\\t就職\\n\\t英語\\n2023年3月26日\\n2023年3月27日\\nChatGPTを活用した究極の英語面接対策\\nChatGPTを使うと、英語面接の対策をこれまでに無いほどお手軽、かつ実践的に行うことができます。ChatGPTを全く使ったことがない人でも分かるように、初めから丁寧に説明しているので、ぜひ活用してみてください！\\n2022年11月12日\\n路頭に迷わないためのレイオフ入門講座\\n最近、TwitterやMetaなど、アメリカの名だたるIT企業が大規模なレイオフを行い、大きな話題になりました。 かく言う僕も、過去に一度だけレイオフに遭ったことがありますし、自分がレイオフされなくても、すぐ隣でレイオフが行われるのを何度も目にしてきました。 そんな経験をもとに、まだレイオフされたことのないラッキーな人たちのために、「レイオフに遭うってこんな感じだよ」「レイオフされたらまずはこれだけはやっておこう」といったことを紹介したいと思います。\\n2021年11月13日\\n2022年2月14日\\n【GAFA米国本社】プロダクトマネージャーとエンジニアの年収比較\\n現在、世界で一番魅力的な職業と言われるプロダクトマネージャー。そのGAFA米国本社での年収を、ジョブレベル別にエンジニアと徹底比較してみました！非エンジニアの方がアメリカ就職を検討する際の参考にしてください！\\n\\npage_id: 271228ae-4f59-4a2d-8539-a4f19c5bef55\\n\\n2021年11月13日\\n2022年2月14日\\n【GAFA米国本社】プロダクトマネージャーとエンジニアの年収比較\\n現在、世界で一番魅力的な職業と言われるプロダクトマネージャー。そのGAFA米国本社での年収を、ジョブレベル別にエンジニアと徹底比較してみました！非エンジニアの方がアメリカ就職を検討する際の参考にしてください！\\n2021年11月6日\\n2021年11月10日\\nGAFA米国本社のエンジニアの年収をジョブレベル別に比較してみた【Google・Amazon・Facebook・Apple】\\n年収アップはアメリカ就職の大きな魅力の1つですが、実際にいくらぐらいもらえるのかはけっこう謎につつまれていますよね。そこで今回は、levels.fyiというアメリカの年収比較サービスに登録されている情報をもとに、GAFA（Google、Amazon、Facebook、Apple）4社のソフトウェアエンジニアの年収を、ジョブレベル別に徹底比較してみました！\\n2021年10月24日\\n2021年11月10日\\n元アマゾン社員がAudibleよりオススメするオーディオブックサービスとは？\\nAmazon在籍中は会社に遠慮してしまい、どうしても紹介できなかったオーディオブック配信サービスのAudiobook.jp。Amazonを退職した今、ようやくおおっぴらに紹介できます！「なかなか読書の時間を取れない」とお悩みの方や「日本の本は高くて」とお嘆きの海外在住の方には圧倒的にオススメです！\\n2021年8月8日\\nAmazonシアトル本社を退職しました\\n私事で恐縮ですが、Amazonシアトル本社を退職いたしました。この記事では、Amazonを退職した理由や、Amaozn退職後の進路について書いています。Amazonのお給料の仕組みについても触れているので、これからAmazonに入ろうと思っている人にも参考になる内容だと思います。\\n2021年6月17日\\n2021年7月31日\\n内定をもらったら絶対に給与交渉すべき3つの理由と交渉のコツ\\n転職活動の結果みごと内定を獲得した後、提示された給与をそのまま承諾してしまっていませんか？それ、実はかなり損しています。この記事では、内定獲得後に必ず給与交渉をした方が良い理由と、その具体的な進め方について説明します。海外就職や外資就職希望者は必読です。\\n2021年3月27日\\nネイティブの英語に近づくライティングの学習法：原文復元法\\n今回は、僕のお気に入りの英文ライティングの学習法をご紹介したいと思います。\\n\\npage_id: 271228ae-4f59-4a2d-8539-a4f19c5bef55\\n\\nそれ、実はかなり損しています。この記事では、内定獲得後に必ず給与交渉をした方が良い理由と、その具体的な進め方について説明します。海外就職や外資就職希望者は必読です。\\n2021年3月27日\\nネイティブの英語に近づくライティングの学習法：原文復元法\\n今回は、僕のお気に入りの英文ライティングの学習法をご紹介したいと思います。これに粛々と取り組むだけで、1. ネイティブっぽいこなれた英文が書けるようになる、2. 英語を話す際にもまとまった量の英文がスラスラ浮かぶようになる、などなど良い事ずくめなので、ぜひ取り組んでみてください！\\n2021年2月27日\\nプロダクトマネージャーにオススメの英語オーディオブック８選\\n日本でもようやく認知されてきたプロダクトマネージャー職。関連書籍もポツポツと出始めていますが、アメリカに比べるとまだまだ少なく、日本のプロダクトマネージャーさんたちも手探りで学んでいるようです。ということで、この記事ではプロダクトマネージャーにオススメの英語オーディオブックを8冊ご紹介します。\\n2021年1月19日\\n2022年7月15日\\n【転職で損したくない人へ】転職エージェントの上手な使い方\\n僕は最初の転職はエージェントを使わずに自分一人で行ったのですが、その結果、入社してから大損していたことに気づきました。 今回の記事では、転職で損をしないようにするために、転職エージェントを使うメリットとその上手な活用の仕方について紹介します。 外資系への就職や海外就職を狙っている人だけでなく、日系企業を狙っている人にとっても大事な話だと思うので、ぜひ読んでみてください。\\nQuery: SQLを勉強するのに良い資料は？\\nOriginal Answer: SQLを学ぶための良い資料として、GMOペパボのSQL研修資料が基本から始まり、RDBMSの歴史やデータベース設計に触れているので初心者にも理解しやすいです。また、Business Insiderやダイヤモンド・シグナルもSQLを含むテクノロジー系の情報を提供しているので、参考になるでしょう。\\nNew Answer: '}], 'model': 'gpt-3.5-turbo', 'stream': False, 'temperature': 0.1}}\n",
      "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/chat/completions\n",
      "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_headers.complete\n",
      "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:send_request_body.complete\n",
      "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 01 Aug 2024 16:35:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'openai-organization', b'user-01p8otbt5gis2mt84rnzemio'), (b'openai-processing-ms', b'2041'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15552000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'200000'), (b'x-ratelimit-remaining-requests', b'9995'), (b'x-ratelimit-remaining-tokens', b'182221'), (b'x-ratelimit-reset-requests', b'40.038s'), (b'x-ratelimit-reset-tokens', b'5.333s'), (b'x-request-id', b'req_31db63d82d75467c8af90bc7fc57c300'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8ac73ddd7fd0688c-NRT'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
      "DEBUG:httpcore.http11:receive_response_body.complete\n",
      "DEBUG:httpcore.http11:response_closed.started\n",
      "DEBUG:httpcore.http11:response_closed.complete\n",
      "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/chat/completions \"200 OK\" Headers({'date': 'Thu, 01 Aug 2024 16:35:31 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'openai-organization': 'user-01p8otbt5gis2mt84rnzemio', 'openai-processing-ms': '2041', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15552000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '10000', 'x-ratelimit-limit-tokens': '200000', 'x-ratelimit-remaining-requests': '9995', 'x-ratelimit-remaining-tokens': '182221', 'x-ratelimit-reset-requests': '40.038s', 'x-ratelimit-reset-tokens': '5.333s', 'x-request-id': 'req_31db63d82d75467c8af90bc7fc57c300', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8ac73ddd7fd0688c-NRT', 'content-encoding': 'gzip', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
      "DEBUG:openai._base_client:request_id: req_31db63d82d75467c8af90bc7fc57c300\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "SQLを学ぶための良い資料として、GMOペパボのSQL研修資料が基本から始まり、RDBMSの歴史やデータベース設計に触れているので初心者にも理解しやすいです。また、Business Insiderやダイヤモンド・シグナルもSQLを含むテクノロジー系の情報を提供しているので、参考になるでしょう。"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "documents = bookmark_documents\n",
    "\n",
    "index = SummaryIndex.from_documents(documents)\n",
    "# set Logging to DEBUG for more detailed outputs\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"SQLを勉強するのに良い資料は？\")\n",
    "display(Markdown(f\"{response}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
